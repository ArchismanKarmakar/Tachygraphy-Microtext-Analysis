{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b09b1f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:26.580423Z",
     "iopub.status.busy": "2024-08-31T07:40:26.580054Z",
     "iopub.status.idle": "2024-08-31T07:40:27.894717Z",
     "shell.execute_reply": "2024-08-31T07:40:27.893382Z"
    },
    "papermill": {
     "duration": 1.346599,
     "end_time": "2024-08-31T07:40:27.896977",
     "exception": false,
     "start_time": "2024-08-31T07:40:26.550378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_EmotionMoodtags_Dataset.csv\n",
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e68f57",
   "metadata": {
    "papermill": {
     "duration": 0.026198,
     "end_time": "2024-08-31T07:40:27.949969",
     "exception": false,
     "start_time": "2024-08-31T07:40:27.923771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET & PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e8d66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.006706Z",
     "iopub.status.busy": "2024-08-31T07:40:28.006244Z",
     "iopub.status.idle": "2024-08-31T07:40:28.330488Z",
     "shell.execute_reply": "2024-08-31T07:40:28.329547Z"
    },
    "papermill": {
     "duration": 0.353816,
     "end_time": "2024-08-31T07:40:28.332520",
     "exception": false,
     "start_time": "2024-08-31T07:40:27.978704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For emoji cleaning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "'''For emoji cleaning'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a4498c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.388569Z",
     "iopub.status.busy": "2024-08-31T07:40:28.388114Z",
     "iopub.status.idle": "2024-08-31T07:40:28.450500Z",
     "shell.execute_reply": "2024-08-31T07:40:28.449777Z"
    },
    "papermill": {
     "duration": 0.09255,
     "end_time": "2024-08-31T07:40:28.452445",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.359895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0aa31ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.508353Z",
     "iopub.status.busy": "2024-08-31T07:40:28.508034Z",
     "iopub.status.idle": "2024-08-31T07:40:28.512048Z",
     "shell.execute_reply": "2024-08-31T07:40:28.511232Z"
    },
    "papermill": {
     "duration": 0.03448,
     "end_time": "2024-08-31T07:40:28.514178",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.479698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6552ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.568916Z",
     "iopub.status.busy": "2024-08-31T07:40:28.568624Z",
     "iopub.status.idle": "2024-08-31T07:40:28.579268Z",
     "shell.execute_reply": "2024-08-31T07:40:28.578200Z"
    },
    "papermill": {
     "duration": 0.040225,
     "end_time": "2024-08-31T07:40:28.581286",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.541061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text         1\n",
      "Meaning      1\n",
      "Sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3b6085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.639548Z",
     "iopub.status.busy": "2024-08-31T07:40:28.639254Z",
     "iopub.status.idle": "2024-08-31T07:40:28.662614Z",
     "shell.execute_reply": "2024-08-31T07:40:28.661896Z"
    },
    "papermill": {
     "duration": 0.053694,
     "end_time": "2024-08-31T07:40:28.664469",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.610775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n",
    "                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n",
    "                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
    "                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
    "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n",
    "                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n",
    "\n",
    "punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n",
    "                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n",
    "\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n",
    "                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n",
    "                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n",
    "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n",
    "                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n",
    "                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n",
    "                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n",
    "                'demonetisation': 'demonetization'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2078acaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.720465Z",
     "iopub.status.busy": "2024-08-31T07:40:28.720168Z",
     "iopub.status.idle": "2024-08-31T07:40:28.732879Z",
     "shell.execute_reply": "2024-08-31T07:40:28.731991Z"
    },
    "papermill": {
     "duration": 0.043889,
     "end_time": "2024-08-31T07:40:28.735020",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.691131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean emoji, Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\:(.*?)\\:','',text)\n",
    "    text = str(text).lower()    #Making Text Lowercase\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    #The next 2 lines remove html text\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    '''Clean contraction using contraction mapping'''    \n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    for word in mapping.keys():\n",
    "        if \"\"+word+\"\" in text:\n",
    "            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n",
    "    #Remove Punctuations\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    '''Cleans special characters present(if any)'''   \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def correct_spelling(x, dic):\n",
    "    '''Corrects common spelling errors'''   \n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "def remove_space(text):\n",
    "    '''Removes awkward spaces'''   \n",
    "    #Removes awkward spaces \n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f24075e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.790183Z",
     "iopub.status.busy": "2024-08-31T07:40:28.789924Z",
     "iopub.status.idle": "2024-08-31T07:40:28.794521Z",
     "shell.execute_reply": "2024-08-31T07:40:28.793668Z"
    },
    "papermill": {
     "duration": 0.034815,
     "end_time": "2024-08-31T07:40:28.796476",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.761661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing_pipeline(text):\n",
    "    '''Cleaning and parsing the text.'''\n",
    "    text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_text(text)\n",
    "    text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_special_chars(text, punct, punct_mapping)\n",
    "#     text = correct_spelling(text, mispell_dict)\n",
    "    text = remove_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5204f8d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.850658Z",
     "iopub.status.busy": "2024-08-31T07:40:28.850397Z",
     "iopub.status.idle": "2024-08-31T07:40:28.862589Z",
     "shell.execute_reply": "2024-08-31T07:40:28.861767Z"
    },
    "papermill": {
     "duration": 0.041489,
     "end_time": "2024-08-31T07:40:28.864627",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.823138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Text':'text', 'Sentiment':'sentiment_polarity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c25af9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.920345Z",
     "iopub.status.busy": "2024-08-31T07:40:28.920012Z",
     "iopub.status.idle": "2024-08-31T07:40:28.930506Z",
     "shell.execute_reply": "2024-08-31T07:40:28.929704Z"
    },
    "papermill": {
     "duration": 0.040942,
     "end_time": "2024-08-31T07:40:28.932262",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.891320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Meaning'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4284e8cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:28.987292Z",
     "iopub.status.busy": "2024-08-31T07:40:28.986633Z",
     "iopub.status.idle": "2024-08-31T07:40:28.995626Z",
     "shell.execute_reply": "2024-08-31T07:40:28.994894Z"
    },
    "papermill": {
     "duration": 0.038528,
     "end_time": "2024-08-31T07:40:28.997471",
     "exception": false,
     "start_time": "2024-08-31T07:40:28.958943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['text', 'sentiment_polarity'], inplace=True) # Dropping NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b723fa6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:29.052708Z",
     "iopub.status.busy": "2024-08-31T07:40:29.052443Z",
     "iopub.status.idle": "2024-08-31T07:40:29.077147Z",
     "shell.execute_reply": "2024-08-31T07:40:29.076197Z"
    },
    "papermill": {
     "duration": 0.055647,
     "end_time": "2024-08-31T07:40:29.079673",
     "exception": false,
     "start_time": "2024-08-31T07:40:29.024026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 4957\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   text                4957 non-null   object\n",
      " 1   sentiment_polarity  4957 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 116.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# df['text'] = df['text'].astype('str')\n",
    "# df['sentiment_polarity'] = df['sentiment_polarity'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7605e81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:29.140781Z",
     "iopub.status.busy": "2024-08-31T07:40:29.140447Z",
     "iopub.status.idle": "2024-08-31T07:40:33.291337Z",
     "shell.execute_reply": "2024-08-31T07:40:33.290522Z"
    },
    "papermill": {
     "duration": 4.182619,
     "end_time": "2024-08-31T07:40:33.293566",
     "exception": false,
     "start_time": "2024-08-31T07:40:29.110947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: text_preprocessing_pipeline(x))\n",
    "df['sentiment_polarity'] = df['sentiment_polarity'].apply(lambda x: text_preprocessing_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e88d8261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.350179Z",
     "iopub.status.busy": "2024-08-31T07:40:33.349380Z",
     "iopub.status.idle": "2024-08-31T07:40:33.364977Z",
     "shell.execute_reply": "2024-08-31T07:40:33.364009Z"
    },
    "papermill": {
     "duration": 0.045784,
     "end_time": "2024-08-31T07:40:33.366974",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.321190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>make a pet face wtf wrong with me tonight haha</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>i dnt care anymore boyz is not worth d drama</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>no relationship is perfect tho me bae goo from...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>over here tryna get my nail polishes and shit lol</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>no one was loved d way i luv u</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment_polarity\n",
       "0                               last session of the day            neutral\n",
       "1     shanghai is also really exciting precisely sky...           positive\n",
       "2                                submit the report asap           negative\n",
       "3                                            happy bday           positive\n",
       "4                                     the ogs i like it           positive\n",
       "...                                                 ...                ...\n",
       "4953     make a pet face wtf wrong with me tonight haha           negative\n",
       "4954       i dnt care anymore boyz is not worth d drama           negative\n",
       "4955  no relationship is perfect tho me bae goo from...           negative\n",
       "4956  over here tryna get my nail polishes and shit lol           negative\n",
       "4957                     no one was loved d way i luv u           positive\n",
       "\n",
       "[4957 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fdf03ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.423196Z",
     "iopub.status.busy": "2024-08-31T07:40:33.422896Z",
     "iopub.status.idle": "2024-08-31T07:40:33.434575Z",
     "shell.execute_reply": "2024-08-31T07:40:33.433767Z"
    },
    "papermill": {
     "duration": 0.043027,
     "end_time": "2024-08-31T07:40:33.436957",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.393930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_polar = pd.get_dummies(df['sentiment_polarity'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f6bc94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.496849Z",
     "iopub.status.busy": "2024-08-31T07:40:33.496487Z",
     "iopub.status.idle": "2024-08-31T07:40:33.501056Z",
     "shell.execute_reply": "2024-08-31T07:40:33.500126Z"
    },
    "papermill": {
     "duration": 0.037277,
     "end_time": "2024-08-31T07:40:33.503082",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.465805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_polar = bin_polar.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ccedd67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.594473Z",
     "iopub.status.busy": "2024-08-31T07:40:33.594086Z",
     "iopub.status.idle": "2024-08-31T07:40:33.607198Z",
     "shell.execute_reply": "2024-08-31T07:40:33.606334Z"
    },
    "papermill": {
     "duration": 0.04355,
     "end_time": "2024-08-31T07:40:33.609349",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.565799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      negative  neutral  positive\n",
       "0            0        1         0\n",
       "1            0        0         1\n",
       "2            1        0         0\n",
       "3            0        0         1\n",
       "4            0        0         1\n",
       "...        ...      ...       ...\n",
       "4953         1        0         0\n",
       "4954         1        0         0\n",
       "4955         1        0         0\n",
       "4956         1        0         0\n",
       "4957         0        0         1\n",
       "\n",
       "[4957 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f32e41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.669872Z",
     "iopub.status.busy": "2024-08-31T07:40:33.669549Z",
     "iopub.status.idle": "2024-08-31T07:40:33.682168Z",
     "shell.execute_reply": "2024-08-31T07:40:33.681196Z"
    },
    "papermill": {
     "duration": 0.043571,
     "end_time": "2024-08-31T07:40:33.684149",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.640578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            last session of the day            neutral   \n",
       "1  shanghai is also really exciting precisely sky...           positive   \n",
       "2                             submit the report asap           negative   \n",
       "3                                         happy bday           positive   \n",
       "4                                  the ogs i like it           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, bin_polar], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0fc1c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.742041Z",
     "iopub.status.busy": "2024-08-31T07:40:33.741701Z",
     "iopub.status.idle": "2024-08-31T07:40:33.752501Z",
     "shell.execute_reply": "2024-08-31T07:40:33.751407Z"
    },
    "papermill": {
     "duration": 0.042889,
     "end_time": "2024-08-31T07:40:33.754672",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.711783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            last session of the day            neutral   \n",
       "1  shanghai is also really exciting precisely sky...           positive   \n",
       "2                             submit the report asap           negative   \n",
       "3                                         happy bday           positive   \n",
       "4                                  the ogs i like it           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(columns=['sentiment_polarity'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8df6178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.812746Z",
     "iopub.status.busy": "2024-08-31T07:40:33.812444Z",
     "iopub.status.idle": "2024-08-31T07:40:33.823692Z",
     "shell.execute_reply": "2024-08-31T07:40:33.822721Z"
    },
    "papermill": {
     "duration": 0.042158,
     "end_time": "2024-08-31T07:40:33.825724",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.783566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 4957\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   text                4957 non-null   object\n",
      " 1   sentiment_polarity  4957 non-null   object\n",
      " 2   negative            4957 non-null   int64 \n",
      " 3   neutral             4957 non-null   int64 \n",
      " 4   positive            4957 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 232.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f0dc221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.883678Z",
     "iopub.status.busy": "2024-08-31T07:40:33.883373Z",
     "iopub.status.idle": "2024-08-31T07:40:33.887489Z",
     "shell.execute_reply": "2024-08-31T07:40:33.886610Z"
    },
    "papermill": {
     "duration": 0.03612,
     "end_time": "2024-08-31T07:40:33.889475",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.853355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_polarity_label_mapping = {\n",
    "    0: \"negative\", 1: \"neutral\", 2: \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96d3bee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:33.947312Z",
     "iopub.status.busy": "2024-08-31T07:40:33.946627Z",
     "iopub.status.idle": "2024-08-31T07:40:33.950750Z",
     "shell.execute_reply": "2024-08-31T07:40:33.949941Z"
    },
    "papermill": {
     "duration": 0.035149,
     "end_time": "2024-08-31T07:40:33.952659",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.917510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_polarity_label_mapping_rev = {\n",
    "    'negative': 0, 'neutral': 1, 'positive': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c524edcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.010822Z",
     "iopub.status.busy": "2024-08-31T07:40:34.010530Z",
     "iopub.status.idle": "2024-08-31T07:40:34.014474Z",
     "shell.execute_reply": "2024-08-31T07:40:34.013559Z"
    },
    "papermill": {
     "duration": 0.035551,
     "end_time": "2024-08-31T07:40:34.016517",
     "exception": false,
     "start_time": "2024-08-31T07:40:33.980966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SENTIMENT_POLARITY_LABELS = [\n",
    "    \"negative\", \"neutral\", \"positive\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d3c7e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.073650Z",
     "iopub.status.busy": "2024-08-31T07:40:34.073358Z",
     "iopub.status.idle": "2024-08-31T07:40:34.078370Z",
     "shell.execute_reply": "2024-08-31T07:40:34.077492Z"
    },
    "papermill": {
     "duration": 0.035841,
     "end_time": "2024-08-31T07:40:34.080381",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.044540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_train_split(dataset, test_ratio=0.1):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b6715e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.138042Z",
     "iopub.status.busy": "2024-08-31T07:40:34.137698Z",
     "iopub.status.idle": "2024-08-31T07:40:34.145873Z",
     "shell.execute_reply": "2024-08-31T07:40:34.144772Z"
    },
    "papermill": {
     "duration": 0.039338,
     "end_time": "2024-08-31T07:40:34.147849",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.108511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4450 examples in training, 507 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "train_ds_pd, validation_ds_pd = test_train_split(df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(validation_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8373778c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.206406Z",
     "iopub.status.busy": "2024-08-31T07:40:34.205811Z",
     "iopub.status.idle": "2024-08-31T07:40:34.211193Z",
     "shell.execute_reply": "2024-08-31T07:40:34.210303Z"
    },
    "papermill": {
     "duration": 0.036894,
     "end_time": "2024-08-31T07:40:34.213472",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.176578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd = train_ds_pd.reset_index(drop=True)\n",
    "validation_ds_pd = validation_ds_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e16ab4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.274285Z",
     "iopub.status.busy": "2024-08-31T07:40:34.273960Z",
     "iopub.status.idle": "2024-08-31T07:40:34.285034Z",
     "shell.execute_reply": "2024-08-31T07:40:34.284059Z"
    },
    "papermill": {
     "duration": 0.043527,
     "end_time": "2024-08-31T07:40:34.287076",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.243549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that is great weee visitors</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            last session of the day            neutral   \n",
       "1  shanghai is also really exciting precisely sky...           positive   \n",
       "2                             submit the report asap           negative   \n",
       "3                                  the ogs i like it           positive   \n",
       "4                        that is great weee visitors           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d50e9a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.347805Z",
     "iopub.status.busy": "2024-08-31T07:40:34.347476Z",
     "iopub.status.idle": "2024-08-31T07:40:34.354062Z",
     "shell.execute_reply": "2024-08-31T07:40:34.353223Z"
    },
    "papermill": {
     "duration": 0.038349,
     "end_time": "2024-08-31T07:40:34.355996",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.317647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative', ..., 'negative', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_labels = np.array(train_ds_pd['sentiment_polarity'])\n",
    "sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c1bd474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.414236Z",
     "iopub.status.busy": "2024-08-31T07:40:34.413909Z",
     "iopub.status.idle": "2024-08-31T07:40:34.419569Z",
     "shell.execute_reply": "2024-08-31T07:40:34.418789Z"
    },
    "papermill": {
     "duration": 0.037228,
     "end_time": "2024-08-31T07:40:34.421478",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.384250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd.drop(columns=['sentiment_polarity'], inplace=True)\n",
    "validation_ds_pd.drop(columns=['sentiment_polarity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c863e17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.480980Z",
     "iopub.status.busy": "2024-08-31T07:40:34.480681Z",
     "iopub.status.idle": "2024-08-31T07:40:34.490408Z",
     "shell.execute_reply": "2024-08-31T07:40:34.489506Z"
    },
    "papermill": {
     "duration": 0.041188,
     "end_time": "2024-08-31T07:40:34.492432",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.451244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that is great weee visitors</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0                            last session of the day         0        1   \n",
       "1  shanghai is also really exciting precisely sky...         0        0   \n",
       "2                             submit the report asap         1        0   \n",
       "3                                  the ogs i like it         0        0   \n",
       "4                        that is great weee visitors         0        0   \n",
       "\n",
       "   positive  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea9cfa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.553058Z",
     "iopub.status.busy": "2024-08-31T07:40:34.552776Z",
     "iopub.status.idle": "2024-08-31T07:40:34.562413Z",
     "shell.execute_reply": "2024-08-31T07:40:34.561599Z"
    },
    "papermill": {
     "duration": 0.041167,
     "end_time": "2024-08-31T07:40:34.564279",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.523112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you guys did not say hi or answer my questions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thats so cool</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>look who i found just for you</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why do i have to enter my registration details...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0                                         happy bday         0        0   \n",
       "1  you guys did not say hi or answer my questions...         0        0   \n",
       "2                                      thats so cool         0        0   \n",
       "3                      look who i found just for you         0        0   \n",
       "4  why do i have to enter my registration details...         0        1   \n",
       "\n",
       "   positive  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c452c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.624719Z",
     "iopub.status.busy": "2024-08-31T07:40:34.624403Z",
     "iopub.status.idle": "2024-08-31T07:40:34.632726Z",
     "shell.execute_reply": "2024-08-31T07:40:34.631423Z"
    },
    "papermill": {
     "duration": 0.041582,
     "end_time": "2024-08-31T07:40:34.635028",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.593446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_indexed_labels = np.array([sentiment_polarity_label_mapping_rev[label] for label in sentiment_labels])\n",
    "sentiment_indexed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5d2d850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:34.694649Z",
     "iopub.status.busy": "2024-08-31T07:40:34.694376Z",
     "iopub.status.idle": "2024-08-31T07:40:40.534179Z",
     "shell.execute_reply": "2024-08-31T07:40:40.533089Z"
    },
    "papermill": {
     "duration": 5.872146,
     "end_time": "2024-08-31T07:40:40.536584",
     "exception": false,
     "start_time": "2024-08-31T07:40:34.664438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815e734",
   "metadata": {
    "papermill": {
     "duration": 0.02854,
     "end_time": "2024-08-31T07:40:40.594373",
     "exception": false,
     "start_time": "2024-08-31T07:40:40.565833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculating Class Weights for each labels to avoid imbalanced distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d794aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:40.654543Z",
     "iopub.status.busy": "2024-08-31T07:40:40.654043Z",
     "iopub.status.idle": "2024-08-31T07:40:40.821861Z",
     "shell.execute_reply": "2024-08-31T07:40:40.820885Z"
    },
    "papermill": {
     "duration": 0.200943,
     "end_time": "2024-08-31T07:40:40.823992",
     "exception": false,
     "start_time": "2024-08-31T07:40:40.623049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3520, 0.3174, 0.3306])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = np.bincount(sentiment_indexed_labels)\n",
    "total_samples = len(sentiment_labels)\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ffab39",
   "metadata": {
    "papermill": {
     "duration": 0.029743,
     "end_time": "2024-08-31T07:40:40.883446",
     "exception": false,
     "start_time": "2024-08-31T07:40:40.853703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class Weight NOTE\n",
    "### This class weights are for the training dataset and are to be used while training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed77391",
   "metadata": {
    "papermill": {
     "duration": 0.028742,
     "end_time": "2024-08-31T07:40:40.940626",
     "exception": false,
     "start_time": "2024-08-31T07:40:40.911884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SETTING CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30ce963e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:41.000022Z",
     "iopub.status.busy": "2024-08-31T07:40:40.999667Z",
     "iopub.status.idle": "2024-08-31T07:40:41.081248Z",
     "shell.execute_reply": "2024-08-31T07:40:41.080209Z"
    },
    "papermill": {
     "duration": 0.113394,
     "end_time": "2024-08-31T07:40:41.083221",
     "exception": false,
     "start_time": "2024-08-31T07:40:40.969827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0764fef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:41.143616Z",
     "iopub.status.busy": "2024-08-31T07:40:41.143058Z",
     "iopub.status.idle": "2024-08-31T07:40:45.023099Z",
     "shell.execute_reply": "2024-08-31T07:40:45.022067Z"
    },
    "papermill": {
     "duration": 3.912785,
     "end_time": "2024-08-31T07:40:45.025726",
     "exception": false,
     "start_time": "2024-08-31T07:40:41.112941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import DebertaV2Model, DebertaV2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbf884f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:45.089603Z",
     "iopub.status.busy": "2024-08-31T07:40:45.089098Z",
     "iopub.status.idle": "2024-08-31T07:40:46.646934Z",
     "shell.execute_reply": "2024-08-31T07:40:46.645900Z"
    },
    "papermill": {
     "duration": 1.592238,
     "end_time": "2024-08-31T07:40:46.649528",
     "exception": false,
     "start_time": "2024-08-31T07:40:45.057290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0212e5eef3f74d47a621a4b590b06a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff6485af1854fc18d55cf627db9a99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78b4dc16a43425590b6888b007d48eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9ccc8",
   "metadata": {
    "papermill": {
     "duration": 0.033856,
     "end_time": "2024-08-31T07:40:46.726225",
     "exception": false,
     "start_time": "2024-08-31T07:40:46.692369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TORCH IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d704f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:40:46.797074Z",
     "iopub.status.busy": "2024-08-31T07:40:46.796715Z",
     "iopub.status.idle": "2024-08-31T07:41:11.828043Z",
     "shell.execute_reply": "2024-08-31T07:41:11.826980Z"
    },
    "papermill": {
     "duration": 25.06874,
     "end_time": "2024-08-31T07:41:11.830510",
     "exception": false,
     "start_time": "2024-08-31T07:40:46.761770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 07:40:50,402\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-08-31 07:40:51,164\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# from optuna.integration import PyTorchLightningPruner\n",
    "from ray import tune\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.integration.pytorch import TuneReportCallback\n",
    "from torch.amp import GradScaler, autocast\n",
    "# from ray.tune.integration.optuna import OptunaSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from torch import autocast\n",
    "# from ray import tune\n",
    "# from ray.tune.integration.tensorboard import TensorBoardReporter\n",
    "from ray.tune.logger import TBXLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ray.train import report\n",
    "# from ray.tune.integration.jupyter import JupyterNotebookReporter\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from ray.tune.schedulers import HyperBandScheduler, AsyncHyperBandScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d298c1f",
   "metadata": {
    "papermill": {
     "duration": 0.031252,
     "end_time": "2024-08-31T07:41:11.893841",
     "exception": false,
     "start_time": "2024-08-31T07:41:11.862589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET CONFIG & ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56c235c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:11.957159Z",
     "iopub.status.busy": "2024-08-31T07:41:11.956038Z",
     "iopub.status.idle": "2024-08-31T07:41:11.965023Z",
     "shell.execute_reply": "2024-08-31T07:41:11.964144Z"
    },
    "papermill": {
     "duration": 0.0427,
     "end_time": "2024-08-31T07:41:11.966998",
     "exception": false,
     "start_time": "2024-08-31T07:41:11.924298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         text = self.data.iloc[index, 0]\n",
    "#         labels = self.data.iloc[index, 1:].values.astype(float)\n",
    "        text = str(self.data.iloc[index]['text'])\n",
    "        labels = self.data.iloc[index][['negative', 'neutral', 'positive']].values.astype(np.float32)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba244a06",
   "metadata": {
    "papermill": {
     "duration": 0.030105,
     "end_time": "2024-08-31T07:41:12.027199",
     "exception": false,
     "start_time": "2024-08-31T07:41:11.997094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e8f0568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:12.088821Z",
     "iopub.status.busy": "2024-08-31T07:41:12.088508Z",
     "iopub.status.idle": "2024-08-31T07:41:12.095794Z",
     "shell.execute_reply": "2024-08-31T07:41:12.094955Z"
    },
    "papermill": {
     "duration": 0.04009,
     "end_time": "2024-08-31T07:41:12.097623",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.057533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.roberta = roberta_model\n",
    "        self.drop = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(self.roberta.config.hidden_size, 256)  # Reduced neurons\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(256, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get the RoBERTa output\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "        # Pass through the custom layers\n",
    "        output = self.drop(cls_token_state)\n",
    "        output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08218909",
   "metadata": {
    "papermill": {
     "duration": 0.029888,
     "end_time": "2024-08-31T07:41:12.157204",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.127316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Other Models to try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2df2766b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:12.262320Z",
     "iopub.status.busy": "2024-08-31T07:41:12.261823Z",
     "iopub.status.idle": "2024-08-31T07:41:12.267937Z",
     "shell.execute_reply": "2024-08-31T07:41:12.266777Z"
    },
    "papermill": {
     "duration": 0.068377,
     "end_time": "2024-08-31T07:41:12.270647",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.202270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SentimentModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(SentimentModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size, 512)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Get the RoBERTa output\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "#         # Pass through the custom layers\n",
    "#         output = self.drop(cls_token_state)\n",
    "# #         output = cls_token_state\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "# #         output = self.drop(output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ffe1605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:12.335059Z",
     "iopub.status.busy": "2024-08-31T07:41:12.334699Z",
     "iopub.status.idle": "2024-08-31T07:41:12.339063Z",
     "shell.execute_reply": "2024-08-31T07:41:12.338230Z"
    },
    "papermill": {
     "duration": 0.037058,
     "end_time": "2024-08-31T07:41:12.340944",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.303886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AdvancedPooling(nn.Module):\n",
    "#     def __init__(self, hidden_size):\n",
    "#         super(AdvancedPooling, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#     def forward(self, hidden_states):\n",
    "#         cls_output = hidden_states[:, 0, :]  # [CLS] token output\n",
    "#         mean_output = hidden_states.mean(dim=1)  # Mean pooling over sequence\n",
    "#         max_output, _ = hidden_states.max(dim=1)  # Max pooling over sequence\n",
    "#         combined_output = torch.cat([cls_output, mean_output, max_output], dim=1)\n",
    "#         return combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a1e955c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:12.402695Z",
     "iopub.status.busy": "2024-08-31T07:41:12.401906Z",
     "iopub.status.idle": "2024-08-31T07:41:12.406866Z",
     "shell.execute_reply": "2024-08-31T07:41:12.406020Z"
    },
    "papermill": {
     "duration": 0.03759,
     "end_time": "2024-08-31T07:41:12.408853",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.371263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SentimentModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(SentimentModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size * 3, 512)\n",
    "#         self.attention_pooling = AdvancedPooling(hidden_size=self.roberta.config.hidden_size)\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         cls_output = output.last_hidden_state[:, 0, :]  # Extract [CLS] token representation\n",
    "#         hidden_states = output.last_hidden_state  # Sequence hidden states\n",
    "#         pooled_output = self.attention_pooling(hidden_states)  # Attention pooling  # Combine CLS and attention pooling\n",
    "#         output = self.drop(pooled_output)\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "#         output = self.drop(output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711a20a",
   "metadata": {
    "papermill": {
     "duration": 0.029797,
     "end_time": "2024-08-31T07:41:12.469253",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.439456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRAIN & VALIDATION\n",
    "### Custom metric is a metric for determining the best model free from any overfitting, underfitting. ```custom_metric = (avg_val_loss−val_accuracy) + α × ∣avg_train_loss−avg_val_loss∣ + β × ∣val_accuracy-train_accuracy∣``` This metric balances between low validation loss, high validation accuracy, and penalizing large discrepancies between training and validation loss. Note that, in the model selection we have used ```α = β = 0.5```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5c3b7",
   "metadata": {
    "papermill": {
     "duration": 0.030508,
     "end_time": "2024-08-31T07:41:12.530002",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.499494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### But, if we have probabilistic values as input and output we cannot directly calculate the accuracy, infact we need to rely on loss only. ```custom_metric = avg_val_loss + α × ∣avg_train_loss−avg_val_loss∣```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "257c7442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:12.592561Z",
     "iopub.status.busy": "2024-08-31T07:41:12.592248Z",
     "iopub.status.idle": "2024-08-31T07:41:12.597590Z",
     "shell.execute_reply": "2024-08-31T07:41:12.596645Z"
    },
    "papermill": {
     "duration": 0.03908,
     "end_time": "2024-08-31T07:41:12.599676",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.560596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom metric calculation function\n",
    "def calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy, alpha=0.5, beta=0.5):\n",
    "    loss_diff = abs(avg_train_loss - avg_val_loss)\n",
    "    accuracy_diff = abs(train_accuracy - val_accuracy)\n",
    "    custom_metric = avg_val_loss - val_accuracy + alpha * loss_diff + beta * accuracy_diff\n",
    "    return custom_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c9800",
   "metadata": {
    "papermill": {
     "duration": 0.030055,
     "end_time": "2024-08-31T07:41:12.659385",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.629330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5435aaa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:12.722893Z",
     "iopub.status.busy": "2024-08-31T07:41:12.722548Z",
     "iopub.status.idle": "2024-08-31T07:41:12.730299Z",
     "shell.execute_reply": "2024-08-31T07:41:12.729265Z"
    },
    "papermill": {
     "duration": 0.042819,
     "end_time": "2024-08-31T07:41:12.732768",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.689949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        EarlyStopping to stop training when a metric has stopped improving.\n",
    "\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss improved to {val_loss:.4f}')\n",
    "#             torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss did not improve. Patience: {self.patience}, Counter: {self.counter}')\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69b4a43a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:12.796632Z",
     "iopub.status.busy": "2024-08-31T07:41:12.796351Z",
     "iopub.status.idle": "2024-08-31T07:41:12.820383Z",
     "shell.execute_reply": "2024-08-31T07:41:12.819172Z"
    },
    "papermill": {
     "duration": 0.058463,
     "end_time": "2024-08-31T07:41:12.822295",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.763832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training function with variable parameters\n",
    "def train_model(config, train_dataset, val_dataset, device):\n",
    "#     model = SentimentModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=3,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    \n",
    "    model = SentimentModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     class_weights_tmp = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights_tmp)\n",
    "#     criterion = nn.BCELoss()\n",
    "    scaler = GradScaler()  # Initialize GradScaler\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):  # Ensure epochs are passed from config\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):  # Mixed precision\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = torch.zeros_like(probabilities)\n",
    "            max_indices = torch.argmax(probabilities, dim=1)\n",
    "            predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "            predictions = predictions.float()\n",
    "                \n",
    "#                 loss = criterion(predictions, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "#             outputs = torch.sigmoid(outputs)  \n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "#             predicted_labels = (outputs > 0.5).float()\n",
    "#             correct_train_preds += (predicted_labels == labels).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "            correct_train_preds += (predictions == labels).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = torch.zeros_like(probabilities)\n",
    "                max_indices = torch.argmax(probabilities, dim=1)\n",
    "                predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "                predictions = predictions.float()\n",
    "                \n",
    "#                     loss = criterion(predictions, labels)\n",
    "                    \n",
    "#                 outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "    \n",
    "#                 predicted_labels = (outputs > 0.5).float()\n",
    "#                 correct_val_preds += (predicted_labels == labels).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "                correct_val_preds += (predictions == labels).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "#         custom_metric = avg_val_loss - val_accuracy\n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "\n",
    "        # Report metrics using ray.train.report\n",
    "        report({\n",
    "            \"loss\": avg_val_loss,\n",
    "            \"accuracy\": val_accuracy,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"custom_metric\": custom_metric,\n",
    "            \"early_stopping_epoch\": epoch + 1,\n",
    "        })\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "#         trial_dir = os.path.join(os.environ[\"TUNE_TRIAL_DIR\"], \"checkpoint.pt\")\n",
    "#         torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "#         checkpoint_path = f\"/kaggle/working/checkpoint_epoch_{epoch}.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_fn(config):\n",
    "    # Load your data here\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "    train_dataset = SentimentDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = SentimentDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(config, train_dataset, val_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf9cec",
   "metadata": {
    "papermill": {
     "duration": 0.029921,
     "end_time": "2024-08-31T07:41:12.882526",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.852605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ed9ab75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:12.943953Z",
     "iopub.status.busy": "2024-08-31T07:41:12.943549Z",
     "iopub.status.idle": "2024-08-31T07:41:12.950419Z",
     "shell.execute_reply": "2024-08-31T07:41:12.949300Z"
    },
    "papermill": {
     "duration": 0.040256,
     "end_time": "2024-08-31T07:41:12.952378",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.912122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'dropout_rate': tune.choice([0.2, 0.25, 0.27, 0.3, 0.32, 0.35, 0.4]),\n",
    "    'batch_size': tune.choice([32, 64]),\n",
    "    'weight_decay': tune.choice([1e-6, 2e-6, 1e-5, 2e-5, 1e-4, 2e-4, 5e-5, 5e-6, 1e-2, 1e-3]),\n",
    "    'lr': tune.choice([1e-6, 1e-5, 2e-5, 1e-4, 2e-4, 2e-6, 3e-6, 5e-6, 3e-5, 5e-5, 2e-7, 1e-7, 1e-3, 5e-7]),\n",
    "    'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df61004b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:13.014463Z",
     "iopub.status.busy": "2024-08-31T07:41:13.014106Z",
     "iopub.status.idle": "2024-08-31T07:41:13.018278Z",
     "shell.execute_reply": "2024-08-31T07:41:13.017499Z"
    },
    "papermill": {
     "duration": 0.037256,
     "end_time": "2024-08-31T07:41:13.020186",
     "exception": false,
     "start_time": "2024-08-31T07:41:12.982930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'dropout_rate': tune.uniform(0.1, 0.5),\n",
    "#     'batch_size': tune.choice([16, 32, 64]),\n",
    "#     'weight_decay': tune.loguniform(1e-6, 1e-1),\n",
    "#     'lr': tune.loguniform(1e-6, 1e-1),\n",
    "#     'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aaedd1",
   "metadata": {
    "papermill": {
     "duration": 0.029592,
     "end_time": "2024-08-31T07:41:13.080235",
     "exception": false,
     "start_time": "2024-08-31T07:41:13.050643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53eb9aeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:13.140577Z",
     "iopub.status.busy": "2024-08-31T07:41:13.140251Z",
     "iopub.status.idle": "2024-08-31T07:41:13.144853Z",
     "shell.execute_reply": "2024-08-31T07:41:13.143891Z"
    },
    "papermill": {
     "duration": 0.037196,
     "end_time": "2024-08-31T07:41:13.146819",
     "exception": false,
     "start_time": "2024-08-31T07:41:13.109623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna_search = OptunaSearch(\n",
    "    metric=[\"accuracy\",\"custom_metric\"],\n",
    "    mode=[\"max\",\"min\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcf957",
   "metadata": {
    "papermill": {
     "duration": 0.029866,
     "end_time": "2024-08-31T07:41:13.206817",
     "exception": false,
     "start_time": "2024-08-31T07:41:13.176951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SCHEDULER ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15729579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:13.276641Z",
     "iopub.status.busy": "2024-08-31T07:41:13.275701Z",
     "iopub.status.idle": "2024-08-31T07:41:13.280963Z",
     "shell.execute_reply": "2024-08-31T07:41:13.280024Z"
    },
    "papermill": {
     "duration": 0.039288,
     "end_time": "2024-08-31T07:41:13.282881",
     "exception": false,
     "start_time": "2024-08-31T07:41:13.243593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric='accuracy',\n",
    "    mode='max',\n",
    "    max_t=22,\n",
    "    grace_period=3,\n",
    "    reduction_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d09dc8",
   "metadata": {
    "papermill": {
     "duration": 0.029941,
     "end_time": "2024-08-31T07:41:13.343841",
     "exception": false,
     "start_time": "2024-08-31T07:41:13.313900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a698a3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:13.404888Z",
     "iopub.status.busy": "2024-08-31T07:41:13.404573Z",
     "iopub.status.idle": "2024-08-31T07:41:13.408953Z",
     "shell.execute_reply": "2024-08-31T07:41:13.408005Z"
    },
    "papermill": {
     "duration": 0.037491,
     "end_time": "2024-08-31T07:41:13.410953",
     "exception": false,
     "start_time": "2024-08-31T07:41:13.373462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To ignore warinings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f966002e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T07:41:13.472668Z",
     "iopub.status.busy": "2024-08-31T07:41:13.472388Z",
     "iopub.status.idle": "2024-08-31T11:23:58.984129Z",
     "shell.execute_reply": "2024-08-31T11:23:58.983139Z"
    },
    "papermill": {
     "duration": 13365.545728,
     "end_time": "2024-08-31T11:23:58.986706",
     "exception": false,
     "start_time": "2024-08-31T07:41:13.440978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-31 11:23:58</td></tr>\n",
       "<tr><td>Running for: </td><td>03:42:26.81        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.2/31.4 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=49<br>Bracket: Iter 12.000: 0.8014464168310322 | Iter 6.000: 0.799474030243261 | Iter 3.000: 0.7652859960552267<br>Logical resource usage: 2.0/4 CPUs, 1.0/2 GPUs (0.0/1.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  early_stopping_epoch</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_3ea8855f</td><td>TERMINATED</td><td>172.19.2.2:344 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.649704</td><td style=\"text-align: right;\">  0.761999</td><td style=\"text-align: right;\">     0.108354  </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">    0.320115</td><td style=\"text-align: right;\">        0.873708</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_5503f487</td><td>TERMINATED</td><td>172.19.2.2:379 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.637068</td><td style=\"text-align: right;\">  0.593688</td><td style=\"text-align: right;\">     0.0682357 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.652193</td><td style=\"text-align: right;\">        0.559101</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_3ca1806f</td><td>TERMINATED</td><td>172.19.2.2:483 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.470322</td><td style=\"text-align: right;\">  0.779093</td><td style=\"text-align: right;\">    -0.276644  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.442407</td><td style=\"text-align: right;\">        0.815431</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_e62ac370</td><td>TERMINATED</td><td>172.19.2.2:585 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.63987 </td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.125946  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637551</td><td style=\"text-align: right;\">        0.557603</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0da8201b</td><td>TERMINATED</td><td>172.19.2.2:658 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.682106</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.170473  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.685712</td><td style=\"text-align: right;\">        0.560899</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_967f3bb2</td><td>TERMINATED</td><td>172.19.2.2:744 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.718498</td><td style=\"text-align: right;\">  0.551611</td><td style=\"text-align: right;\">     0.168778  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.719882</td><td style=\"text-align: right;\">        0.549213</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_85b8262b</td><td>TERMINATED</td><td>172.19.2.2:818 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.687599</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.173431  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.694075</td><td style=\"text-align: right;\">        0.552959</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_1059f835</td><td>TERMINATED</td><td>172.19.2.2:902 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.460709</td><td style=\"text-align: right;\">  0.798817</td><td style=\"text-align: right;\">    -0.228154  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.318837</td><td style=\"text-align: right;\">        0.876854</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_974210f1</td><td>TERMINATED</td><td>172.19.2.2:976 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.47413 </td><td style=\"text-align: right;\">  0.822485</td><td style=\"text-align: right;\">    -0.175918  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.227222</td><td style=\"text-align: right;\">        0.920449</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_f152234b</td><td>TERMINATED</td><td>172.19.2.2:1070</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.469539</td><td style=\"text-align: right;\">  0.801446</td><td style=\"text-align: right;\">    -0.209418  </td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">    0.304611</td><td style=\"text-align: right;\">        0.881498</td><td style=\"text-align: right;\">                    12</td></tr>\n",
       "<tr><td>train_fn_72c017f5</td><td>TERMINATED</td><td>172.19.2.2:1143</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.692639</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.179058  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.693098</td><td style=\"text-align: right;\">        0.56015 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_1cf649fe</td><td>TERMINATED</td><td>172.19.2.2:1232</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.694224</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.181495  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.690563</td><td style=\"text-align: right;\">        0.558652</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_aaee3ede</td><td>TERMINATED</td><td>172.19.2.2:1321</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.464937</td><td style=\"text-align: right;\">  0.771203</td><td style=\"text-align: right;\">    -0.279323  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.44629 </td><td style=\"text-align: right;\">        0.806442</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_52314554</td><td>TERMINATED</td><td>172.19.2.2:1412</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.472242</td><td style=\"text-align: right;\">  0.768573</td><td style=\"text-align: right;\">    -0.276896  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.463451</td><td style=\"text-align: right;\">        0.798652</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_f12c2024</td><td>TERMINATED</td><td>172.19.2.2:1497</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.451977</td><td style=\"text-align: right;\">  0.788297</td><td style=\"text-align: right;\">    -0.310942  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.432399</td><td style=\"text-align: right;\">        0.819476</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_46d5fbf6</td><td>TERMINATED</td><td>172.19.2.2:1583</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.626652</td><td style=\"text-align: right;\">  0.673899</td><td style=\"text-align: right;\">     0.00352101</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.635562</td><td style=\"text-align: right;\">        0.581273</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f545ee5d</td><td>TERMINATED</td><td>172.19.2.2:1670</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.43877 </td><td style=\"text-align: right;\">  0.793557</td><td style=\"text-align: right;\">    -0.301898  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.381833</td><td style=\"text-align: right;\">        0.842397</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_89d8f842</td><td>TERMINATED</td><td>172.19.2.2:1744</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.528696</td><td style=\"text-align: right;\">  0.813281</td><td style=\"text-align: right;\">    -0.0919782 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.245708</td><td style=\"text-align: right;\">        0.915506</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_7bf5c7fc</td><td>TERMINATED</td><td>172.19.2.2:1837</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.488576</td><td style=\"text-align: right;\">  0.814596</td><td style=\"text-align: right;\">    -0.161026  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.252008</td><td style=\"text-align: right;\">        0.908015</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_5bd7c5aa</td><td>TERMINATED</td><td>172.19.2.2:1921</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.464594</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">    -0.20435   </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.293772</td><td style=\"text-align: right;\">        0.891685</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_569efa17</td><td>TERMINATED</td><td>172.19.2.2:2008</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.465627</td><td style=\"text-align: right;\">  0.788297</td><td style=\"text-align: right;\">    -0.217487  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.335427</td><td style=\"text-align: right;\">        0.868464</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_97ff9c84</td><td>TERMINATED</td><td>172.19.2.2:2102</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.457657</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">    -0.213391  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.282156</td><td style=\"text-align: right;\">        0.898577</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_10db737d</td><td>TERMINATED</td><td>172.19.2.2:2184</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.4662  </td><td style=\"text-align: right;\">  0.811966</td><td style=\"text-align: right;\">    -0.176996  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.230402</td><td style=\"text-align: right;\">        0.913708</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_999109d8</td><td>TERMINATED</td><td>172.19.2.2:2283</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.486887</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">    -0.105234  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.189337</td><td style=\"text-align: right;\">        0.934382</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_173a2958</td><td>TERMINATED</td><td>172.19.2.2:2320</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.629234</td><td style=\"text-align: right;\">  0.612097</td><td style=\"text-align: right;\">     0.0338389 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.634661</td><td style=\"text-align: right;\">        0.58412 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_dc668998</td><td>TERMINATED</td><td>172.19.2.2:2416</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.630275</td><td style=\"text-align: right;\">  0.639711</td><td style=\"text-align: right;\">     0.0336276 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.639987</td><td style=\"text-align: right;\">        0.563296</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_2b0a330f</td><td>TERMINATED</td><td>172.19.2.2:2499</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.502933</td><td style=\"text-align: right;\">  0.82117 </td><td style=\"text-align: right;\">    -0.13743   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.229812</td><td style=\"text-align: right;\">        0.909663</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_2432548b</td><td>TERMINATED</td><td>172.19.2.2:2574</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.540176</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">    -0.0278853 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.19106 </td><td style=\"text-align: right;\">        0.930936</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_c51dadea</td><td>TERMINATED</td><td>172.19.2.2:2669</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.47192 </td><td style=\"text-align: right;\">  0.81854 </td><td style=\"text-align: right;\">    -0.159739  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.205909</td><td style=\"text-align: right;\">        0.926292</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_c8da1df7</td><td>TERMINATED</td><td>172.19.2.2:2745</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.476397</td><td style=\"text-align: right;\">  0.802761</td><td style=\"text-align: right;\">    -0.171355  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.259048</td><td style=\"text-align: right;\">        0.895431</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_5b7f40f4</td><td>TERMINATED</td><td>172.19.2.2:2836</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.637811</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.124271  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.63772 </td><td style=\"text-align: right;\">        0.560599</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ebee44c4</td><td>TERMINATED</td><td>172.19.2.2:2906</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.554219</td><td style=\"text-align: right;\">  0.811966</td><td style=\"text-align: right;\">    -0.0323519 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.211914</td><td style=\"text-align: right;\">        0.920449</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_aa5f7367</td><td>TERMINATED</td><td>172.19.2.2:2993</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.636066</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0661577 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637838</td><td style=\"text-align: right;\">        0.561049</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_8dd0dbed</td><td>TERMINATED</td><td>172.19.2.2:3074</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.478666</td><td style=\"text-align: right;\">  0.804076</td><td style=\"text-align: right;\">    -0.195514  </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.301688</td><td style=\"text-align: right;\">        0.886891</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_55f77e54</td><td>TERMINATED</td><td>172.19.2.2:3149</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.4635  </td><td style=\"text-align: right;\">  0.785667</td><td style=\"text-align: right;\">    -0.244863  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.361576</td><td style=\"text-align: right;\">        0.838352</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_e02c9976</td><td>TERMINATED</td><td>172.19.2.2:3241</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.487437</td><td style=\"text-align: right;\">  0.792242</td><td style=\"text-align: right;\">    -0.149272  </td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">    0.282258</td><td style=\"text-align: right;\">        0.898127</td><td style=\"text-align: right;\">                     9</td></tr>\n",
       "<tr><td>train_fn_816ed5ce</td><td>TERMINATED</td><td>172.19.2.2:3326</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.444063</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">    -0.253795  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.315789</td><td style=\"text-align: right;\">        0.876404</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_2c1829f1</td><td>TERMINATED</td><td>172.19.2.2:3427</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.644199</td><td style=\"text-align: right;\">  0.598948</td><td style=\"text-align: right;\">     0.0650842 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.659149</td><td style=\"text-align: right;\">        0.574232</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e5f32fd1</td><td>TERMINATED</td><td>172.19.2.2:3502</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.635868</td><td style=\"text-align: right;\">  0.601578</td><td style=\"text-align: right;\">     0.0590353 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.651871</td><td style=\"text-align: right;\">        0.56809 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_22c4fdf2</td><td>TERMINATED</td><td>172.19.2.2:3586</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.480083</td><td style=\"text-align: right;\">  0.82117 </td><td style=\"text-align: right;\">    -0.144521  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.198215</td><td style=\"text-align: right;\">        0.932434</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_991c70d1</td><td>TERMINATED</td><td>172.19.2.2:3661</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.502621</td><td style=\"text-align: right;\">  0.796187</td><td style=\"text-align: right;\">    -0.0842479 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.211844</td><td style=\"text-align: right;\">        0.924045</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_a0f705bc</td><td>TERMINATED</td><td>172.19.2.2:3756</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.477468</td><td style=\"text-align: right;\">  0.796187</td><td style=\"text-align: right;\">    -0.15394   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.25764 </td><td style=\"text-align: right;\">        0.905918</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_6678ae57</td><td>TERMINATED</td><td>172.19.2.2:3831</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.4966  </td><td style=\"text-align: right;\">  0.750164</td><td style=\"text-align: right;\">    -0.215411  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.556525</td><td style=\"text-align: right;\">        0.733783</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_4a758f2d</td><td>TERMINATED</td><td>172.19.2.2:3918</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.634922</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0651237 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637662</td><td style=\"text-align: right;\">        0.561798</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_2f59d9e9</td><td>TERMINATED</td><td>172.19.2.2:3993</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.57537 </td><td style=\"text-align: right;\">  0.725181</td><td style=\"text-align: right;\">    -0.0971697 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.617045</td><td style=\"text-align: right;\">        0.661573</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_cdd21384</td><td>TERMINATED</td><td>172.19.2.2:4075</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.635505</td><td style=\"text-align: right;\">  0.55687 </td><td style=\"text-align: right;\">     0.0809342 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637574</td><td style=\"text-align: right;\">        0.559401</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_47b80e27</td><td>TERMINATED</td><td>172.19.2.2:4150</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.448167</td><td style=\"text-align: right;\">  0.789612</td><td style=\"text-align: right;\">    -0.30982   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.418975</td><td style=\"text-align: right;\">        0.82367 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_419d9af0</td><td>TERMINATED</td><td>172.19.2.2:4235</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.4409  </td><td style=\"text-align: right;\">  0.788297</td><td style=\"text-align: right;\">    -0.315373  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.413125</td><td style=\"text-align: right;\">        0.824569</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_59eb5c92</td><td>TERMINATED</td><td>172.19.2.2:4328</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.531237</td><td style=\"text-align: right;\">  0.739645</td><td style=\"text-align: right;\">    -0.13807   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.595339</td><td style=\"text-align: right;\">        0.663071</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_18cf7192</td><td>TERMINATED</td><td>172.19.2.2:4416</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.669613</td><td style=\"text-align: right;\">  0.57002 </td><td style=\"text-align: right;\">     0.113888  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.675598</td><td style=\"text-align: right;\">        0.547416</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_4580c472</td><td>TERMINATED</td><td>172.19.2.2:4485</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.653633</td><td style=\"text-align: right;\">  0.554241</td><td style=\"text-align: right;\">     0.102333  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.654953</td><td style=\"text-align: right;\">        0.558801</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_5f470107</td><td>TERMINATED</td><td>172.19.2.2:4575</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.683539</td><td style=\"text-align: right;\">  0.55687 </td><td style=\"text-align: right;\">     0.137977  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.697002</td><td style=\"text-align: right;\">        0.547715</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ec7aa763</td><td>TERMINATED</td><td>172.19.2.2:4645</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.528496</td><td style=\"text-align: right;\">  0.810651</td><td style=\"text-align: right;\">    -0.0602255 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.19893 </td><td style=\"text-align: right;\">        0.924944</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_8bb3ace0</td><td>TERMINATED</td><td>172.19.2.2:4734</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.466733</td><td style=\"text-align: right;\">  0.790927</td><td style=\"text-align: right;\">    -0.208349  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.319021</td><td style=\"text-align: right;\">        0.874906</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_3e47b82d</td><td>TERMINATED</td><td>172.19.2.2:4817</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.450019</td><td style=\"text-align: right;\">  0.815911</td><td style=\"text-align: right;\">    -0.248567  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.291444</td><td style=\"text-align: right;\">        0.891985</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_7db4ebdd</td><td>TERMINATED</td><td>172.19.2.2:4909</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.474348</td><td style=\"text-align: right;\">  0.809336</td><td style=\"text-align: right;\">    -0.192295  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.278053</td><td style=\"text-align: right;\">        0.898427</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_62dfcbbc</td><td>TERMINATED</td><td>172.19.2.2:4998</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.495142</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">    -0.15603   </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.277941</td><td style=\"text-align: right;\">        0.896629</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_d971ac72</td><td>TERMINATED</td><td>172.19.2.2:5090</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.701945</td><td style=\"text-align: right;\">  0.571335</td><td style=\"text-align: right;\">     0.141088  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.700116</td><td style=\"text-align: right;\">        0.55221 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_5f426447</td><td>TERMINATED</td><td>172.19.2.2:5179</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.694221</td><td style=\"text-align: right;\">  0.55687 </td><td style=\"text-align: right;\">     0.140902  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.695915</td><td style=\"text-align: right;\">        0.551461</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_9a0326fc</td><td>TERMINATED</td><td>172.19.2.2:5216</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.485331</td><td style=\"text-align: right;\">  0.804076</td><td style=\"text-align: right;\">    -0.166886  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.277161</td><td style=\"text-align: right;\">        0.899625</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_89e0d936</td><td>TERMINATED</td><td>172.19.2.2:5310</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.446909</td><td style=\"text-align: right;\">  0.794872</td><td style=\"text-align: right;\">    -0.291145  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.382446</td><td style=\"text-align: right;\">        0.844045</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_7f0ef638</td><td>TERMINATED</td><td>172.19.2.2:5404</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.471196</td><td style=\"text-align: right;\">  0.790927</td><td style=\"text-align: right;\">    -0.239265  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.369823</td><td style=\"text-align: right;\">        0.850487</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_7a09c8bd</td><td>TERMINATED</td><td>172.19.2.2:5486</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.501229</td><td style=\"text-align: right;\">  0.811966</td><td style=\"text-align: right;\">    -0.114827  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.221039</td><td style=\"text-align: right;\">        0.923596</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_770a5483</td><td>TERMINATED</td><td>172.19.2.2:5579</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.463552</td><td style=\"text-align: right;\">  0.779093</td><td style=\"text-align: right;\">    -0.244421  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.382968</td><td style=\"text-align: right;\">        0.840749</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_7fd08880</td><td>TERMINATED</td><td>172.19.2.2:5661</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.530341</td><td style=\"text-align: right;\">  0.810651</td><td style=\"text-align: right;\">    -0.0673194 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.217454</td><td style=\"text-align: right;\">        0.923745</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_8159bd03</td><td>TERMINATED</td><td>172.19.2.2:5755</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.515073</td><td style=\"text-align: right;\">  0.7357  </td><td style=\"text-align: right;\">    -0.18768   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.562871</td><td style=\"text-align: right;\">        0.717603</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_dc69c8fa</td><td>TERMINATED</td><td>172.19.2.2:5837</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.63082 </td><td style=\"text-align: right;\">  0.634451</td><td style=\"text-align: right;\">     0.0305965 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638457</td><td style=\"text-align: right;\">        0.573633</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_63e14d0d</td><td>TERMINATED</td><td>172.19.2.2:5913</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.634259</td><td style=\"text-align: right;\">  0.554241</td><td style=\"text-align: right;\">     0.0936067 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.643691</td><td style=\"text-align: right;\">        0.571985</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c321fa8a</td><td>TERMINATED</td><td>172.19.2.2:5997</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.47919 </td><td style=\"text-align: right;\">  0.801446</td><td style=\"text-align: right;\">    -0.178239  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.284242</td><td style=\"text-align: right;\">        0.894532</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_f388285a</td><td>TERMINATED</td><td>172.19.2.2:6073</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.457402</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">    -0.230428  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.314616</td><td style=\"text-align: right;\">        0.881948</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_4763c946</td><td>TERMINATED</td><td>172.19.2.2:6178</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.45727 </td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">    -0.261065  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.352121</td><td style=\"text-align: right;\">        0.858577</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_2c6c719b</td><td>TERMINATED</td><td>172.19.2.2:6248</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.562026</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">     0.0241343 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.175391</td><td style=\"text-align: right;\">        0.937978</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_43d1612d</td><td>TERMINATED</td><td>172.19.2.2:6348</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.640074</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0721813 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638166</td><td style=\"text-align: right;\">        0.557154</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_3ba10a93</td><td>TERMINATED</td><td>172.19.2.2:6418</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.638022</td><td style=\"text-align: right;\">  0.55687 </td><td style=\"text-align: right;\">     0.0829796 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638249</td><td style=\"text-align: right;\">        0.5603  </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a1e42247</td><td>TERMINATED</td><td>172.19.2.2:6507</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.66307 </td><td style=\"text-align: right;\">  0.581854</td><td style=\"text-align: right;\">     0.103814  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.636584</td><td style=\"text-align: right;\">        0.563146</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_5eb09f5f</td><td>TERMINATED</td><td>172.19.2.2:6578</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.45106 </td><td style=\"text-align: right;\">  0.792242</td><td style=\"text-align: right;\">    -0.306487  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.413398</td><td style=\"text-align: right;\">        0.82397 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_b9646c33</td><td>TERMINATED</td><td>172.19.2.2:6666</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.657804</td><td style=\"text-align: right;\">  0.583169</td><td style=\"text-align: right;\">     0.0885485 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.670402</td><td style=\"text-align: right;\">        0.56794 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0442d3c2</td><td>TERMINATED</td><td>172.19.2.2:6754</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.633042</td><td style=\"text-align: right;\">  0.608153</td><td style=\"text-align: right;\">     0.0447491 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637942</td><td style=\"text-align: right;\">        0.573333</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_217860ce</td><td>TERMINATED</td><td>172.19.2.2:6791</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.561923</td><td style=\"text-align: right;\">  0.744905</td><td style=\"text-align: right;\">    -0.123994  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.610649</td><td style=\"text-align: right;\">        0.675655</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_de59a64b</td><td>TERMINATED</td><td>172.19.2.2:6883</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.539176</td><td style=\"text-align: right;\">  0.731755</td><td style=\"text-align: right;\">    -0.147986  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.593237</td><td style=\"text-align: right;\">        0.696629</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_7df5a04e</td><td>TERMINATED</td><td>172.19.2.2:6956</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.624103</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">     0.124899  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.154653</td><td style=\"text-align: right;\">        0.948315</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_38378c55</td><td>TERMINATED</td><td>172.19.2.2:7042</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.559653</td><td style=\"text-align: right;\">  0.809336</td><td style=\"text-align: right;\">     0.0278168 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.147226</td><td style=\"text-align: right;\">        0.95191 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_0ac5a327</td><td>TERMINATED</td><td>172.19.2.2:7133</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.470657</td><td style=\"text-align: right;\">  0.822485</td><td style=\"text-align: right;\">    -0.153254  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.184658</td><td style=\"text-align: right;\">        0.933633</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_18d35c95</td><td>TERMINATED</td><td>172.19.2.2:7219</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.456083</td><td style=\"text-align: right;\">  0.796187</td><td style=\"text-align: right;\">    -0.256842  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.35165 </td><td style=\"text-align: right;\">        0.858277</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_733b097b</td><td>TERMINATED</td><td>172.19.2.2:7303</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.450172</td><td style=\"text-align: right;\">  0.796187</td><td style=\"text-align: right;\">    -0.253396  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.33811 </td><td style=\"text-align: right;\">        0.869363</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_0887e04e</td><td>TERMINATED</td><td>172.19.2.2:7390</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.477242</td><td style=\"text-align: right;\">  0.817226</td><td style=\"text-align: right;\">    -0.195936  </td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">    0.272744</td><td style=\"text-align: right;\">        0.900824</td><td style=\"text-align: right;\">                     9</td></tr>\n",
       "<tr><td>train_fn_f66568da</td><td>TERMINATED</td><td>172.19.2.2:7479</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.58287 </td><td style=\"text-align: right;\">  0.827745</td><td style=\"text-align: right;\">     0.00745602</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.184247</td><td style=\"text-align: right;\">        0.933783</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_9e7b9f4e</td><td>TERMINATED</td><td>172.19.2.2:7576</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.636538</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0625822 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637705</td><td style=\"text-align: right;\">        0.568539</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_01963f4a</td><td>TERMINATED</td><td>172.19.2.2:7650</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.453437</td><td style=\"text-align: right;\">  0.801446</td><td style=\"text-align: right;\">    -0.256348  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.33084 </td><td style=\"text-align: right;\">        0.862172</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_a48f7494</td><td>TERMINATED</td><td>172.19.2.2:7733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.635767</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0682151 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637757</td><td style=\"text-align: right;\">        0.556554</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_78ba70c9</td><td>TERMINATED</td><td>172.19.2.2:7821</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.638175</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0698044 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638121</td><td style=\"text-align: right;\">        0.556255</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_199e02cb</td><td>TERMINATED</td><td>172.19.2.2:7857</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.451494</td><td style=\"text-align: right;\">  0.788297</td><td style=\"text-align: right;\">    -0.316402  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.435728</td><td style=\"text-align: right;\">        0.813333</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_e0e7f7f3</td><td>TERMINATED</td><td>172.19.2.2:7952</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.511801</td><td style=\"text-align: right;\">  0.742275</td><td style=\"text-align: right;\">    -0.198472  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.556527</td><td style=\"text-align: right;\">        0.722996</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a2a4272c</td><td>TERMINATED</td><td>172.19.2.2:8040</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.49571 </td><td style=\"text-align: right;\">  0.817226</td><td style=\"text-align: right;\">    -0.142897  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.235705</td><td style=\"text-align: right;\">        0.914457</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_f483c086</td><td>TERMINATED</td><td>172.19.2.2:8076</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.520904</td><td style=\"text-align: right;\">  0.804076</td><td style=\"text-align: right;\">    -0.0751388 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.218963</td><td style=\"text-align: right;\">        0.918202</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_ed8862cd</td><td>TERMINATED</td><td>172.19.2.2:8183</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.459132</td><td style=\"text-align: right;\">  0.797502</td><td style=\"text-align: right;\">    -0.216016  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.303965</td><td style=\"text-align: right;\">        0.887041</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_34d9ee31</td><td>TERMINATED</td><td>172.19.2.2:8249</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.459781</td><td style=\"text-align: right;\">  0.804076</td><td style=\"text-align: right;\">    -0.229835  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.307533</td><td style=\"text-align: right;\">        0.880749</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_b63b2371</td><td>TERMINATED</td><td>172.19.2.2:8358</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.517101</td><td style=\"text-align: right;\">  0.813281</td><td style=\"text-align: right;\">    -0.0870586 </td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">    0.215465</td><td style=\"text-align: right;\">        0.929888</td><td style=\"text-align: right;\">                     9</td></tr>\n",
       "<tr><td>train_fn_dbd75a86</td><td>TERMINATED</td><td>172.19.2.2:8424</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.507598</td><td style=\"text-align: right;\">  0.814596</td><td style=\"text-align: right;\">    -0.097779  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.202955</td><td style=\"text-align: right;\">        0.92839 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_fc12de9b</td><td>TERMINATED</td><td>172.19.2.2:8527</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.618422</td><td style=\"text-align: right;\">  0.64497 </td><td style=\"text-align: right;\">     0.0103791 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.634722</td><td style=\"text-align: right;\">        0.587416</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 07:41:18,453\tINFO worker.py:1753 -- Started a local Ray instance.\n",
      "2024-08-31 07:41:19,708\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-08-31 07:41:19,716\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "[I 2024-08-31 07:41:19,773] A new study created in memory with name: optuna\n",
      "\u001b[36m(train_fn pid=344)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=344)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=379)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=379)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  early_stopping_epoch</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_01963f4a</td><td style=\"text-align: right;\">  0.801446</td><td style=\"text-align: right;\">    -0.256348  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.453437</td><td style=\"text-align: right;\">        0.862172</td><td style=\"text-align: right;\">    0.33084 </td></tr>\n",
       "<tr><td>train_fn_0442d3c2</td><td style=\"text-align: right;\">  0.608153</td><td style=\"text-align: right;\">     0.0447491 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.633042</td><td style=\"text-align: right;\">        0.573333</td><td style=\"text-align: right;\">    0.637942</td></tr>\n",
       "<tr><td>train_fn_0887e04e</td><td style=\"text-align: right;\">  0.817226</td><td style=\"text-align: right;\">    -0.195936  </td><td style=\"text-align: right;\">                     9</td><td style=\"text-align: right;\">0.477242</td><td style=\"text-align: right;\">        0.900824</td><td style=\"text-align: right;\">    0.272744</td></tr>\n",
       "<tr><td>train_fn_0ac5a327</td><td style=\"text-align: right;\">  0.822485</td><td style=\"text-align: right;\">    -0.153254  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.470657</td><td style=\"text-align: right;\">        0.933633</td><td style=\"text-align: right;\">    0.184658</td></tr>\n",
       "<tr><td>train_fn_0da8201b</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.170473  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.682106</td><td style=\"text-align: right;\">        0.560899</td><td style=\"text-align: right;\">    0.685712</td></tr>\n",
       "<tr><td>train_fn_1059f835</td><td style=\"text-align: right;\">  0.798817</td><td style=\"text-align: right;\">    -0.228154  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.460709</td><td style=\"text-align: right;\">        0.876854</td><td style=\"text-align: right;\">    0.318837</td></tr>\n",
       "<tr><td>train_fn_10db737d</td><td style=\"text-align: right;\">  0.811966</td><td style=\"text-align: right;\">    -0.176996  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.4662  </td><td style=\"text-align: right;\">        0.913708</td><td style=\"text-align: right;\">    0.230402</td></tr>\n",
       "<tr><td>train_fn_173a2958</td><td style=\"text-align: right;\">  0.612097</td><td style=\"text-align: right;\">     0.0338389 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.629234</td><td style=\"text-align: right;\">        0.58412 </td><td style=\"text-align: right;\">    0.634661</td></tr>\n",
       "<tr><td>train_fn_18cf7192</td><td style=\"text-align: right;\">  0.57002 </td><td style=\"text-align: right;\">     0.113888  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.669613</td><td style=\"text-align: right;\">        0.547416</td><td style=\"text-align: right;\">    0.675598</td></tr>\n",
       "<tr><td>train_fn_18d35c95</td><td style=\"text-align: right;\">  0.796187</td><td style=\"text-align: right;\">    -0.256842  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.456083</td><td style=\"text-align: right;\">        0.858277</td><td style=\"text-align: right;\">    0.35165 </td></tr>\n",
       "<tr><td>train_fn_199e02cb</td><td style=\"text-align: right;\">  0.788297</td><td style=\"text-align: right;\">    -0.316402  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.451494</td><td style=\"text-align: right;\">        0.813333</td><td style=\"text-align: right;\">    0.435728</td></tr>\n",
       "<tr><td>train_fn_1cf649fe</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.181495  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.694224</td><td style=\"text-align: right;\">        0.558652</td><td style=\"text-align: right;\">    0.690563</td></tr>\n",
       "<tr><td>train_fn_217860ce</td><td style=\"text-align: right;\">  0.744905</td><td style=\"text-align: right;\">    -0.123994  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.561923</td><td style=\"text-align: right;\">        0.675655</td><td style=\"text-align: right;\">    0.610649</td></tr>\n",
       "<tr><td>train_fn_22c4fdf2</td><td style=\"text-align: right;\">  0.82117 </td><td style=\"text-align: right;\">    -0.144521  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.480083</td><td style=\"text-align: right;\">        0.932434</td><td style=\"text-align: right;\">    0.198215</td></tr>\n",
       "<tr><td>train_fn_2432548b</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">    -0.0278853 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.540176</td><td style=\"text-align: right;\">        0.930936</td><td style=\"text-align: right;\">    0.19106 </td></tr>\n",
       "<tr><td>train_fn_2b0a330f</td><td style=\"text-align: right;\">  0.82117 </td><td style=\"text-align: right;\">    -0.13743   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.502933</td><td style=\"text-align: right;\">        0.909663</td><td style=\"text-align: right;\">    0.229812</td></tr>\n",
       "<tr><td>train_fn_2c1829f1</td><td style=\"text-align: right;\">  0.598948</td><td style=\"text-align: right;\">     0.0650842 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.644199</td><td style=\"text-align: right;\">        0.574232</td><td style=\"text-align: right;\">    0.659149</td></tr>\n",
       "<tr><td>train_fn_2c6c719b</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">     0.0241343 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.562026</td><td style=\"text-align: right;\">        0.937978</td><td style=\"text-align: right;\">    0.175391</td></tr>\n",
       "<tr><td>train_fn_2f59d9e9</td><td style=\"text-align: right;\">  0.725181</td><td style=\"text-align: right;\">    -0.0971697 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.57537 </td><td style=\"text-align: right;\">        0.661573</td><td style=\"text-align: right;\">    0.617045</td></tr>\n",
       "<tr><td>train_fn_34d9ee31</td><td style=\"text-align: right;\">  0.804076</td><td style=\"text-align: right;\">    -0.229835  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.459781</td><td style=\"text-align: right;\">        0.880749</td><td style=\"text-align: right;\">    0.307533</td></tr>\n",
       "<tr><td>train_fn_38378c55</td><td style=\"text-align: right;\">  0.809336</td><td style=\"text-align: right;\">     0.0278168 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.559653</td><td style=\"text-align: right;\">        0.95191 </td><td style=\"text-align: right;\">    0.147226</td></tr>\n",
       "<tr><td>train_fn_3ba10a93</td><td style=\"text-align: right;\">  0.55687 </td><td style=\"text-align: right;\">     0.0829796 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.638022</td><td style=\"text-align: right;\">        0.5603  </td><td style=\"text-align: right;\">    0.638249</td></tr>\n",
       "<tr><td>train_fn_3ca1806f</td><td style=\"text-align: right;\">  0.779093</td><td style=\"text-align: right;\">    -0.276644  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.470322</td><td style=\"text-align: right;\">        0.815431</td><td style=\"text-align: right;\">    0.442407</td></tr>\n",
       "<tr><td>train_fn_3e47b82d</td><td style=\"text-align: right;\">  0.815911</td><td style=\"text-align: right;\">    -0.248567  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.450019</td><td style=\"text-align: right;\">        0.891985</td><td style=\"text-align: right;\">    0.291444</td></tr>\n",
       "<tr><td>train_fn_3ea8855f</td><td style=\"text-align: right;\">  0.761999</td><td style=\"text-align: right;\">     0.108354  </td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.649704</td><td style=\"text-align: right;\">        0.873708</td><td style=\"text-align: right;\">    0.320115</td></tr>\n",
       "<tr><td>train_fn_419d9af0</td><td style=\"text-align: right;\">  0.788297</td><td style=\"text-align: right;\">    -0.315373  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.4409  </td><td style=\"text-align: right;\">        0.824569</td><td style=\"text-align: right;\">    0.413125</td></tr>\n",
       "<tr><td>train_fn_43d1612d</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0721813 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.640074</td><td style=\"text-align: right;\">        0.557154</td><td style=\"text-align: right;\">    0.638166</td></tr>\n",
       "<tr><td>train_fn_4580c472</td><td style=\"text-align: right;\">  0.554241</td><td style=\"text-align: right;\">     0.102333  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.653633</td><td style=\"text-align: right;\">        0.558801</td><td style=\"text-align: right;\">    0.654953</td></tr>\n",
       "<tr><td>train_fn_46d5fbf6</td><td style=\"text-align: right;\">  0.673899</td><td style=\"text-align: right;\">     0.00352101</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.626652</td><td style=\"text-align: right;\">        0.581273</td><td style=\"text-align: right;\">    0.635562</td></tr>\n",
       "<tr><td>train_fn_4763c946</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">    -0.261065  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.45727 </td><td style=\"text-align: right;\">        0.858577</td><td style=\"text-align: right;\">    0.352121</td></tr>\n",
       "<tr><td>train_fn_47b80e27</td><td style=\"text-align: right;\">  0.789612</td><td style=\"text-align: right;\">    -0.30982   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.448167</td><td style=\"text-align: right;\">        0.82367 </td><td style=\"text-align: right;\">    0.418975</td></tr>\n",
       "<tr><td>train_fn_4a758f2d</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0651237 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.634922</td><td style=\"text-align: right;\">        0.561798</td><td style=\"text-align: right;\">    0.637662</td></tr>\n",
       "<tr><td>train_fn_52314554</td><td style=\"text-align: right;\">  0.768573</td><td style=\"text-align: right;\">    -0.276896  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.472242</td><td style=\"text-align: right;\">        0.798652</td><td style=\"text-align: right;\">    0.463451</td></tr>\n",
       "<tr><td>train_fn_5503f487</td><td style=\"text-align: right;\">  0.593688</td><td style=\"text-align: right;\">     0.0682357 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637068</td><td style=\"text-align: right;\">        0.559101</td><td style=\"text-align: right;\">    0.652193</td></tr>\n",
       "<tr><td>train_fn_55f77e54</td><td style=\"text-align: right;\">  0.785667</td><td style=\"text-align: right;\">    -0.244863  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.4635  </td><td style=\"text-align: right;\">        0.838352</td><td style=\"text-align: right;\">    0.361576</td></tr>\n",
       "<tr><td>train_fn_569efa17</td><td style=\"text-align: right;\">  0.788297</td><td style=\"text-align: right;\">    -0.217487  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.465627</td><td style=\"text-align: right;\">        0.868464</td><td style=\"text-align: right;\">    0.335427</td></tr>\n",
       "<tr><td>train_fn_59eb5c92</td><td style=\"text-align: right;\">  0.739645</td><td style=\"text-align: right;\">    -0.13807   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.531237</td><td style=\"text-align: right;\">        0.663071</td><td style=\"text-align: right;\">    0.595339</td></tr>\n",
       "<tr><td>train_fn_5b7f40f4</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.124271  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637811</td><td style=\"text-align: right;\">        0.560599</td><td style=\"text-align: right;\">    0.63772 </td></tr>\n",
       "<tr><td>train_fn_5bd7c5aa</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">    -0.20435   </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.464594</td><td style=\"text-align: right;\">        0.891685</td><td style=\"text-align: right;\">    0.293772</td></tr>\n",
       "<tr><td>train_fn_5eb09f5f</td><td style=\"text-align: right;\">  0.792242</td><td style=\"text-align: right;\">    -0.306487  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.45106 </td><td style=\"text-align: right;\">        0.82397 </td><td style=\"text-align: right;\">    0.413398</td></tr>\n",
       "<tr><td>train_fn_5f426447</td><td style=\"text-align: right;\">  0.55687 </td><td style=\"text-align: right;\">     0.140902  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.694221</td><td style=\"text-align: right;\">        0.551461</td><td style=\"text-align: right;\">    0.695915</td></tr>\n",
       "<tr><td>train_fn_5f470107</td><td style=\"text-align: right;\">  0.55687 </td><td style=\"text-align: right;\">     0.137977  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.683539</td><td style=\"text-align: right;\">        0.547715</td><td style=\"text-align: right;\">    0.697002</td></tr>\n",
       "<tr><td>train_fn_62dfcbbc</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">    -0.15603   </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.495142</td><td style=\"text-align: right;\">        0.896629</td><td style=\"text-align: right;\">    0.277941</td></tr>\n",
       "<tr><td>train_fn_63e14d0d</td><td style=\"text-align: right;\">  0.554241</td><td style=\"text-align: right;\">     0.0936067 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.634259</td><td style=\"text-align: right;\">        0.571985</td><td style=\"text-align: right;\">    0.643691</td></tr>\n",
       "<tr><td>train_fn_6678ae57</td><td style=\"text-align: right;\">  0.750164</td><td style=\"text-align: right;\">    -0.215411  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.4966  </td><td style=\"text-align: right;\">        0.733783</td><td style=\"text-align: right;\">    0.556525</td></tr>\n",
       "<tr><td>train_fn_72c017f5</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.179058  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.692639</td><td style=\"text-align: right;\">        0.56015 </td><td style=\"text-align: right;\">    0.693098</td></tr>\n",
       "<tr><td>train_fn_733b097b</td><td style=\"text-align: right;\">  0.796187</td><td style=\"text-align: right;\">    -0.253396  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.450172</td><td style=\"text-align: right;\">        0.869363</td><td style=\"text-align: right;\">    0.33811 </td></tr>\n",
       "<tr><td>train_fn_770a5483</td><td style=\"text-align: right;\">  0.779093</td><td style=\"text-align: right;\">    -0.244421  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.463552</td><td style=\"text-align: right;\">        0.840749</td><td style=\"text-align: right;\">    0.382968</td></tr>\n",
       "<tr><td>train_fn_78ba70c9</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0698044 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.638175</td><td style=\"text-align: right;\">        0.556255</td><td style=\"text-align: right;\">    0.638121</td></tr>\n",
       "<tr><td>train_fn_7a09c8bd</td><td style=\"text-align: right;\">  0.811966</td><td style=\"text-align: right;\">    -0.114827  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.501229</td><td style=\"text-align: right;\">        0.923596</td><td style=\"text-align: right;\">    0.221039</td></tr>\n",
       "<tr><td>train_fn_7bf5c7fc</td><td style=\"text-align: right;\">  0.814596</td><td style=\"text-align: right;\">    -0.161026  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.488576</td><td style=\"text-align: right;\">        0.908015</td><td style=\"text-align: right;\">    0.252008</td></tr>\n",
       "<tr><td>train_fn_7db4ebdd</td><td style=\"text-align: right;\">  0.809336</td><td style=\"text-align: right;\">    -0.192295  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.474348</td><td style=\"text-align: right;\">        0.898427</td><td style=\"text-align: right;\">    0.278053</td></tr>\n",
       "<tr><td>train_fn_7df5a04e</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">     0.124899  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.624103</td><td style=\"text-align: right;\">        0.948315</td><td style=\"text-align: right;\">    0.154653</td></tr>\n",
       "<tr><td>train_fn_7f0ef638</td><td style=\"text-align: right;\">  0.790927</td><td style=\"text-align: right;\">    -0.239265  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.471196</td><td style=\"text-align: right;\">        0.850487</td><td style=\"text-align: right;\">    0.369823</td></tr>\n",
       "<tr><td>train_fn_7fd08880</td><td style=\"text-align: right;\">  0.810651</td><td style=\"text-align: right;\">    -0.0673194 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.530341</td><td style=\"text-align: right;\">        0.923745</td><td style=\"text-align: right;\">    0.217454</td></tr>\n",
       "<tr><td>train_fn_8159bd03</td><td style=\"text-align: right;\">  0.7357  </td><td style=\"text-align: right;\">    -0.18768   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.515073</td><td style=\"text-align: right;\">        0.717603</td><td style=\"text-align: right;\">    0.562871</td></tr>\n",
       "<tr><td>train_fn_816ed5ce</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">    -0.253795  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.444063</td><td style=\"text-align: right;\">        0.876404</td><td style=\"text-align: right;\">    0.315789</td></tr>\n",
       "<tr><td>train_fn_85b8262b</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.173431  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.687599</td><td style=\"text-align: right;\">        0.552959</td><td style=\"text-align: right;\">    0.694075</td></tr>\n",
       "<tr><td>train_fn_89d8f842</td><td style=\"text-align: right;\">  0.813281</td><td style=\"text-align: right;\">    -0.0919782 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.528696</td><td style=\"text-align: right;\">        0.915506</td><td style=\"text-align: right;\">    0.245708</td></tr>\n",
       "<tr><td>train_fn_89e0d936</td><td style=\"text-align: right;\">  0.794872</td><td style=\"text-align: right;\">    -0.291145  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.446909</td><td style=\"text-align: right;\">        0.844045</td><td style=\"text-align: right;\">    0.382446</td></tr>\n",
       "<tr><td>train_fn_8bb3ace0</td><td style=\"text-align: right;\">  0.790927</td><td style=\"text-align: right;\">    -0.208349  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.466733</td><td style=\"text-align: right;\">        0.874906</td><td style=\"text-align: right;\">    0.319021</td></tr>\n",
       "<tr><td>train_fn_8dd0dbed</td><td style=\"text-align: right;\">  0.804076</td><td style=\"text-align: right;\">    -0.195514  </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.478666</td><td style=\"text-align: right;\">        0.886891</td><td style=\"text-align: right;\">    0.301688</td></tr>\n",
       "<tr><td>train_fn_967f3bb2</td><td style=\"text-align: right;\">  0.551611</td><td style=\"text-align: right;\">     0.168778  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.718498</td><td style=\"text-align: right;\">        0.549213</td><td style=\"text-align: right;\">    0.719882</td></tr>\n",
       "<tr><td>train_fn_974210f1</td><td style=\"text-align: right;\">  0.822485</td><td style=\"text-align: right;\">    -0.175918  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.47413 </td><td style=\"text-align: right;\">        0.920449</td><td style=\"text-align: right;\">    0.227222</td></tr>\n",
       "<tr><td>train_fn_97ff9c84</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">    -0.213391  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.457657</td><td style=\"text-align: right;\">        0.898577</td><td style=\"text-align: right;\">    0.282156</td></tr>\n",
       "<tr><td>train_fn_991c70d1</td><td style=\"text-align: right;\">  0.796187</td><td style=\"text-align: right;\">    -0.0842479 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.502621</td><td style=\"text-align: right;\">        0.924045</td><td style=\"text-align: right;\">    0.211844</td></tr>\n",
       "<tr><td>train_fn_999109d8</td><td style=\"text-align: right;\">  0.805391</td><td style=\"text-align: right;\">    -0.105234  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.486887</td><td style=\"text-align: right;\">        0.934382</td><td style=\"text-align: right;\">    0.189337</td></tr>\n",
       "<tr><td>train_fn_9a0326fc</td><td style=\"text-align: right;\">  0.804076</td><td style=\"text-align: right;\">    -0.166886  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.485331</td><td style=\"text-align: right;\">        0.899625</td><td style=\"text-align: right;\">    0.277161</td></tr>\n",
       "<tr><td>train_fn_9e7b9f4e</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0625822 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636538</td><td style=\"text-align: right;\">        0.568539</td><td style=\"text-align: right;\">    0.637705</td></tr>\n",
       "<tr><td>train_fn_a0f705bc</td><td style=\"text-align: right;\">  0.796187</td><td style=\"text-align: right;\">    -0.15394   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.477468</td><td style=\"text-align: right;\">        0.905918</td><td style=\"text-align: right;\">    0.25764 </td></tr>\n",
       "<tr><td>train_fn_a1e42247</td><td style=\"text-align: right;\">  0.581854</td><td style=\"text-align: right;\">     0.103814  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.66307 </td><td style=\"text-align: right;\">        0.563146</td><td style=\"text-align: right;\">    0.636584</td></tr>\n",
       "<tr><td>train_fn_a2a4272c</td><td style=\"text-align: right;\">  0.817226</td><td style=\"text-align: right;\">    -0.142897  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.49571 </td><td style=\"text-align: right;\">        0.914457</td><td style=\"text-align: right;\">    0.235705</td></tr>\n",
       "<tr><td>train_fn_a48f7494</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0682151 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.635767</td><td style=\"text-align: right;\">        0.556554</td><td style=\"text-align: right;\">    0.637757</td></tr>\n",
       "<tr><td>train_fn_aa5f7367</td><td style=\"text-align: right;\">  0.580539</td><td style=\"text-align: right;\">     0.0661577 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636066</td><td style=\"text-align: right;\">        0.561049</td><td style=\"text-align: right;\">    0.637838</td></tr>\n",
       "<tr><td>train_fn_aaee3ede</td><td style=\"text-align: right;\">  0.771203</td><td style=\"text-align: right;\">    -0.279323  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.464937</td><td style=\"text-align: right;\">        0.806442</td><td style=\"text-align: right;\">    0.44629 </td></tr>\n",
       "<tr><td>train_fn_b63b2371</td><td style=\"text-align: right;\">  0.813281</td><td style=\"text-align: right;\">    -0.0870586 </td><td style=\"text-align: right;\">                     9</td><td style=\"text-align: right;\">0.517101</td><td style=\"text-align: right;\">        0.929888</td><td style=\"text-align: right;\">    0.215465</td></tr>\n",
       "<tr><td>train_fn_b9646c33</td><td style=\"text-align: right;\">  0.583169</td><td style=\"text-align: right;\">     0.0885485 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.657804</td><td style=\"text-align: right;\">        0.56794 </td><td style=\"text-align: right;\">    0.670402</td></tr>\n",
       "<tr><td>train_fn_c321fa8a</td><td style=\"text-align: right;\">  0.801446</td><td style=\"text-align: right;\">    -0.178239  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.47919 </td><td style=\"text-align: right;\">        0.894532</td><td style=\"text-align: right;\">    0.284242</td></tr>\n",
       "<tr><td>train_fn_c51dadea</td><td style=\"text-align: right;\">  0.81854 </td><td style=\"text-align: right;\">    -0.159739  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.47192 </td><td style=\"text-align: right;\">        0.926292</td><td style=\"text-align: right;\">    0.205909</td></tr>\n",
       "<tr><td>train_fn_c8da1df7</td><td style=\"text-align: right;\">  0.802761</td><td style=\"text-align: right;\">    -0.171355  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.476397</td><td style=\"text-align: right;\">        0.895431</td><td style=\"text-align: right;\">    0.259048</td></tr>\n",
       "<tr><td>train_fn_cdd21384</td><td style=\"text-align: right;\">  0.55687 </td><td style=\"text-align: right;\">     0.0809342 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.635505</td><td style=\"text-align: right;\">        0.559401</td><td style=\"text-align: right;\">    0.637574</td></tr>\n",
       "<tr><td>train_fn_d971ac72</td><td style=\"text-align: right;\">  0.571335</td><td style=\"text-align: right;\">     0.141088  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.701945</td><td style=\"text-align: right;\">        0.55221 </td><td style=\"text-align: right;\">    0.700116</td></tr>\n",
       "<tr><td>train_fn_dbd75a86</td><td style=\"text-align: right;\">  0.814596</td><td style=\"text-align: right;\">    -0.097779  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.507598</td><td style=\"text-align: right;\">        0.92839 </td><td style=\"text-align: right;\">    0.202955</td></tr>\n",
       "<tr><td>train_fn_dc668998</td><td style=\"text-align: right;\">  0.639711</td><td style=\"text-align: right;\">     0.0336276 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.630275</td><td style=\"text-align: right;\">        0.563296</td><td style=\"text-align: right;\">    0.639987</td></tr>\n",
       "<tr><td>train_fn_dc69c8fa</td><td style=\"text-align: right;\">  0.634451</td><td style=\"text-align: right;\">     0.0305965 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.63082 </td><td style=\"text-align: right;\">        0.573633</td><td style=\"text-align: right;\">    0.638457</td></tr>\n",
       "<tr><td>train_fn_de59a64b</td><td style=\"text-align: right;\">  0.731755</td><td style=\"text-align: right;\">    -0.147986  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.539176</td><td style=\"text-align: right;\">        0.696629</td><td style=\"text-align: right;\">    0.593237</td></tr>\n",
       "<tr><td>train_fn_e02c9976</td><td style=\"text-align: right;\">  0.792242</td><td style=\"text-align: right;\">    -0.149272  </td><td style=\"text-align: right;\">                     9</td><td style=\"text-align: right;\">0.487437</td><td style=\"text-align: right;\">        0.898127</td><td style=\"text-align: right;\">    0.282258</td></tr>\n",
       "<tr><td>train_fn_e0e7f7f3</td><td style=\"text-align: right;\">  0.742275</td><td style=\"text-align: right;\">    -0.198472  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.511801</td><td style=\"text-align: right;\">        0.722996</td><td style=\"text-align: right;\">    0.556527</td></tr>\n",
       "<tr><td>train_fn_e5f32fd1</td><td style=\"text-align: right;\">  0.601578</td><td style=\"text-align: right;\">     0.0590353 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.635868</td><td style=\"text-align: right;\">        0.56809 </td><td style=\"text-align: right;\">    0.651871</td></tr>\n",
       "<tr><td>train_fn_e62ac370</td><td style=\"text-align: right;\">  0.529257</td><td style=\"text-align: right;\">     0.125946  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.63987 </td><td style=\"text-align: right;\">        0.557603</td><td style=\"text-align: right;\">    0.637551</td></tr>\n",
       "<tr><td>train_fn_ebee44c4</td><td style=\"text-align: right;\">  0.811966</td><td style=\"text-align: right;\">    -0.0323519 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.554219</td><td style=\"text-align: right;\">        0.920449</td><td style=\"text-align: right;\">    0.211914</td></tr>\n",
       "<tr><td>train_fn_ec7aa763</td><td style=\"text-align: right;\">  0.810651</td><td style=\"text-align: right;\">    -0.0602255 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.528496</td><td style=\"text-align: right;\">        0.924944</td><td style=\"text-align: right;\">    0.19893 </td></tr>\n",
       "<tr><td>train_fn_ed8862cd</td><td style=\"text-align: right;\">  0.797502</td><td style=\"text-align: right;\">    -0.216016  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.459132</td><td style=\"text-align: right;\">        0.887041</td><td style=\"text-align: right;\">    0.303965</td></tr>\n",
       "<tr><td>train_fn_f12c2024</td><td style=\"text-align: right;\">  0.788297</td><td style=\"text-align: right;\">    -0.310942  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.451977</td><td style=\"text-align: right;\">        0.819476</td><td style=\"text-align: right;\">    0.432399</td></tr>\n",
       "<tr><td>train_fn_f152234b</td><td style=\"text-align: right;\">  0.801446</td><td style=\"text-align: right;\">    -0.209418  </td><td style=\"text-align: right;\">                    12</td><td style=\"text-align: right;\">0.469539</td><td style=\"text-align: right;\">        0.881498</td><td style=\"text-align: right;\">    0.304611</td></tr>\n",
       "<tr><td>train_fn_f388285a</td><td style=\"text-align: right;\">  0.800131</td><td style=\"text-align: right;\">    -0.230428  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.457402</td><td style=\"text-align: right;\">        0.881948</td><td style=\"text-align: right;\">    0.314616</td></tr>\n",
       "<tr><td>train_fn_f483c086</td><td style=\"text-align: right;\">  0.804076</td><td style=\"text-align: right;\">    -0.0751388 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.520904</td><td style=\"text-align: right;\">        0.918202</td><td style=\"text-align: right;\">    0.218963</td></tr>\n",
       "<tr><td>train_fn_f545ee5d</td><td style=\"text-align: right;\">  0.793557</td><td style=\"text-align: right;\">    -0.301898  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.43877 </td><td style=\"text-align: right;\">        0.842397</td><td style=\"text-align: right;\">    0.381833</td></tr>\n",
       "<tr><td>train_fn_f66568da</td><td style=\"text-align: right;\">  0.827745</td><td style=\"text-align: right;\">     0.00745602</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.58287 </td><td style=\"text-align: right;\">        0.933783</td><td style=\"text-align: right;\">    0.184247</td></tr>\n",
       "<tr><td>train_fn_fc12de9b</td><td style=\"text-align: right;\">  0.64497 </td><td style=\"text-align: right;\">     0.0103791 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.618422</td><td style=\"text-align: right;\">        0.587416</td><td style=\"text-align: right;\">    0.634722</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_fn pid=483)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=483)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=585)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=585)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=658)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=658)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=744)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=744)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=818)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=818)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=902)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=902)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=976)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=976)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1070)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1070)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1143)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1143)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1232)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1232)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1321)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1321)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1412)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1412)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1497)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1497)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1583)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1583)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1670)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1670)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1744)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1744)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1837)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1837)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1921)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1921)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2008)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2008)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2102)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2102)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2184)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2184)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2283)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2283)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2320)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2320)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2416)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2416)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2499)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2499)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2574)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2574)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2669)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2669)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2745)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2745)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2836)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2836)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2906)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2906)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2993)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2993)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3074)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3074)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3149)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3149)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3241)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3241)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3326)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3326)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3427)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3427)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3502)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3502)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3586)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3586)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3661)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3661)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3756)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3756)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3831)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3831)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3918)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3918)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3993)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3993)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4075)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4075)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4150)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4150)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4235)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4235)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4328)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4328)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4416)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4416)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4485)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4485)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4575)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4575)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4645)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4645)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4734)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4734)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4817)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4817)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4909)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4909)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4998)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4998)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5090)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5090)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5179)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5179)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5216)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5216)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5310)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5310)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5404)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5404)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5486)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5486)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5579)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5579)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5661)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5661)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5755)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5755)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5837)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5837)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5913)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5913)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5997)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5997)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6073)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6073)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6178)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6178)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6248)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6248)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6348)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6348)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6418)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6418)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6507)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6507)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6578)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6578)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6666)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6666)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6754)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6754)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6791)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6791)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6883)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6883)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6956)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6956)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7042)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7042)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7133)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7133)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7219)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7219)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7303)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7303)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7390)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7390)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7479)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7479)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7576)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7576)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7650)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7650)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7733)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7733)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7821)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7857)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7857)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7952)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7952)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8040)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8040)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8076)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8076)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8183)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8183)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8249)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8249)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8358)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8358)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8424)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8424)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8527)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8527)\u001b[0m   warnings.warn(\n",
      "2024-08-31 11:23:58,726\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_fn_2024-08-31_07-41-19' in 0.0437s.\n",
      "2024-08-31 11:23:58,779\tINFO tune.py:1041 -- Total run time: 13359.06 seconds (13346.77 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /kaggle/working/tensorboard_logs\n",
    "\n",
    "\n",
    "# ray.init(ignore_reinit_error=True)\n",
    "# reporter = CLIReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "#     print_intermediate_tables=False\n",
    "# )\n",
    "\n",
    "reporter = JupyterNotebookReporter(\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "    print_intermediate_tables=False\n",
    ")\n",
    "\n",
    "# tuner = tune.run(\n",
    "#     train_fn,\n",
    "#     config=search_space,\n",
    "#     num_samples=25,\n",
    "#     progress_reporter=reporter,\n",
    "#     resources_per_trial={\"cpu\": 4, \"gpu\": 2},  # Adjust resources as needed\n",
    "#     scheduler=ASHAScheduler(\n",
    "#         metric=\"accuracy\",\n",
    "#         mode=\"max\",\n",
    "#         max_t=15,\n",
    "#         grace_period=1,\n",
    "#         reduction_factor=2\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# reporter = TensorBoardReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"training_iteration\", \"train_loss\", \"train_accuracy\"]\n",
    "# )\n",
    "\n",
    "\n",
    "result = tune.run(\n",
    "    train_fn,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "    config=search_space,\n",
    "    num_samples=100,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    search_alg=optuna_search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3379c8",
   "metadata": {
    "papermill": {
     "duration": 0.040271,
     "end_time": "2024-08-31T11:23:59.070872",
     "exception": false,
     "start_time": "2024-08-31T11:23:59.030601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfda11ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:23:59.153414Z",
     "iopub.status.busy": "2024-08-31T11:23:59.152177Z",
     "iopub.status.idle": "2024-08-31T11:23:59.160615Z",
     "shell.execute_reply": "2024-08-31T11:23:59.159765Z"
    },
    "papermill": {
     "duration": 0.051176,
     "end_time": "2024-08-31T11:23:59.162531",
     "exception": false,
     "start_time": "2024-08-31T11:23:59.111355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'dropout_rate': 0.4, 'batch_size': 64, 'weight_decay': 5e-05, 'lr': 0.0001, 'epochs': 20}\n",
      "Best trial final validation loss: 0.5828703716397285\n",
      "Best trial final validation accuracy: 0.8277449046679816\n",
      "Best trial final training loss: 0.18424713632890155\n",
      "Best trial final training accuracy: 0.9337827715355805\n",
      "Best trial final custom_metric: 0.007456018060959968\n",
      "Best trial final Early Stopping Epoch: 6\n"
     ]
    }
   ],
   "source": [
    "# best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "# best_checkpoint_dir = best_trial.checkpoint.value\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
    "print(f\"Best trial final training loss: {best_trial.last_result['train_loss']}\")\n",
    "print(f\"Best trial final training accuracy: {best_trial.last_result['train_accuracy']}\")\n",
    "print(f\"Best trial final custom_metric: {best_trial.last_result['custom_metric']}\")\n",
    "print(f\"Best trial final Early Stopping Epoch: {best_trial.last_result['early_stopping_epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274a3df",
   "metadata": {
    "papermill": {
     "duration": 0.039777,
     "end_time": "2024-08-31T11:23:59.242008",
     "exception": false,
     "start_time": "2024-08-31T11:23:59.202231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Train the Model with the Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c470b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:23:59.323913Z",
     "iopub.status.busy": "2024-08-31T11:23:59.323571Z",
     "iopub.status.idle": "2024-08-31T11:23:59.349810Z",
     "shell.execute_reply": "2024-08-31T11:23:59.348942Z"
    },
    "papermill": {
     "duration": 0.069352,
     "end_time": "2024-08-31T11:23:59.351670",
     "exception": false,
     "start_time": "2024-08-31T11:23:59.282318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_best_model(config, device, train_dataset = train_ds_pd, val_dataset = validation_ds_pd):\n",
    "    print(f\"\"\"\n",
    "    Tuning Model with:\n",
    "    {config}\n",
    "    \"\"\")\n",
    "#     model = SentimentModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=3,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    model = SentimentModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     class_weights_tmp = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights_tmp)\n",
    "#     criterion = nn.BCELoss()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    ## DATASET ENCODING\n",
    "    \n",
    "    train_dataset = SentimentDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = SentimentDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = None\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    \n",
    "    ### Running for config epochs +patience+1 for introducing noise. \n",
    "    \n",
    "    for epoch in range((config[\"epochs\"]+patience+1)):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = torch.zeros_like(probabilities)\n",
    "            max_indices = torch.argmax(probabilities, dim=1)\n",
    "            predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "            predictions = predictions.float()\n",
    "                \n",
    "#                 loss = criterion(predictions, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "#             outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "#             predicted_labels = (outputs > 0.5).float()\n",
    "#             correct_train_preds += (predicted_labels == labels).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "            correct_train_preds += (predictions == labels).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = torch.zeros_like(probabilities)\n",
    "                max_indices = torch.argmax(probabilities, dim=1)\n",
    "                predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "                predictions = predictions.float()\n",
    "\n",
    "#                     loss = criterion(predictions, labels)\n",
    "                \n",
    "#                 outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "    \n",
    "#                 predicted_labels = (outputs > 0.5).float()\n",
    "#                 correct_val_preds += (predicted_labels == labels).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "                correct_val_preds += (predictions == labels).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "        checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "#         # Save the best model based on validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "#             best_model_path = checkpoint_path\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_since_improvement = 0\n",
    "            best_model_path = checkpoint_path\n",
    "            # Save the model checkpoint with the best validation loss\n",
    "#             checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#             torch.save(model.state_dict(), checkpoint_path)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'config': config  # Save configuration\n",
    "            }, checkpoint_path)\n",
    "    \n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            print(f\"Best Model Epoch Saved: {epoch - patience +1}\")\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "#         if epochs_since_improvement >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "#             print(f\"Best Model Epoch Saved: {epoch - patience}\")\n",
    "#             break\n",
    "            \n",
    "#         custom_metric = calculate_custom_metric(avg_val_loss, avg_train_loss)        \n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "        print(f\"\"\"\n",
    "        Validation Loss: {avg_val_loss},\n",
    "        Training Loss: {avg_train_loss},\n",
    "        Argmax Binary Validation Accuracy: {val_accuracy},\n",
    "        Argmax Binary Training Accuracy: {train_accuracy},\n",
    "        Custom Metric: {custom_metric},\n",
    "        Epochs: {epoch+1}\n",
    "        \"\"\")\n",
    "    \n",
    "    print(f\"Best Validation Loss: {best_val_loss}, Best Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de15c3",
   "metadata": {
    "papermill": {
     "duration": 0.040701,
     "end_time": "2024-08-31T11:23:59.432326",
     "exception": false,
     "start_time": "2024-08-31T11:23:59.391625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BEST MODEL AFTER FINAL TRAINING & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdfc75ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:23:59.516593Z",
     "iopub.status.busy": "2024-08-31T11:23:59.516232Z",
     "iopub.status.idle": "2024-08-31T11:31:15.164173Z",
     "shell.execute_reply": "2024-08-31T11:31:15.163160Z"
    },
    "papermill": {
     "duration": 435.738311,
     "end_time": "2024-08-31T11:31:15.211542",
     "exception": false,
     "start_time": "2024-08-31T11:23:59.473231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Tuning Model with:\n",
      "    {'dropout_rate': 0.4, 'batch_size': 64, 'weight_decay': 5e-05, 'lr': 0.0001, 'epochs': 20}\n",
      "    \n",
      "\n",
      "        Validation Loss: 0.635015994310379,\n",
      "        Training Loss: 0.6355250086103167,\n",
      "        Argmax Binary Validation Accuracy: 0.6015779092702169,\n",
      "        Argmax Binary Training Accuracy: 0.5943071161048689,\n",
      "        Custom Metric: 0.037327988772804965,\n",
      "        Epochs: 1\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.5271183215081692,\n",
      "        Training Loss: 0.5962147167750768,\n",
      "        Argmax Binary Validation Accuracy: 0.7357001972386588,\n",
      "        Argmax Binary Training Accuracy: 0.6404494382022472,\n",
      "        Custom Metric: -0.12640829857883001,\n",
      "        Epochs: 2\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.48824916407465935,\n",
      "        Training Loss: 0.4909138709306717,\n",
      "        Argmax Binary Validation Accuracy: 0.7646285338593031,\n",
      "        Argmax Binary Training Accuracy: 0.7638951310861424,\n",
      "        Custom Metric: -0.2746803149700572,\n",
      "        Epochs: 3\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.4763871058821678,\n",
      "        Training Loss: 0.4187149499143873,\n",
      "        Argmax Binary Validation Accuracy: 0.7961867192636424,\n",
      "        Argmax Binary Training Accuracy: 0.8088389513108615,\n",
      "        Custom Metric: -0.28463741937397474,\n",
      "        Epochs: 4\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.5500625856220722,\n",
      "        Training Loss: 0.36182561346462794,\n",
      "        Argmax Binary Validation Accuracy: 0.7488494411571335,\n",
      "        Argmax Binary Training Accuracy: 0.8542322097378278,\n",
      "        Custom Metric: -0.051976985165991973,\n",
      "        Epochs: 5\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.5595715045928955,\n",
      "        Training Loss: 0.35883152144295827,\n",
      "        Argmax Binary Validation Accuracy: 0.7422748191978962,\n",
      "        Argmax Binary Training Accuracy: 0.8527340823970038,\n",
      "        Custom Metric: -0.02710369143047825,\n",
      "        Epochs: 6\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.4800875335931778,\n",
      "        Training Loss: 0.2718058681913785,\n",
      "        Argmax Binary Validation Accuracy: 0.8027613412228797,\n",
      "        Argmax Binary Training Accuracy: 0.8993258426966292,\n",
      "        Custom Metric: -0.17025072419192747,\n",
      "        Epochs: 7\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.5361796729266644,\n",
      "        Training Loss: 0.20775313866989953,\n",
      "        Argmax Binary Validation Accuracy: 0.8014464168310322,\n",
      "        Argmax Binary Training Accuracy: 0.9267415730337079,\n",
      "        Custom Metric: -0.038405898674647665,\n",
      "        Epochs: 8\n",
      "        \n",
      "Early stopping at epoch 9\n",
      "Best Model Epoch Saved: 4\n",
      "Best Validation Loss: 0.4763871058821678, Best Validation accuracy: 0.8001314924391848\n"
     ]
    }
   ],
   "source": [
    "best_config = best_trial.config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model with the best configuration\n",
    "best_model, best_model_path = train_best_model(best_config, device, train_ds_pd, validation_ds_pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab97e4c",
   "metadata": {
    "papermill": {
     "duration": 0.040493,
     "end_time": "2024-08-31T11:31:15.292824",
     "exception": false,
     "start_time": "2024-08-31T11:31:15.252331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42604241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:31:15.379675Z",
     "iopub.status.busy": "2024-08-31T11:31:15.379297Z",
     "iopub.status.idle": "2024-08-31T11:31:16.615058Z",
     "shell.execute_reply": "2024-08-31T11:31:16.613913Z"
    },
    "papermill": {
     "duration": 1.280266,
     "end_time": "2024-08-31T11:31:16.617202",
     "exception": false,
     "start_time": "2024-08-31T11:31:15.336936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: /kaggle/working/final_best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "# final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path) \n",
    "\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path)\n",
    "torch.save({'model_state_dict': best_model.state_dict(),'config': best_config}, final_model_path)\n",
    "\n",
    "print(f\"Best model saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632851a1",
   "metadata": {
    "papermill": {
     "duration": 0.040917,
     "end_time": "2024-08-31T11:31:16.703274",
     "exception": false,
     "start_time": "2024-08-31T11:31:16.662357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a769bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:31:16.790502Z",
     "iopub.status.busy": "2024-08-31T11:31:16.790117Z",
     "iopub.status.idle": "2024-08-31T11:31:18.353787Z",
     "shell.execute_reply": "2024-08-31T11:31:18.352700Z"
    },
    "papermill": {
     "duration": 1.610481,
     "end_time": "2024-08-31T11:31:18.355818",
     "exception": false,
     "start_time": "2024-08-31T11:31:16.745337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /kaggle/working/final_best_model.pt for inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# final_model_path = \"/kaggle/input/tachygraphy-lv2-emotion-moodtags-v1/transformers/default/1/final_best_model.pt\"\n",
    "\n",
    "\n",
    "checkpoint = torch.load(final_model_path)\n",
    "config = checkpoint['config']\n",
    "\n",
    "# loaded_model = SentimentModel(\n",
    "#     roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#     n_classes=3,\n",
    "#     dropout_rate=config[\"dropout_rate\"]\n",
    "# )\n",
    "loaded_model = SentimentModel(\n",
    "    roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "    n_classes=3,\n",
    "    dropout_rate=config[\"dropout_rate\"]\n",
    ")\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(f\"Loaded model from {final_model_path} for inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59b209",
   "metadata": {
    "papermill": {
     "duration": 0.041826,
     "end_time": "2024-08-31T11:31:18.441433",
     "exception": false,
     "start_time": "2024-08-31T11:31:18.399607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PREDICT ON RANDOM INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21054113",
   "metadata": {
    "papermill": {
     "duration": 0.040723,
     "end_time": "2024-08-31T11:31:18.523275",
     "exception": false,
     "start_time": "2024-08-31T11:31:18.482552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1c04df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:31:18.607113Z",
     "iopub.status.busy": "2024-08-31T11:31:18.606711Z",
     "iopub.status.idle": "2024-08-31T11:31:18.613842Z",
     "shell.execute_reply": "2024-08-31T11:31:18.612962Z"
    },
    "papermill": {
     "duration": 0.05162,
     "end_time": "2024-08-31T11:31:18.615619",
     "exception": false,
     "start_time": "2024-08-31T11:31:18.563999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, device, max_len=128):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "#     # Convert logits to probabilities using sigmoid\n",
    "#     probabilities = torch.sigmoid(logits)\n",
    "    \n",
    "#     # Convert probabilities to binary predictions\n",
    "#     predictions = torch.zeros_like(probabilities)\n",
    "#     max_indices = torch.argmax(probabilities, dim=1)\n",
    "#     predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "    \n",
    "#     # Move predictions to CPU and convert to numpy for easy manipulation\n",
    "#     predictions_array = predictions.cpu().numpy().squeeze()\n",
    "\n",
    "#     return predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f9ab038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:31:18.699844Z",
     "iopub.status.busy": "2024-08-31T11:31:18.699513Z",
     "iopub.status.idle": "2024-08-31T11:31:18.708512Z",
     "shell.execute_reply": "2024-08-31T11:31:18.707778Z"
    },
    "papermill": {
     "duration": 0.053726,
     "end_time": "2024-08-31T11:31:18.710436",
     "exception": false,
     "start_time": "2024-08-31T11:31:18.656710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = loaded_model\n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7993011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:31:18.796176Z",
     "iopub.status.busy": "2024-08-31T11:31:18.795860Z",
     "iopub.status.idle": "2024-08-31T11:31:19.624270Z",
     "shell.execute_reply": "2024-08-31T11:31:19.623476Z"
    },
    "papermill": {
     "duration": 0.873334,
     "end_time": "2024-08-31T11:31:19.626561",
     "exception": false,
     "start_time": "2024-08-31T11:31:18.753227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ad821",
   "metadata": {
    "papermill": {
     "duration": 0.041667,
     "end_time": "2024-08-31T11:31:19.709948",
     "exception": false,
     "start_time": "2024-08-31T11:31:19.668281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Samples & Random Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "118c7b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:31:19.797794Z",
     "iopub.status.busy": "2024-08-31T11:31:19.797138Z",
     "iopub.status.idle": "2024-08-31T11:31:22.387947Z",
     "shell.execute_reply": "2024-08-31T11:31:22.387008Z"
    },
    "papermill": {
     "duration": 2.635184,
     "end_time": "2024-08-31T11:31:22.389995",
     "exception": false,
     "start_time": "2024-08-31T11:31:19.754811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'hey! hru, wanna ply valo toni8?': [[0.02697821 0.94266677 0.03354749]]\n",
      "NEAGTIVE: 0.0, NEUTRAL: 1.0, POSITIVE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"a1097372-8eb1-400b-8459-3e47c9f01fd5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a1097372-8eb1-400b-8459-3e47c9f01fd5\")) {                    Plotly.newPlot(                        \"a1097372-8eb1-400b-8459-3e47c9f01fd5\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.02697821,0.94266677,0.03354749,0.02697821],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a1097372-8eb1-400b-8459-3e47c9f01fd5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLQAAAHeCAYAAACCDFI4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/6klEQVR4nO3dd5gV9dk//ntZ2F3qorJUka4UW0REMAgafVCIXdGIFAsaA2J5iCUkAQt2RYMtGgVb1KigfmNDDCTBiiIGhRBEsCGCKAiilN35/cGP87D0hV2WIa/XdXFdnDmfM3PP3OecZd/MfCYrSZIkAAAAACAlKpR3AQAAAABQEgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAoJX379o3GjRuXdxk7tLI6RllZWTF06NBSX++OZsKECZGVlRUTJkzILCvtYzpq1KjIysqKOXPmlNo6y9L26v2Gjn2XLl1i7733LvNtR0TMmTMnsrKyYtSoUdtlewCwoxNoAZBKU6dOjZNPPjkaNWoUeXl50aBBgzjyyCNjxIgRZbrduXPnxtChQ2PKlCllup2ysmzZshg6dGixX8o3Zc0v8Wv+VKpUKZo2bRq9e/eOjz/+uGyL3Qavv/56DB06NBYtWlSq6+3SpUux47HrrrtGu3bt4oEHHoiioqJS3VZZu/baa+OZZ54p7zKKady4cebYVqhQIWrWrBn77LNPnHvuufHWW2+V2nb+/Oc/x2233VZq6ytNO3JtALAjyUqSJCnvIgCgJF5//fU47LDDYo899og+ffpE3bp147PPPos333wzZs2aFR999FGZbfudd96Jdu3axciRI6Nv377Fnlu5cmUUFRVFbm5umW1/W3399ddRUFAQQ4YM2aKzWiZMmBCHHXZYDBw4MNq1axcrV66MyZMnx7333hvVqlWLqVOnRv369bd4+3379o0JEyaU+tk/P/74Y1SsWDEqVqwYERE333xz/PrXv47Zs2eX6tlLXbp0iVmzZsV1110XERELFiyIhx56KKZMmRKXXXZZXH/99aW2rQ1Z04/x48dHly5dImLr33fVqlWLk08+eb0zfgoLC2PlypWRm5sbWVlZpVT5lmncuHHssssu8b//+78REbFkyZKYPn16PPnkkzFv3ry4+OKL49Zbby32mnV7vyV+/vOfxwcffFCi92FRUVGsWLEicnJyokKF1f8n3KVLl/j666/jgw8+2OL1bG1tSZLE8uXLo1KlSpGdnV1q2wOAtNryn/wAsIMYNmxY5Ofnx6RJk6JmzZrFnps/f375FBURlSpVKrdtl7VOnTrFySefHBERZ555Zuy5554xcODAePDBB+OKK64ol5rWBAx5eXmRl5e33babn58fZ5xxRubxeeedF3vttVfccccdcfXVV2/wfbB2raWttN932dnZ5RqYNGjQoNjxjYi44YYb4vTTT4/hw4dHixYt4vzzz888V9a9//HHHzMh1vZ8n60rKyurXLcPADsalxwCkDqzZs2KNm3arBdmRUTUrl17vWWPPPJItG3bNipXrhy77rprnHbaafHZZ58VG7NmLpxp06bFYYcdFlWqVIkGDRrEjTfemBkzYcKEaNeuXUSsDnXWXBq15gyXdecyWjPnzc033xx33nlnNG3aNKpUqRL/8z//E5999lkkSRJXX3117L777lG5cuU47rjj4ptvvlmv/hdffDE6deoUVatWjerVq0f37t3jww8/LDamb9++Ua1atfjiiy/i+OOPj2rVqkVBQUEMGjQoCgsLM/UUFBRERMSVV16ZqX9r5h86/PDDIyJi9uzZmWV33XVXtGnTJnJzc6N+/frRv3//Lbrk7+abb46OHTvGbrvtFpUrV462bdvGU089td64rKysGDBgQDz66KOZ7bz00kuZ59bsx9ChQ+PXv/51REQ0adIks59z5syJzp07x3777bfBOvbaa6/o2rVrSQ5DRERUqVIlDj744Pj+++9jwYIFm631iy++iLPOOivq1KkTubm50aZNm3jggQfWW+/nn38exx9/fFStWjVq164dF198cSxfvny9cRuaQ6uoqChuv/322GeffSIvLy8KCgriqKOOinfeeSdT3/fffx8PPvhg5visOeNwY3NobUl/t+RztDUqV64cDz/8cOy6664xbNiwWPsCg3Xfw0uWLImLLrooGjduHLm5uVG7du048sgjY/LkyZkan3/++fjkk08y+77m+K25xPbxxx+P3/72t9GgQYOoUqVKfPfddxucQ2uNd999Nzp27BiVK1eOJk2axD333FPs+Y0d03XXuanaNjaH1t/+9rfM90PNmjXjuOOOi+nTpxcbM3To0MjKyoqPPvoo+vbtGzVr1oz8/Pw488wzY9myZVvWBADYwThDC4DUadSoUbzxxhvxwQcfbHZC5mHDhsXvfve76NGjR5xzzjmxYMGCGDFiRBx66KHx3nvvFQvFvv322zjqqKPixBNPjB49esRTTz0Vl112Weyzzz5x9NFHR6tWreKqq66K3//+93HuuedGp06dIiKiY8eOm6zh0UcfjRUrVsQFF1wQ33zzTdx4443Ro0ePOPzww2PChAlx2WWXxUcffRQjRoyIQYMGFQs3Hn744ejTp0907do1brjhhli2bFncfffd8dOf/jTee++9YkFGYWFhdO3aNdq3bx8333xzjBs3Lm655ZZo1qxZnH/++VFQUBB33313nH/++XHCCSfEiSeeGBER++67bwk7sDpUjIjYbbfdImL1L8xXXnllHHHEEXH++efHjBkz4u67745JkybFa6+9tsmziG6//fY49thjo2fPnrFixYp4/PHH45RTTom//vWv0b1792Jj//a3v8Vf/vKXGDBgQNSqVWuDlxOeeOKJ8Z///Ccee+yxGD58eNSqVSsiIgoKCqJXr17Rr1+/9d47kyZNiv/85z/x29/+tsTHIiLi448/juzs7GLvpw3V+tVXX8XBBx+cCbwKCgrixRdfjLPPPju+++67uOiiiyIi4ocffoif/exn8emnn8bAgQOjfv368fDDD8ff/va3Larn7LPPjlGjRsXRRx8d55xzTqxatSr++c9/xptvvhkHHnhgPPzww3HOOefEQQcdFOeee25ERDRr1myj6ytJfzf3Odpa1apVixNOOCHuv//+mDZtWrRp02aD4375y1/GU089FQMGDIjWrVvHwoULY+LEiTF9+vQ44IADYvDgwbF48eL4/PPPY/jw4Zl1r+3qq6+OnJycGDRoUCxfvjxycnI2Wte3334b3bp1ix49esQvfvGL+Mtf/hLnn39+5OTkxFlnnVWifdyS2tY2bty4OProo6Np06YxdOjQ+OGHH2LEiBFxyCGHxOTJk9f7fPTo0SOaNGkS1113XUyePDn+9Kc/Re3ateOGG24oUZ0AsENIACBlxo4dm2RnZyfZ2dlJhw4dkksvvTR5+eWXkxUrVhQbN2fOnCQ7OzsZNmxYseVTp05NKlasWGx5586dk4hIHnroocyy5cuXJ3Xr1k1OOumkzLJJkyYlEZGMHDlyvbr69OmTNGrUKPN49uzZSUQkBQUFyaJFizLLr7jiiiQikv322y9ZuXJlZvkvfvGLJCcnJ/nxxx+TJEmSJUuWJDVr1kz69etXbDvz5s1L8vPziy3v06dPEhHJVVddVWzsT37yk6Rt27aZxwsWLEgiIhkyZMh69W/I+PHjk4hIHnjggWTBggXJ3Llzk+effz5p3LhxkpWVlUyaNCmZP39+kpOTk/zP//xPUlhYmHntHXfckXntxo5RkiTJsmXLij1esWJFsvfeeyeHH354seURkVSoUCH58MMP16tz3X266aabkohIZs+eXWzcokWLkry8vOSyyy4rtnzgwIFJ1apVk6VLl27yeHTu3Dlp2bJlsmDBgmTBggXJ9OnTk4EDByYRkRxzzDGbrfXss89O6tWrl3z99dfFlp922mlJfn5+5ljcdtttSUQkf/nLXzJjvv/++6R58+ZJRCTjx4/PLF/3mP7tb39LIiIZOHDgevUXFRVl/l61atWkT58+640ZOXJksWNXkv5u6edoYxo1apR07959o88PHz48iYjk2WefzSxbt/f5+flJ//79N7md7t27r/c+TJL/e783bdp0vfflmufWPvZr9veWW27JLFu+fHmy//77J7Vr1858J617TDe1zo3Vtub7ZO3vnjXbWbhwYWbZ+++/n1SoUCHp3bt3ZtmQIUOSiEjOOuusYus84YQTkt122229bQFAGrjkEIDUOfLII+ONN96IY489Nt5///248cYbo2vXrtGgQYN47rnnMuNGjx4dRUVF0aNHj/j6668zf+rWrRstWrSI8ePHF1tvtWrVis3dk5OTEwcddNA2383vlFNOifz8/Mzj9u3bR0TEGWecUWwi6/bt28eKFSviiy++iIiIV155JRYtWhS/+MUvitWfnZ0d7du3X6/+iNVnp6ytU6dOpXI3wrPOOisKCgqifv360b1798zlagceeGCMGzcuVqxYERdddFFmsuyIiH79+kWNGjXi+eef3+S6K1eunPn7t99+G4sXL45OnTplLhFbW+fOnaN169ZbvR/5+flx3HHHxWOPPZa5bK2wsDCeeOKJzOV9m/Pvf/87CgoKoqCgIFq1ahUjRoyI7t27r3fZ4Lq1JkkSTz/9dBxzzDGRJEmxnnbt2jUWL16c2ecXXngh6tWrl5m3LGL1pY1rzqbalKeffjqysrJiyJAh6z23NZO8l7S/ZfU5WrPuiNWXFW5MzZo146233oq5c+du9Xb69OlT7H25KRUrVozzzjsv8zgnJyfOO++8mD9/frz77rtbXcPmfPnllzFlypTo27dv7Lrrrpnl++67bxx55JHxwgsvrPeaDX0/LFy4ML777rsyqxMAyopLDgFIpXbt2sXo0aNjxYoV8f7778eYMWNi+PDhcfLJJ8eUKVOidevWMXPmzEiSJFq0aLHBdax7Gdzuu+++3i/8u+yyS/zrX//aplr32GOPYo/XhFsNGzbc4PJvv/02IiJmzpwZEf83X9W6atSoUezxmrmS1rbLLrtk1rctfv/730enTp0iOzs7atWqFa1atcqEcZ988klErJ6Dam05OTnRtGnTzPMb89e//jWuueaamDJlSrE5ojYUvjRp0mRbdyV69+4dTzzxRPzzn/+MQw89NMaNGxdfffVV9OrVa4te37hx47jvvvsyk3S3aNFig3O3rVvrggULYtGiRXHvvffGvffeu8F1r7mpwSeffBLNmzdf7xise4w3ZNasWVG/fv1iIce2KGl/y+pzFBGxdOnSiIioXr36RsfceOON0adPn2jYsGG0bds2unXrFr17946mTZtu8XZK8j6rX7/+ekHonnvuGRGr5706+OCDt3hdJbGxvkREtGrVKl5++eX4/vvvi9W27nfRLrvsEhGrv3PW/T4BgB2dQAuAVMvJyYl27dpFu3btYs8994wzzzwznnzyyRgyZEgUFRVFVlZWvPjiixu8a9u6c9Ns7M5uyVoTUG+Nja13c9srKiqKiNXzaNWtW3e9cWuf3bWp9ZWGffbZJ4444ohSX+8///nPOPbYY+PQQw+Nu+66K+rVqxeVKlWKkSNHxp///Of1xm/pWTOb0rVr16hTp0488sgjceihh8YjjzwSdevW3eL9q1q16haNXbfWNf0844wzok+fPht8zdbMZ7ajKavPUUTEBx98EBERzZs33+iYHj16RKdOnWLMmDExduzYuOmmm+KGG26I0aNHb/EcXqXxPlvbxs6MW3PDhu2lLHsDANubQAuAncaBBx4YEasvxYlYPcl1kiTRpEmTzBkT22prLtnaWmsm6a5du3aphUllUX+jRo0iImLGjBnFzoJZsWJFzJ49e5O1P/3005GXlxcvv/xy5ObmZpaPHDlym2ra1H5mZ2fH6aefHqNGjYobbrghnnnmmejXr1+ZBoIRqyelr169ehQWFm62n40aNYoPPvggkiQpti8zZszY7HaaNWsWL7/8cnzzzTebPEtrS98L29Lf0rR06dIYM2ZMNGzYMFq1arXJsfXq1Ytf/epX8atf/Srmz58fBxxwQAwbNiwTaJXm52Du3LnrnQn1n//8JyIiMyn7mjOh1r0r5IbOXtyavqzr3//+d9SqVWuLLqEFgLQyhxYAqTN+/PgNnlGwZs6YNZfgnHjiiZGdnR1XXnnleuOTJImFCxeWeNtrfkFc9xfTstC1a9eoUaNGXHvttbFy5cr1nl+wYEGJ11mlSpWIKN36jzjiiMjJyYk//OEPxY7z/fffH4sXL17vToVry87OjqysrGJnqsyZMyeeeeaZbappc33q1atXfPvtt3HeeefF0qVLi835VFays7PjpJNOiqeffjpzptHa1u5nt27dYu7cufHUU09lli1btmyjlyqu7aSTTookSeLKK69c77m1+1O1atUteh9sS39Lyw8//BC9evWKb775JgYPHrzJM54WL15cbFnt2rWjfv36xS5nrVq16nrjttaqVavij3/8Y+bxihUr4o9//GMUFBRE27ZtI+L/wul//OMfxWrdUD+3tLZ69erF/vvvHw8++GCxPn7wwQcxduzY6Nat29buEgCkgjO0AEidCy64IJYtWxYnnHBCtGzZMlasWBGvv/56PPHEE9G4ceM488wzI2L1L5HXXHNNXHHFFTFnzpw4/vjjo3r16jF79uwYM2ZMnHvuuTFo0KASbbtZs2ZRs2bNuOeee6J69epRtWrVaN++fanM7bSuGjVqxN133x29evWKAw44IE477bQoKCiITz/9NJ5//vk45JBD4o477ijROitXrhytW7eOJ554Ivbcc8/YddddY++994699957q+ssKCiIK664Iq688so46qij4thjj40ZM2bEXXfdFe3atdtkWNS9e/e49dZb46ijjorTTz895s+fH3feeWc0b958m+ZcWhMkDB48OE477bSoVKlSHHPMMZmg6yc/+Unsvffe8eSTT0arVq3igAMO2OptlcT1118f48ePj/bt20e/fv2idevW8c0338TkyZNj3Lhx8c0330TE6gnX77jjjujdu3e8++67Ua9evXj44YczgeSmHHbYYdGrV6/4wx/+EDNnzoyjjjoqioqK4p///GccdthhMWDAgIhYfYzGjRsXt956a9SvXz+aNGmSuWHB2ralv1vjiy++iEceeSQiVp+VNW3atHjyySdj3rx58b//+7/FJmBf15IlS2L33XePk08+Ofbbb7+oVq1ajBs3LiZNmhS33HJLZlzbtm3jiSeeiEsuuSTatWsX1apVi2OOOWar6q1fv37ccMMNMWfOnNhzzz3jiSeeiClTpsS9996bmaevTZs2cfDBB8cVV1yROXPu8ccfj1WrVq23vpLUdtNNN8XRRx8dHTp0iLPPPjt++OGHGDFiROTn58fQoUO3an8AIDW2+30VAWAbvfjii8lZZ52VtGzZMqlWrVqSk5OTNG/ePLnggguSr776ar3xTz/9dPLTn/40qVq1alK1atWkZcuWSf/+/ZMZM2ZkxnTu3Dlp06bNeq/t06dP0qhRo2LLnn322aR169ZJxYoVk4hIRo4cucGxs2fPTiIiuemmm4q9fvz48UlEJE8++WSx5SNHjkwiIpk0adJ647t27Zrk5+cneXl5SbNmzZK+ffsm77zzTrE6q1atul79Q4YMSdb9cf/6668nbdu2TXJycpKISIYMGbLe6zZX64bccccdScuWLZNKlSolderUSc4///zk22+/LTZmQ8fz/vvvT1q0aJHk5uYmLVu2TEaOHLnBuiMi6d+//wa3vaH9uPrqq5MGDRokFSpUSCIimT17drHnb7zxxiQikmuvvXaz+7bGxt4nG6pnY7V+9dVXSf/+/ZOGDRsmlSpVSurWrZv87Gc/S+69995i4z755JPk2GOPTapUqZLUqlUrufDCC5OXXnopiYhk/PjxmXEbOqarVq1KbrrppqRly5ZJTk5OUlBQkBx99NHJu+++mxnz73//Ozn00EOTypUrJxGR9OnTJ0mS/3sfrnu8tqS/JfkcbUijRo2SiEgiIsnKykpq1KiRtGnTJunXr1/y1ltvbfA1a/d++fLlya9//etkv/32S6pXr55UrVo12W+//ZK77rqr2GuWLl2anH766UnNmjWTiMjUtqn3+5rn1j72a/b3nXfeSTp06JDk5eUljRo1Su644471Xj9r1qzkiCOOSHJzc5M6deokv/nNb5JXXnllvXVurLY13ydrvm/WGDduXHLIIYcklStXTmrUqJEcc8wxybRp04qNWfN5WrBgQbHlG+s1AKRBVpKYBRIA+O9z++23x8UXXxxz5sxZ7+5vAADs2ARaAMB/nSRJYr/99ovddtstxo8fX97lAABQQubQAgD+a3z//ffx3HPPxfjx42Pq1Knx7LPPlndJAABsBWdoAQD/NebMmRNNmjSJmjVrxq9+9asYNmxYeZcEAMBWEGgBAAAAkCoVyrsAAAAAACgJgRYAAAAAqVLqk8IXFRXF3Llzo3r16pGVlVXaqwcAAAAgJZIkiSVLlkT9+vWjQoXSO6+q1AOtuXPnRsOGDUt7tQAAAACk1GeffRa77757qa2v1AOt6tWrR8TqQmvUqFHaqwcAAAAgJb777rto2LBhJi8qLaUeaK25zLBGjRoCLQAAAABKfVoqk8IDAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUqltWK9x7yclTIrVJWq9+oOXmnb/dtAgAAAJS3fZrsUd4lrKfwh8IyWa8ztAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFTJSpIkKc0Vfvfdd5Gfnx+LFy+OGjVqlOaqAQAAAEiRssqJnKEFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFKlYmmvMEmSiIj47rvvSnvVAAAAAKTImnxoTV5UWko90Fq4cGFERDRs2LC0Vw0AAABACi1cuDDy8/NLbX2lHmjtuuuuERHx6aeflmqhlI/vvvsuGjZsGJ999lnUqFGjvMthG+nnzkdPdy76uXPRz52Lfu589HTnop87F/3cuSxevDj22GOPTF5UWko90KpQYfW0XPn5+d54O5EaNWro505EP3c+erpz0c+di37uXPRz56OnOxf93Lno585lTV5Uausr1bUBAAAAQBkTaAEAAACQKqUeaOXm5saQIUMiNze3tFdNOdDPnYt+7nz0dOeinzsX/dy56OfOR093Lvq5c9HPnUtZ9TMrKe37JgIAAABAGXLJIQAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFTZqkDrzjvvjMaNG0deXl60b98+3n777U2Of/LJJ6Nly5aRl5cX++yzT7zwwgtbVSxloyT9/PDDD+Okk06Kxo0bR1ZWVtx2223br1C2SEn6ed9990WnTp1il112iV122SWOOOKIzX6e2f5K0tPRo0fHgQceGDVr1oyqVavG/vvvHw8//PB2rJbNKenP0DUef/zxyMrKiuOPP75sC6REStLPUaNGRVZWVrE/eXl527FaNqekn89FixZF//79o169epGbmxt77rmnf+fuYErS0y5duqz3Gc3Kyoru3btvx4rZlJJ+Rm+77bbYa6+9onLlytGwYcO4+OKL48cff9xO1bI5JennypUr46qrropmzZpFXl5e7LfffvHSSy9tx2rZlH/84x9xzDHHRP369SMrKyueeeaZzb5mwoQJccABB0Rubm40b948Ro0aVfINJyX0+OOPJzk5OckDDzyQfPjhh0m/fv2SmjVrJl999dUGx7/22mtJdnZ2cuONNybTpk1Lfvvb3yaVKlVKpk6dWtJNUwZK2s+33347GTRoUPLYY48ldevWTYYPH759C2aTStrP008/PbnzzjuT9957L5k+fXrSt2/fJD8/P/n888+3c+VsTEl7On78+GT06NHJtGnTko8++ii57bbbkuzs7OSll17azpWzISXt5xqzZ89OGjRokHTq1Ck57rjjtk+xbFZJ+zly5MikRo0ayZdffpn5M2/evO1cNRtT0n4uX748OfDAA5Nu3bolEydOTGbPnp1MmDAhmTJlynaunI0paU8XLlxY7PP5wQcfJNnZ2cnIkSO3b+FsUEn7+eijjya5ubnJo48+msyePTt5+eWXk3r16iUXX3zxdq6cDSlpPy+99NKkfv36yfPPP5/MmjUrueuuu5K8vLxk8uTJ27lyNuSFF15IBg8enIwePTqJiGTMmDGbHP/xxx8nVapUSS655JJk2rRpyYgRI7bqd5YSB1oHHXRQ0r9//8zjwsLCpH79+sl11123wfE9evRIunfvXmxZ+/btk/POO6+km6YMlLSfa2vUqJFAawezLf1MkiRZtWpVUr169eTBBx8sqxIpoW3taZIkyU9+8pPkt7/9bVmURwltTT9XrVqVdOzYMfnTn/6U9OnTR6C1AylpP0eOHJnk5+dvp+ooqZL28+67706aNm2arFixYnuVSAlt68/Q4cOHJ9WrV0+WLl1aViVSAiXtZ//+/ZPDDz+82LJLLrkkOeSQQ8q0TrZMSftZr1695I477ii27MQTT0x69uxZpnVSclsSaF166aVJmzZtii079dRTk65du5ZoWyW65HDFihXx7rvvxhFHHJFZVqFChTjiiCPijTfe2OBr3njjjWLjIyK6du260fFsP1vTT3ZcpdHPZcuWxcqVK2PXXXctqzIpgW3taZIk8eqrr8aMGTPi0EMPLctS2QJb28+rrroqateuHWefffb2KJMttLX9XLp0aTRq1CgaNmwYxx13XHz44Yfbo1w2Y2v6+dxzz0WHDh2if//+UadOndh7773j2muvjcLCwu1VNptQGv8uuv/+++O0006LqlWrllWZbKGt6WfHjh3j3XffzVzG9vHHH8cLL7wQ3bp12y41s3Fb08/ly5evd5l+5cqVY+LEiWVaK2WjtHKiEgVaX3/9dRQWFkadOnWKLa9Tp07Mmzdvg6+ZN29eicaz/WxNP9lxlUY/L7vssqhfv/56Xy6Uj63t6eLFi6NatWqRk5MT3bt3jxEjRsSRRx5Z1uWyGVvTz4kTJ8b9998f99133/YokRLYmn7utdde8cADD8Szzz4bjzzySBQVFUXHjh3j888/3x4lswlb08+PP/44nnrqqSgsLIwXXnghfve738Utt9wS11xzzfYomc3Y1n8Xvf322/HBBx/EOeecU1YlUgJb08/TTz89rrrqqvjpT38alSpVimbNmkWXLl3iN7/5zfYomU3Ymn527do1br311pg5c2YUFRXFK6+8EqNHj44vv/xye5RMKdtYTvTdd9/FDz/8sMXrcZdDICIirr/++nj88cdjzJgxJilOuerVq8eUKVNi0qRJMWzYsLjkkktiwoQJ5V0WJbRkyZLo1atX3HfffVGrVq3yLodS0KFDh+jdu3fsv//+0blz5xg9enQUFBTEH//4x/Iuja1QVFQUtWvXjnvvvTfatm0bp556agwePDjuueee8i6NUnD//ffHPvvsEwcddFB5l8JWmjBhQlx77bVx1113xeTJk2P06NHx/PPPx9VXX13epbEVbr/99mjRokW0bNkycnJyYsCAAXHmmWdGhQoijf9mFUsyuFatWpGdnR1fffVVseVfffVV1K1bd4OvqVu3bonGs/1sTT/ZcW1LP2+++ea4/vrrY9y4cbHvvvuWZZmUwNb2tEKFCtG8efOIiNh///1j+vTpcd1110WXLl3Kslw2o6T9nDVrVsyZMyeOOeaYzLKioqKIiKhYsWLMmDEjmjVrVrZFs1Gl8TO0UqVK8ZOf/CQ++uijsiiREtiaftarVy8qVaoU2dnZmWWtWrWKefPmxYoVKyInJ6dMa2bTtuUz+v3338fjjz8eV111VVmWSAlsTT9/97vfRa9evTJn2e2zzz7x/fffx7nnnhuDBw8WhJSjrelnQUFBPPPMM/Hjjz/GwoULo379+nH55ZdH06ZNt0fJlLKN5UQ1atSIypUrb/F6SvQpzsnJibZt28arr76aWVZUVBSvvvpqdOjQYYOv6dChQ7HxERGvvPLKRsez/WxNP9lxbW0/b7zxxrj66qvjpZdeigMPPHB7lMoWKq3PaFFRUSxfvrwsSqQEStrPli1bxtSpU2PKlCmZP8cee2wcdthhMWXKlGjYsOH2LJ91lMbns7CwMKZOnRr16tUrqzLZQlvTz0MOOSQ++uijTNAcEfGf//wn6tWrJ8zaAWzLZ/TJJ5+M5cuXxxlnnFHWZbKFtqafy5YtWy+0WhNAr563mvKyLZ/PvLy8aNCgQaxatSqefvrpOO6448q6XMpAqeVEJZuvfvXtNXNzc5NRo0Yl06ZNS84999ykZs2amdtO9+rVK7n88ssz41977bWkYsWKyc0335xMnz49GTJkSFKpUqVk6tSpJd00ZaCk/Vy+fHny3nvvJe+9915Sr169ZNCgQcl7772XzJw5s7x2gbWUtJ/XX399kpOTkzz11FPFblO9ZMmS8toF1lHSnl577bXJ2LFjk1mzZiXTpk1Lbr755qRixYrJfffdV167wFpK2s91ucvhjqWk/bzyyiuTl19+OZk1a1by7rvvJqeddlqSl5eXfPjhh+W1C6ylpP389NNPk+rVqycDBgxIZsyYkfz1r39NateunVxzzTXltQusY2u/c3/6058mp5566vYul80oaT+HDBmSVK9ePXnssceSjz/+OBk7dmzSrFmzpEePHuW1C6ylpP188803k6effjqZNWtW8o9//CM5/PDDkyZNmiTffvttOe0Ba1uyZEkmJ4iI5NZbb03ee++95JNPPkmSJEkuv/zypFevXpnxH3/8cVKlSpXk17/+dTJ9+vTkzjvvTLKzs5OXXnqpRNstcaCVJEkyYsSIZI899khycnKSgw46KHnzzTczz3Xu3Dnp06dPsfF/+ctfkj333DPJyclJ2rRpkzz//PNbs1nKSEn6OXv27CQi1vvTuXPn7V84G1SSfjZq1GiD/RwyZMj2L5yNKklPBw8enDRv3jzJy8tLdtlll6RDhw7J448/Xg5VszEl/Rm6NoHWjqck/bzooosyY+vUqZN069YtmTx5cjlUzcaU9PP5+uuvJ+3bt09yc3OTpk2bJsOGDUtWrVq1natmU0ra03//+99JRCRjx47dzpWyJUrSz5UrVyZDhw5NmjVrluTl5SUNGzZMfvWrXwlAdiAl6eeECROSVq1aJbm5ucluu+2W9OrVK/niiy/KoWo2ZPz48Rv8vXJND/v06bNeZjB+/Phk//33T3JycpKmTZsmI0eOLPF2s5LE+ZYAAAAApIeZ8AAAAABIFYEWAAAAAKki0AIAAAAgVSqWdwEAUBKFhYWxcuXK8i4DYKeUk5MTFSr4P28AdnwCLQBSIUmSmDdvXixatKi8SwHYaVWoUCGaNGkSOTk55V0KAGySuxwCkApffvllLFq0KGrXrh1VqlSJrKys8i4JYKdSVFQUc+fOjUqVKsUee+zhexaAHZoztADY4RUWFmbCrN122628ywHYaRUUFMTcuXNj1apVUalSpfIuBwA2ygXyAOzw1syZVaVKlXKuBGDntuZSw8LCwnKuBAA2TaAFQGq4/AWgbPmeBSAtBFoAAAAApIpACwD+Sw0dOjT233//8i6DHUjjxo3jtttuK+8y/itNmDAhsrKyNnsnVz0CgNVMCg9AqjW+/Pnttq0513ffbtsqbVlZWTFmzJg4/vjjM8sGDRoUF1xwQfkVta2G5m/n7S3evtvbAl26dIn9999/pwg49nlwn+26val9pm7X7W1Ox44d48svv4z8/NXv61GjRsVFF120XsA1adKkqFq1ajlUCAA7FoEWAPyXqlatWlSrVq28y6CMJUkShYWFUbGif/btyHJycqJu3bqbHVdQULAdqgGAHZ9LDgGgDHXp0iUGDhwYl156aey6665Rt27dGDp0aOb5RYsWxTnnnBMFBQVRo0aNOPzww+P9998vto5rrrkmateuHdWrV49zzjknLr/88mKXCk6aNCmOPPLIqFWrVuTn50fnzp1j8uTJmecbN24cEREnnHBCZGVlZR6vfcnh2LFjIy8vb72zQS688MI4/PDDM48nTpwYnTp1isqVK0fDhg1j4MCB8f3332/zcdoZbWvv+/btW+yMuoiIiy66KLp06ZJ5/u9//3vcfvvtkZWVFVlZWTFnzpzMpWsvvvhitG3bNnJzc2PixIkxa9asOO6446JOnTpRrVq1aNeuXYwbN247HImdR5cuXWLAgAExYMCAyM/Pj1q1asXvfve7SJIkIiK+/fbb6N27d+yyyy5RpUqVOProo2PmzJmZ13/yySdxzDHHxC677BJVq1aNNm3axAsvvBARxS85nDBhQpx55pmxePHiTG/XvHfWvuTw9NNPj1NPPbVYjStXroxatWrFQw89FBERRUVFcd1110WTJk2icuXKsd9++8VTTz1VxkcKAMqeQAsAytiDDz4YVatWjbfeeituvPHGuOqqq+KVV16JiIhTTjkl5s+fHy+++GK8++67ccABB8TPfvaz+OabbyIi4tFHH41hw4bFDTfcEO+++27ssccecffddxdb/5IlS6JPnz4xceLEePPNN6NFixbRrVu3WLJkSUSsDrwiIkaOHBlffvll5vHafvazn0XNmjXj6aefziwrLCyMJ554Inr27BkREbNmzYqjjjoqTjrppPjXv/4VTzzxREycODEGDBhQ+gdtJ7Etvd+c22+/PTp06BD9+vWLL7/8Mr788sto2LBh5vnLL788rr/++pg+fXrsu+++sXTp0ujWrVu8+uqr8d5778VRRx0VxxxzTHz66adlsu87qwcffDAqVqwYb7/9dtx+++1x6623xp/+9KeIWB0yvvPOO/Hcc8/FG2+8EUmSRLdu3WLlypUREdG/f/9Yvnx5/OMf/4ipU6fGDTfcsMGzJDt27Bi33XZb1KhRI9PbQYMGrTeuZ8+e8f/+3/+LpUuXZpa9/PLLsWzZsjjhhBMiIuK6666Lhx56KO6555748MMP4+KLL44zzjgj/v73v5fF4QGA7ca55wBQxvbdd98YMmRIRES0aNEi7rjjjnj11VejcuXK8fbbb8f8+fMjNzc3IiJuvvnmeOaZZ+Kpp56Kc889N0aMGBFnn312nHnmmRER8fvf/z7Gjh1b7BfYtc+gioi49957o2bNmvH3v/89fv7zn2cuUapZs+ZGL2nKzs6O0047Lf785z/H2WefHRERr776aixatChOOumkiFj9i3HPnj3joosuyuzLH/7wh+jcuXPcfffdkZeXV0pHbOexLb3fnPz8/MjJyYkqVapssK9XXXVVHHnkkZnHu+66a+y3336Zx1dffXWMGTMmnnvuOaFkCTRs2DCGDx8eWVlZsddee8XUqVNj+PDh0aVLl3juuefitddei44dO0bE6kC6YcOG8cwzz8Qpp5wSn376aZx00kmxzz6r5wtr2rTpBreRk5MT+fn5kZWVtcnLELt27RpVq1aNMWPGRK9evSIi4s9//nMce+yxUb169Vi+fHlce+21MW7cuOjQoUNmmxMnTow//vGP0blz59I8NACwXTlDCwDK2L777lvscb169WL+/Pnx/vvvx9KlS2O33XbLzGdVrVq1mD17dsyaNSsiImbMmBEHHXRQsdev+/irr76Kfv36RYsWLSI/Pz9q1KgRS5cuLfGZNz179owJEybE3LlzI2L1L+Pdu3ePmjVrRkTE+++/H6NGjSpWa9euXaOoqChmz55dom39t9iW3m+rAw88sNjjpUuXxqBBg6JVq1ZRs2bNqFatWkyfPt0ZWiV08MEHR1ZWVuZxhw4dYubMmTFt2rSoWLFitG/fPvPcbrvtFnvttVdMnz49IiIGDhwY11xzTRxyyCExZMiQ+Ne//rVNtVSsWDF69OgRjz76aEREfP/99/Hss89mzqr86KOPYtmyZXHkkUcWe5899NBDpfY+A4Dy4gwtAChjlSpVKvY4KysrioqKYunSpVGvXr2YMGHCeq9ZEyJtiT59+sTChQvj9ttvj0aNGkVubm506NAhVqxYUaI627VrF82aNYvHH388zj///BgzZkyMGjUq8/zSpUvjvPPOi4EDB6732j322KNE2/pvsS29r1ChQmZupjXWXLq2Jda9E96gQYPilVdeiZtvvjmaN28elStXjpNPPrnE7xO23jnnnBNdu3aN559/PsaOHRvXXXdd3HLLLdt0t9GePXtG586dY/78+fHKK69E5cqV46ijjoqIyJzJ+fzzz0eDBg2KvW7NmYEAkFYCLQAoJwcccEDMmzcvKlasmJmofV177bVXTJo0KXr37p1Ztu4cWK+99lrcdddd0a1bt4iI+Oyzz+Lrr78uNqZSpUpRWFi42Zp69uwZjz76aOy+++5RoUKF6N69e7F6p02bFs2bN9/SXWQjtqT3BQUF8cEHHxRbNmXKlGIhWU5Ozhb1NWL1+6Rv376ZuZWWLl0ac+bM2ar6/5u99dZbxR6vmbeudevWsWrVqnjrrbcylxwuXLgwZsyYEa1bt86Mb9iwYfzyl7+MX/7yl3HFFVfEfffdt8FAa0t727Fjx2jYsGE88cQT8eKLL8Ypp5ySeY+0bt06cnNz49NPP3V5IQA7HZccAkA5OeKII6JDhw5x/PHHx9ixY2POnDnx+uuvx+DBg+Odd96JiIgLLrgg7r///njwwQdj5syZcc0118S//vWvYpc8tWjRIh5++OGYPn16vPXWW9GzZ8+oXLlysW01btw4Xn311Zg3b158++23G62pZ8+eMXny5Bg2bFicfPLJxc7iuOyyy+L111+PAQMGxJQpU2LmzJnx7LPPmn9pK2xJ7w8//PB455134qGHHoqZM2fGkCFD1gu4GjduHG+99VbMmTMnvv766ygqKtroNlu0aBGjR4+OKVOmxPvvvx+nn376JsezYZ9++mlccsklMWPGjHjsscdixIgRceGFF0aLFi3iuOOOi379+sXEiRPj/fffjzPOOCMaNGgQxx13XESsvkvlyy+/HLNnz47JkyfH+PHjo1WrVhvcTuPGjWPp0qXx6quvxtdffx3Lli3baE2nn3563HPPPfHKK69kLjeMiKhevXoMGjQoLr744njwwQdj1qxZMXny5BgxYkQ8+OCDpXtgAGA7c4YWAKk25/rumx+0g8rKyooXXnghBg8eHGeeeWYsWLAg6tatG4ceemjUqVMnIlYHTB9//HEMGjQofvzxx+jRo0f07ds33n777cx67r///jj33HPjgAMOiIYNG8a111673h3RbrnllrjkkkvivvvuiwYNGmz0zJzmzZvHQQcdFG+//XbcdtttxZ7bd9994+9//3sMHjw4OnXqFEmSRLNmzeLUU08t1eOyxYYuLp/tloIt6X3Xrl3jd7/7XVx66aXx448/xllnnRW9e/eOqVOnZtYzaNCg6NOnT7Ru3Tp++OGHTc5lduutt8ZZZ50VHTt2jFq1asVll10W3333XZnv65aa2mfq5gftAHr37h0//PBDHHTQQZGdnR0XXnhhZhL/kSNHxoUXXhg///nPY8WKFXHooYfGCy+8kDljqrCwMPr37x+ff/551KhRI4466qgYPnz4BrfTsWPH+OUvfxmnnnpqLFy4MIYMGRJDhw7d4NiePXvGsGHDolGjRnHIIYcUe+7qq6+OgoKCuO666+Ljjz+OmjVrxgEHHBC/+c1vSu+gAEA5yErWnZwBAHYwP/74Y8yePTuaNGniTnoRceSRR0bdunXj4YcfLu9S4L9Kly5dYv/9918v7N2Z+L4FIC2coQUAO7Bly5bFPffcE127do3s7Ox47LHHYty4cfHKK6+Ud2kAAFBuBFoAsANbc2nasGHD4scff4y99tornn766TjiiCPKuzQAACg3Ai0A2IFVrlw5xo0bV95lABExYcKE8i4BAPj/ucshAAAAAKki0AIgNdzHBKBs+Z4FIC0EWgDs8Nbc8n7ZsmXlXAnAzm3FihUREZGdnV3OlQDApplDC4AdXnZ2dtSsWTPmz58fERFVqlSJrKyscq4KYOdSVFQUCxYsiCpVqkTFin5NAGDH5icVAKlQt27diIhMqAVA6atQoULsscce/tMAgB1eVuJCeQBSpLCwMFauXFneZQDslHJycqJCBbOSALDjE2gBAAAAkCr++wUAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFX+Pww7lqD14UzfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"hey! hru, wanna ply valo toni8?\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50532c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:31:22.476880Z",
     "iopub.status.busy": "2024-08-31T11:31:22.476497Z",
     "iopub.status.idle": "2024-08-31T11:31:22.793940Z",
     "shell.execute_reply": "2024-08-31T11:31:22.792745Z"
    },
    "papermill": {
     "duration": 0.363755,
     "end_time": "2024-08-31T11:31:22.797472",
     "exception": false,
     "start_time": "2024-08-31T11:31:22.433717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'what a badass char is arthur, he is the best game char ever made, i luv rdr2': [[0.00264824 0.01474799 0.9822923 ]]\n",
      "NEAGTIVE: 0.0, NEUTRAL: 0.0, POSITIVE: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"4edb9cbc-3cc0-4a4c-858c-1300e232e1fe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4edb9cbc-3cc0-4a4c-858c-1300e232e1fe\")) {                    Plotly.newPlot(                        \"4edb9cbc-3cc0-4a4c-858c-1300e232e1fe\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.0026482379,0.0147479875,0.9822923,0.0026482379],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4edb9cbc-3cc0-4a4c-858c-1300e232e1fe');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"what a badass char is arthur, he is the best game char ever made, i luv rdr2\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac41a8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T11:31:22.887637Z",
     "iopub.status.busy": "2024-08-31T11:31:22.887327Z",
     "iopub.status.idle": "2024-08-31T11:31:23.211696Z",
     "shell.execute_reply": "2024-08-31T11:31:23.210409Z"
    },
    "papermill": {
     "duration": 0.370604,
     "end_time": "2024-08-31T11:31:23.214356",
     "exception": false,
     "start_time": "2024-08-31T11:31:22.843752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'I don't no fr y hes sooo sad.': [[0.9568717  0.03126885 0.01763903]]\n",
      "NEAGTIVE: 1.0, NEUTRAL: 0.0, POSITIVE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"67646fe9-2ce3-4d9c-82f4-f25b14cf8e6f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"67646fe9-2ce3-4d9c-82f4-f25b14cf8e6f\")) {                    Plotly.newPlot(                        \"67646fe9-2ce3-4d9c-82f4-f25b14cf8e6f\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.9568717,0.031268854,0.017639026,0.9568717],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('67646fe9-2ce3-4d9c-82f4-f25b14cf8e6f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"I don't no fr y hes sooo sad.\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5557640,
     "sourceId": 9273793,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13865.82432,
   "end_time": "2024-08-31T11:31:28.584230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-31T07:40:22.759910",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0212e5eef3f74d47a621a4b590b06a77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fcd2e523ae7549daa98656bdd8986c12",
        "IPY_MODEL_27e72d399d27413f8adceb539fc59120",
        "IPY_MODEL_1f1f3f1b0551451f86c7839a52ea2b4a"
       ],
       "layout": "IPY_MODEL_5fb0e30a42cb458d9d2e3793f231e350"
      }
     },
     "1cafcebc8bcd406b938e25a9dfdd43a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1f1f3f1b0551451f86c7839a52ea2b4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d620531de86a4f06809253c68ace6254",
       "placeholder": "​",
       "style": "IPY_MODEL_91ed7397ef94476489259297baf31976",
       "value": " 52.0/52.0 [00:00&lt;00:00, 4.04kB/s]"
      }
     },
     "23d76455f0794fb2aee7fd417ec5ff09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "27e72d399d27413f8adceb539fc59120": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a0cb13860c144b7da5a83c2d25709a06",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1cafcebc8bcd406b938e25a9dfdd43a8",
       "value": 52.0
      }
     },
     "2a1bd23792844798aa36c7a48d07b681": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2d433b5b34e54d06b48cdc7d256be2cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fcbb0020a3c4218ba35e3236634d15d",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a1bc3b22f157458baeaf5cdd43d520d7",
       "value": 579.0
      }
     },
     "46931f9d07bb49d4a74f7ded31d43eb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b17649d0d704520b427256a457ee78f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_46931f9d07bb49d4a74f7ded31d43eb0",
       "placeholder": "​",
       "style": "IPY_MODEL_c9ee64d08b8f4723a7fde50d58b5b0cf",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 11.1MB/s]"
      }
     },
     "4c01e45bd34145e49fc5be0fcafa3cd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c47eaac4a044168ac12b03933de4437": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4da53315e2884b8ebbce5e997b3cd4c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c1b90cc4dd0044ca9e21ea1fa2c0a78b",
       "placeholder": "​",
       "style": "IPY_MODEL_4c01e45bd34145e49fc5be0fcafa3cd9",
       "value": " 579/579 [00:00&lt;00:00, 49.3kB/s]"
      }
     },
     "4fcbb0020a3c4218ba35e3236634d15d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54e113f565db4290a6cac1dc4a092383": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81025d4715bc4f27af12099d434f7301",
       "placeholder": "​",
       "style": "IPY_MODEL_a3de22c4e16f41e1a7c7334168e5151c",
       "value": "spm.model: 100%"
      }
     },
     "5fb0e30a42cb458d9d2e3793f231e350": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ff6485af1854fc18d55cf627db9a99b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_54e113f565db4290a6cac1dc4a092383",
        "IPY_MODEL_6e75074920d04b52846abe99af28e3f3",
        "IPY_MODEL_4b17649d0d704520b427256a457ee78f"
       ],
       "layout": "IPY_MODEL_4c47eaac4a044168ac12b03933de4437"
      }
     },
     "6103696e3eda471c9587bd1000f33314": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e75074920d04b52846abe99af28e3f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_96fe3575218f4e0abdd7f402b96c6f75",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9a14977b80f14c85a0304ecc6900f104",
       "value": 2464616.0
      }
     },
     "796e25d32b964048bd4e07730c26501a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6103696e3eda471c9587bd1000f33314",
       "placeholder": "​",
       "style": "IPY_MODEL_2a1bd23792844798aa36c7a48d07b681",
       "value": "config.json: 100%"
      }
     },
     "81025d4715bc4f27af12099d434f7301": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91ed7397ef94476489259297baf31976": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "96fe3575218f4e0abdd7f402b96c6f75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "990ecb3da95f4a538fb32793751137c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a14977b80f14c85a0304ecc6900f104": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a0cb13860c144b7da5a83c2d25709a06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a1bc3b22f157458baeaf5cdd43d520d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a3de22c4e16f41e1a7c7334168e5151c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aba65db1252946e4b6c05e2db5515a85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c1b90cc4dd0044ca9e21ea1fa2c0a78b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c9ee64d08b8f4723a7fde50d58b5b0cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d620531de86a4f06809253c68ace6254": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d78b4dc16a43425590b6888b007d48eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_796e25d32b964048bd4e07730c26501a",
        "IPY_MODEL_2d433b5b34e54d06b48cdc7d256be2cb",
        "IPY_MODEL_4da53315e2884b8ebbce5e997b3cd4c0"
       ],
       "layout": "IPY_MODEL_990ecb3da95f4a538fb32793751137c9"
      }
     },
     "fcd2e523ae7549daa98656bdd8986c12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aba65db1252946e4b6c05e2db5515a85",
       "placeholder": "​",
       "style": "IPY_MODEL_23d76455f0794fb2aee7fd417ec5ff09",
       "value": "tokenizer_config.json: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
