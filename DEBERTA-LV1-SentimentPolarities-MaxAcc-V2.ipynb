{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e8cf18",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:57.222043Z",
     "iopub.status.busy": "2024-08-30T13:07:57.221137Z",
     "iopub.status.idle": "2024-08-30T13:07:58.003017Z",
     "shell.execute_reply": "2024-08-30T13:07:58.001593Z"
    },
    "papermill": {
     "duration": 0.819949,
     "end_time": "2024-08-30T13:07:58.005657",
     "exception": false,
     "start_time": "2024-08-30T13:07:57.185708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_EmotionMoodtags_Dataset.csv\n",
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799f0ed",
   "metadata": {
    "papermill": {
     "duration": 0.034517,
     "end_time": "2024-08-30T13:07:58.072949",
     "exception": false,
     "start_time": "2024-08-30T13:07:58.038432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET & PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4b8a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:58.139752Z",
     "iopub.status.busy": "2024-08-30T13:07:58.138607Z",
     "iopub.status.idle": "2024-08-30T13:07:58.413351Z",
     "shell.execute_reply": "2024-08-30T13:07:58.412206Z"
    },
    "papermill": {
     "duration": 0.310662,
     "end_time": "2024-08-30T13:07:58.416450",
     "exception": false,
     "start_time": "2024-08-30T13:07:58.105788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For emoji cleaning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "'''For emoji cleaning'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b2a7c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:58.485174Z",
     "iopub.status.busy": "2024-08-30T13:07:58.483938Z",
     "iopub.status.idle": "2024-08-30T13:07:58.547830Z",
     "shell.execute_reply": "2024-08-30T13:07:58.546734Z"
    },
    "papermill": {
     "duration": 0.100151,
     "end_time": "2024-08-30T13:07:58.551076",
     "exception": false,
     "start_time": "2024-08-30T13:07:58.450925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e64939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:58.620532Z",
     "iopub.status.busy": "2024-08-30T13:07:58.619724Z",
     "iopub.status.idle": "2024-08-30T13:07:58.624597Z",
     "shell.execute_reply": "2024-08-30T13:07:58.623536Z"
    },
    "papermill": {
     "duration": 0.040708,
     "end_time": "2024-08-30T13:07:58.627353",
     "exception": false,
     "start_time": "2024-08-30T13:07:58.586645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887971eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:58.697340Z",
     "iopub.status.busy": "2024-08-30T13:07:58.696506Z",
     "iopub.status.idle": "2024-08-30T13:07:58.707695Z",
     "shell.execute_reply": "2024-08-30T13:07:58.706437Z"
    },
    "papermill": {
     "duration": 0.046946,
     "end_time": "2024-08-30T13:07:58.710623",
     "exception": false,
     "start_time": "2024-08-30T13:07:58.663677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text         1\n",
      "Meaning      1\n",
      "Sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ef74e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:58.779208Z",
     "iopub.status.busy": "2024-08-30T13:07:58.778159Z",
     "iopub.status.idle": "2024-08-30T13:07:58.806164Z",
     "shell.execute_reply": "2024-08-30T13:07:58.805039Z"
    },
    "papermill": {
     "duration": 0.063808,
     "end_time": "2024-08-30T13:07:58.808889",
     "exception": false,
     "start_time": "2024-08-30T13:07:58.745081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n",
    "                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n",
    "                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
    "                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
    "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n",
    "                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n",
    "\n",
    "punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n",
    "                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n",
    "\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n",
    "                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n",
    "                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n",
    "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n",
    "                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n",
    "                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n",
    "                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n",
    "                'demonetisation': 'demonetization'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6658ba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:58.877613Z",
     "iopub.status.busy": "2024-08-30T13:07:58.877201Z",
     "iopub.status.idle": "2024-08-30T13:07:58.892941Z",
     "shell.execute_reply": "2024-08-30T13:07:58.891803Z"
    },
    "papermill": {
     "duration": 0.051781,
     "end_time": "2024-08-30T13:07:58.895952",
     "exception": false,
     "start_time": "2024-08-30T13:07:58.844171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean emoji, Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\:(.*?)\\:','',text)\n",
    "    text = str(text).lower()    #Making Text Lowercase\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    #The next 2 lines remove html text\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    '''Clean contraction using contraction mapping'''    \n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    for word in mapping.keys():\n",
    "        if \"\"+word+\"\" in text:\n",
    "            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n",
    "    #Remove Punctuations\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    '''Cleans special characters present(if any)'''   \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def correct_spelling(x, dic):\n",
    "    '''Corrects common spelling errors'''   \n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "def remove_space(text):\n",
    "    '''Removes awkward spaces'''   \n",
    "    #Removes awkward spaces \n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3425ea85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:58.966847Z",
     "iopub.status.busy": "2024-08-30T13:07:58.966417Z",
     "iopub.status.idle": "2024-08-30T13:07:58.973160Z",
     "shell.execute_reply": "2024-08-30T13:07:58.971819Z"
    },
    "papermill": {
     "duration": 0.042905,
     "end_time": "2024-08-30T13:07:58.975908",
     "exception": false,
     "start_time": "2024-08-30T13:07:58.933003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing_pipeline(text):\n",
    "    '''Cleaning and parsing the text.'''\n",
    "    text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_text(text)\n",
    "    text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_special_chars(text, punct, punct_mapping)\n",
    "#     text = correct_spelling(text, mispell_dict)\n",
    "    text = remove_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597f5e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:59.046341Z",
     "iopub.status.busy": "2024-08-30T13:07:59.045899Z",
     "iopub.status.idle": "2024-08-30T13:07:59.056410Z",
     "shell.execute_reply": "2024-08-30T13:07:59.055278Z"
    },
    "papermill": {
     "duration": 0.047172,
     "end_time": "2024-08-30T13:07:59.058933",
     "exception": false,
     "start_time": "2024-08-30T13:07:59.011761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Text':'text', 'Sentiment':'sentiment_polarity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa940a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:59.125571Z",
     "iopub.status.busy": "2024-08-30T13:07:59.124480Z",
     "iopub.status.idle": "2024-08-30T13:07:59.135317Z",
     "shell.execute_reply": "2024-08-30T13:07:59.134273Z"
    },
    "papermill": {
     "duration": 0.046876,
     "end_time": "2024-08-30T13:07:59.138209",
     "exception": false,
     "start_time": "2024-08-30T13:07:59.091333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Meaning'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec090f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:59.210731Z",
     "iopub.status.busy": "2024-08-30T13:07:59.210337Z",
     "iopub.status.idle": "2024-08-30T13:07:59.222228Z",
     "shell.execute_reply": "2024-08-30T13:07:59.220927Z"
    },
    "papermill": {
     "duration": 0.048049,
     "end_time": "2024-08-30T13:07:59.224958",
     "exception": false,
     "start_time": "2024-08-30T13:07:59.176909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['text', 'sentiment_polarity'], inplace=True) # Dropping NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d487ebba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:59.295162Z",
     "iopub.status.busy": "2024-08-30T13:07:59.294049Z",
     "iopub.status.idle": "2024-08-30T13:07:59.318114Z",
     "shell.execute_reply": "2024-08-30T13:07:59.316771Z"
    },
    "papermill": {
     "duration": 0.061329,
     "end_time": "2024-08-30T13:07:59.321519",
     "exception": false,
     "start_time": "2024-08-30T13:07:59.260190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 4957\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   text                4957 non-null   object\n",
      " 1   sentiment_polarity  4957 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 116.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# df['text'] = df['text'].astype('str')\n",
    "# df['sentiment_polarity'] = df['sentiment_polarity'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71215ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:07:59.393529Z",
     "iopub.status.busy": "2024-08-30T13:07:59.392356Z",
     "iopub.status.idle": "2024-08-30T13:08:04.048165Z",
     "shell.execute_reply": "2024-08-30T13:08:04.047240Z"
    },
    "papermill": {
     "duration": 4.692691,
     "end_time": "2024-08-30T13:08:04.050702",
     "exception": false,
     "start_time": "2024-08-30T13:07:59.358011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: text_preprocessing_pipeline(x))\n",
    "df['sentiment_polarity'] = df['sentiment_polarity'].apply(lambda x: text_preprocessing_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47e7a15d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.116518Z",
     "iopub.status.busy": "2024-08-30T13:08:04.116080Z",
     "iopub.status.idle": "2024-08-30T13:08:04.132310Z",
     "shell.execute_reply": "2024-08-30T13:08:04.131176Z"
    },
    "papermill": {
     "duration": 0.051453,
     "end_time": "2024-08-30T13:08:04.134498",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.083045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>make a pet face wtf wrong with me tonight haha</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>i dnt care anymore boyz is not worth d drama</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>no relationship is perfect tho me bae goo from...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>over here tryna get my nail polishes and shit lol</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>no one was loved d way i luv u</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment_polarity\n",
       "0                               last session of the day            neutral\n",
       "1     shanghai is also really exciting precisely sky...           positive\n",
       "2                                submit the report asap           negative\n",
       "3                                            happy bday           positive\n",
       "4                                     the ogs i like it           positive\n",
       "...                                                 ...                ...\n",
       "4953     make a pet face wtf wrong with me tonight haha           negative\n",
       "4954       i dnt care anymore boyz is not worth d drama           negative\n",
       "4955  no relationship is perfect tho me bae goo from...           negative\n",
       "4956  over here tryna get my nail polishes and shit lol           negative\n",
       "4957                     no one was loved d way i luv u           positive\n",
       "\n",
       "[4957 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "483da6bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.197949Z",
     "iopub.status.busy": "2024-08-30T13:08:04.197519Z",
     "iopub.status.idle": "2024-08-30T13:08:04.208266Z",
     "shell.execute_reply": "2024-08-30T13:08:04.207188Z"
    },
    "papermill": {
     "duration": 0.045444,
     "end_time": "2024-08-30T13:08:04.210614",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.165170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_polar = pd.get_dummies(df['sentiment_polarity'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21707bc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.280666Z",
     "iopub.status.busy": "2024-08-30T13:08:04.279724Z",
     "iopub.status.idle": "2024-08-30T13:08:04.284807Z",
     "shell.execute_reply": "2024-08-30T13:08:04.283860Z"
    },
    "papermill": {
     "duration": 0.043182,
     "end_time": "2024-08-30T13:08:04.286988",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.243806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_polar = bin_polar.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9dd3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.393448Z",
     "iopub.status.busy": "2024-08-30T13:08:04.392590Z",
     "iopub.status.idle": "2024-08-30T13:08:04.406409Z",
     "shell.execute_reply": "2024-08-30T13:08:04.405294Z"
    },
    "papermill": {
     "duration": 0.050083,
     "end_time": "2024-08-30T13:08:04.409014",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.358931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      negative  neutral  positive\n",
       "0            0        1         0\n",
       "1            0        0         1\n",
       "2            1        0         0\n",
       "3            0        0         1\n",
       "4            0        0         1\n",
       "...        ...      ...       ...\n",
       "4953         1        0         0\n",
       "4954         1        0         0\n",
       "4955         1        0         0\n",
       "4956         1        0         0\n",
       "4957         0        0         1\n",
       "\n",
       "[4957 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b05adccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.476639Z",
     "iopub.status.busy": "2024-08-30T13:08:04.475692Z",
     "iopub.status.idle": "2024-08-30T13:08:04.490299Z",
     "shell.execute_reply": "2024-08-30T13:08:04.489052Z"
    },
    "papermill": {
     "duration": 0.050323,
     "end_time": "2024-08-30T13:08:04.492615",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.442292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            last session of the day            neutral   \n",
       "1  shanghai is also really exciting precisely sky...           positive   \n",
       "2                             submit the report asap           negative   \n",
       "3                                         happy bday           positive   \n",
       "4                                  the ogs i like it           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, bin_polar], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8da271ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.557137Z",
     "iopub.status.busy": "2024-08-30T13:08:04.556704Z",
     "iopub.status.idle": "2024-08-30T13:08:04.570021Z",
     "shell.execute_reply": "2024-08-30T13:08:04.568917Z"
    },
    "papermill": {
     "duration": 0.048589,
     "end_time": "2024-08-30T13:08:04.572398",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.523809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            last session of the day            neutral   \n",
       "1  shanghai is also really exciting precisely sky...           positive   \n",
       "2                             submit the report asap           negative   \n",
       "3                                         happy bday           positive   \n",
       "4                                  the ogs i like it           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(columns=['sentiment_polarity'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "373a260e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.638574Z",
     "iopub.status.busy": "2024-08-30T13:08:04.637635Z",
     "iopub.status.idle": "2024-08-30T13:08:04.652129Z",
     "shell.execute_reply": "2024-08-30T13:08:04.650918Z"
    },
    "papermill": {
     "duration": 0.049885,
     "end_time": "2024-08-30T13:08:04.654469",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.604584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 4957\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   text                4957 non-null   object\n",
      " 1   sentiment_polarity  4957 non-null   object\n",
      " 2   negative            4957 non-null   int64 \n",
      " 3   neutral             4957 non-null   int64 \n",
      " 4   positive            4957 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 232.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23db5cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.721219Z",
     "iopub.status.busy": "2024-08-30T13:08:04.720792Z",
     "iopub.status.idle": "2024-08-30T13:08:04.725825Z",
     "shell.execute_reply": "2024-08-30T13:08:04.724772Z"
    },
    "papermill": {
     "duration": 0.041106,
     "end_time": "2024-08-30T13:08:04.728144",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.687038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_polarity_label_mapping = {\n",
    "    0: \"negative\", 1: \"neutral\", 2: \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac2f86fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.794664Z",
     "iopub.status.busy": "2024-08-30T13:08:04.794249Z",
     "iopub.status.idle": "2024-08-30T13:08:04.799403Z",
     "shell.execute_reply": "2024-08-30T13:08:04.798314Z"
    },
    "papermill": {
     "duration": 0.041275,
     "end_time": "2024-08-30T13:08:04.801646",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.760371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_polarity_label_mapping_rev = {\n",
    "    'negative': 0, 'neutral': 1, 'positive': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a40831ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.870393Z",
     "iopub.status.busy": "2024-08-30T13:08:04.869523Z",
     "iopub.status.idle": "2024-08-30T13:08:04.874651Z",
     "shell.execute_reply": "2024-08-30T13:08:04.873516Z"
    },
    "papermill": {
     "duration": 0.041962,
     "end_time": "2024-08-30T13:08:04.877038",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.835076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SENTIMENT_POLARITY_LABELS = [\n",
    "    \"negative\", \"neutral\", \"positive\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5a8e38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:04.945557Z",
     "iopub.status.busy": "2024-08-30T13:08:04.944621Z",
     "iopub.status.idle": "2024-08-30T13:08:04.950798Z",
     "shell.execute_reply": "2024-08-30T13:08:04.949663Z"
    },
    "papermill": {
     "duration": 0.042292,
     "end_time": "2024-08-30T13:08:04.953278",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.910986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_train_split(dataset, test_ratio=0.1):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a178274f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.022031Z",
     "iopub.status.busy": "2024-08-30T13:08:05.021263Z",
     "iopub.status.idle": "2024-08-30T13:08:05.030476Z",
     "shell.execute_reply": "2024-08-30T13:08:05.029236Z"
    },
    "papermill": {
     "duration": 0.046032,
     "end_time": "2024-08-30T13:08:05.032762",
     "exception": false,
     "start_time": "2024-08-30T13:08:04.986730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4455 examples in training, 502 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "train_ds_pd, validation_ds_pd = test_train_split(df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(validation_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9dd4b1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.100663Z",
     "iopub.status.busy": "2024-08-30T13:08:05.099966Z",
     "iopub.status.idle": "2024-08-30T13:08:05.105687Z",
     "shell.execute_reply": "2024-08-30T13:08:05.104661Z"
    },
    "papermill": {
     "duration": 0.041497,
     "end_time": "2024-08-30T13:08:05.107787",
     "exception": false,
     "start_time": "2024-08-30T13:08:05.066290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd = train_ds_pd.reset_index(drop=True)\n",
    "validation_ds_pd = validation_ds_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cff23513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.173703Z",
     "iopub.status.busy": "2024-08-30T13:08:05.173297Z",
     "iopub.status.idle": "2024-08-30T13:08:05.186070Z",
     "shell.execute_reply": "2024-08-30T13:08:05.184949Z"
    },
    "papermill": {
     "duration": 0.048765,
     "end_time": "2024-08-30T13:08:05.188437",
     "exception": false,
     "start_time": "2024-08-30T13:08:05.139672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            last session of the day            neutral   \n",
       "1  shanghai is also really exciting precisely sky...           positive   \n",
       "2                             submit the report asap           negative   \n",
       "3                                         happy bday           positive   \n",
       "4                                  the ogs i like it           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dca3c8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.257180Z",
     "iopub.status.busy": "2024-08-30T13:08:05.256343Z",
     "iopub.status.idle": "2024-08-30T13:08:05.264877Z",
     "shell.execute_reply": "2024-08-30T13:08:05.263912Z"
    },
    "papermill": {
     "duration": 0.045585,
     "end_time": "2024-08-30T13:08:05.267220",
     "exception": false,
     "start_time": "2024-08-30T13:08:05.221635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative', ..., 'negative', 'negative',\n",
       "       'negative'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_labels = np.array(train_ds_pd['sentiment_polarity'])\n",
    "sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "469a1efb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.335306Z",
     "iopub.status.busy": "2024-08-30T13:08:05.334355Z",
     "iopub.status.idle": "2024-08-30T13:08:05.341272Z",
     "shell.execute_reply": "2024-08-30T13:08:05.340274Z"
    },
    "papermill": {
     "duration": 0.043934,
     "end_time": "2024-08-30T13:08:05.343593",
     "exception": false,
     "start_time": "2024-08-30T13:08:05.299659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd.drop(columns=['sentiment_polarity'], inplace=True)\n",
    "validation_ds_pd.drop(columns=['sentiment_polarity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c73ef153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.411431Z",
     "iopub.status.busy": "2024-08-30T13:08:05.410472Z",
     "iopub.status.idle": "2024-08-30T13:08:05.422495Z",
     "shell.execute_reply": "2024-08-30T13:08:05.421371Z"
    },
    "papermill": {
     "duration": 0.048588,
     "end_time": "2024-08-30T13:08:05.425045",
     "exception": false,
     "start_time": "2024-08-30T13:08:05.376457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0                            last session of the day         0        1   \n",
       "1  shanghai is also really exciting precisely sky...         0        0   \n",
       "2                             submit the report asap         1        0   \n",
       "3                                         happy bday         0        0   \n",
       "4                                  the ogs i like it         0        0   \n",
       "\n",
       "   positive  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31dc654d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.496334Z",
     "iopub.status.busy": "2024-08-30T13:08:05.495956Z",
     "iopub.status.idle": "2024-08-30T13:08:05.507940Z",
     "shell.execute_reply": "2024-08-30T13:08:05.506755Z"
    },
    "papermill": {
     "duration": 0.049135,
     "end_time": "2024-08-30T13:08:05.510283",
     "exception": false,
     "start_time": "2024-08-30T13:08:05.461148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that is great weee visitors</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my bike was put on holdshould have known that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a faux gothy chick looking at me sorr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am sorry at least it is friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is watching acoustic performances in the mood ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0                        that is great weee visitors         0        0   \n",
       "1  my bike was put on holdshould have known that ...         1        0   \n",
       "2  there is a faux gothy chick looking at me sorr...         0        1   \n",
       "3                   i am sorry at least it is friday         1        0   \n",
       "4  is watching acoustic performances in the mood ...         0        1   \n",
       "\n",
       "   positive  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a0962ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.579530Z",
     "iopub.status.busy": "2024-08-30T13:08:05.579098Z",
     "iopub.status.idle": "2024-08-30T13:08:05.588168Z",
     "shell.execute_reply": "2024-08-30T13:08:05.587090Z"
    },
    "papermill": {
     "duration": 0.046482,
     "end_time": "2024-08-30T13:08:05.590503",
     "exception": false,
     "start_time": "2024-08-30T13:08:05.544021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_indexed_labels = np.array([sentiment_polarity_label_mapping_rev[label] for label in sentiment_labels])\n",
    "sentiment_indexed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2ca0988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:05.659384Z",
     "iopub.status.busy": "2024-08-30T13:08:05.658985Z",
     "iopub.status.idle": "2024-08-30T13:08:08.952249Z",
     "shell.execute_reply": "2024-08-30T13:08:08.951119Z"
    },
    "papermill": {
     "duration": 3.331016,
     "end_time": "2024-08-30T13:08:08.954837",
     "exception": false,
     "start_time": "2024-08-30T13:08:05.623821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca4d14",
   "metadata": {
    "papermill": {
     "duration": 0.033776,
     "end_time": "2024-08-30T13:08:09.023252",
     "exception": false,
     "start_time": "2024-08-30T13:08:08.989476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculating Class Weights for each labels to avoid imbalanced distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eecb237a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:09.096577Z",
     "iopub.status.busy": "2024-08-30T13:08:09.095661Z",
     "iopub.status.idle": "2024-08-30T13:08:09.177827Z",
     "shell.execute_reply": "2024-08-30T13:08:09.176745Z"
    },
    "papermill": {
     "duration": 0.122681,
     "end_time": "2024-08-30T13:08:09.180288",
     "exception": false,
     "start_time": "2024-08-30T13:08:09.057607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3490, 0.3153, 0.3357])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = np.bincount(sentiment_indexed_labels)\n",
    "total_samples = len(sentiment_labels)\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4efbb0a",
   "metadata": {
    "papermill": {
     "duration": 0.032746,
     "end_time": "2024-08-30T13:08:09.247173",
     "exception": false,
     "start_time": "2024-08-30T13:08:09.214427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class Weight NOTE\n",
    "### This class weights are for the training dataset and are to be used while training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30943e87",
   "metadata": {
    "papermill": {
     "duration": 0.032888,
     "end_time": "2024-08-30T13:08:09.314767",
     "exception": false,
     "start_time": "2024-08-30T13:08:09.281879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SETTING CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f2ab0df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:09.385647Z",
     "iopub.status.busy": "2024-08-30T13:08:09.384947Z",
     "iopub.status.idle": "2024-08-30T13:08:09.473754Z",
     "shell.execute_reply": "2024-08-30T13:08:09.472556Z"
    },
    "papermill": {
     "duration": 0.126667,
     "end_time": "2024-08-30T13:08:09.476146",
     "exception": false,
     "start_time": "2024-08-30T13:08:09.349479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8916d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:09.544758Z",
     "iopub.status.busy": "2024-08-30T13:08:09.544356Z",
     "iopub.status.idle": "2024-08-30T13:08:11.916419Z",
     "shell.execute_reply": "2024-08-30T13:08:11.915243Z"
    },
    "papermill": {
     "duration": 2.409588,
     "end_time": "2024-08-30T13:08:11.919237",
     "exception": false,
     "start_time": "2024-08-30T13:08:09.509649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import DebertaV2Model, DebertaV2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "916b5a99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:11.989720Z",
     "iopub.status.busy": "2024-08-30T13:08:11.989111Z",
     "iopub.status.idle": "2024-08-30T13:08:13.588409Z",
     "shell.execute_reply": "2024-08-30T13:08:13.587083Z"
    },
    "papermill": {
     "duration": 1.637764,
     "end_time": "2024-08-30T13:08:13.590951",
     "exception": false,
     "start_time": "2024-08-30T13:08:11.953187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252cbfdaddf240b4a4da61294d058bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ceaa24782024c3089b58d46a27273bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08f56b26629466393a5f3160f482ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17d8e1",
   "metadata": {
    "papermill": {
     "duration": 0.033884,
     "end_time": "2024-08-30T13:08:13.659825",
     "exception": false,
     "start_time": "2024-08-30T13:08:13.625941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TORCH IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a81a1cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:13.729747Z",
     "iopub.status.busy": "2024-08-30T13:08:13.728794Z",
     "iopub.status.idle": "2024-08-30T13:08:30.192310Z",
     "shell.execute_reply": "2024-08-30T13:08:30.191272Z"
    },
    "papermill": {
     "duration": 16.501533,
     "end_time": "2024-08-30T13:08:30.195061",
     "exception": false,
     "start_time": "2024-08-30T13:08:13.693528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 13:08:15,667\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-08-30 13:08:16,257\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# from optuna.integration import PyTorchLightningPruner\n",
    "from ray import tune\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.integration.pytorch import TuneReportCallback\n",
    "from torch.amp import GradScaler, autocast\n",
    "# from ray.tune.integration.optuna import OptunaSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from torch import autocast\n",
    "# from ray import tune\n",
    "# from ray.tune.integration.tensorboard import TensorBoardReporter\n",
    "from ray.tune.logger import TBXLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ray.train import report\n",
    "# from ray.tune.integration.jupyter import JupyterNotebookReporter\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from ray.tune.schedulers import HyperBandScheduler, AsyncHyperBandScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765bcf5b",
   "metadata": {
    "papermill": {
     "duration": 0.033493,
     "end_time": "2024-08-30T13:08:30.263960",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.230467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET CONFIG & ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8609cfa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:30.345505Z",
     "iopub.status.busy": "2024-08-30T13:08:30.344445Z",
     "iopub.status.idle": "2024-08-30T13:08:30.359286Z",
     "shell.execute_reply": "2024-08-30T13:08:30.357985Z"
    },
    "papermill": {
     "duration": 0.064741,
     "end_time": "2024-08-30T13:08:30.362108",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.297367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         text = self.data.iloc[index, 0]\n",
    "#         labels = self.data.iloc[index, 1:].values.astype(float)\n",
    "        text = str(self.data.iloc[index]['text'])\n",
    "        labels = self.data.iloc[index][['negative', 'neutral', 'positive']].values.astype(np.float32)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51091a9",
   "metadata": {
    "papermill": {
     "duration": 0.035632,
     "end_time": "2024-08-30T13:08:30.434148",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.398516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba0f4250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:30.509524Z",
     "iopub.status.busy": "2024-08-30T13:08:30.508301Z",
     "iopub.status.idle": "2024-08-30T13:08:30.519264Z",
     "shell.execute_reply": "2024-08-30T13:08:30.518160Z"
    },
    "papermill": {
     "duration": 0.0518,
     "end_time": "2024-08-30T13:08:30.521901",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.470101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.roberta = roberta_model\n",
    "        self.drop = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(self.roberta.config.hidden_size, 256)  # Reduced neurons\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(256, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get the RoBERTa output\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "        # Pass through the custom layers\n",
    "        output = self.drop(cls_token_state)\n",
    "        output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa50bea",
   "metadata": {
    "papermill": {
     "duration": 0.03287,
     "end_time": "2024-08-30T13:08:30.591751",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.558881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Other Models to try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39356c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:30.660807Z",
     "iopub.status.busy": "2024-08-30T13:08:30.660380Z",
     "iopub.status.idle": "2024-08-30T13:08:30.666139Z",
     "shell.execute_reply": "2024-08-30T13:08:30.665053Z"
    },
    "papermill": {
     "duration": 0.043727,
     "end_time": "2024-08-30T13:08:30.668571",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.624844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SentimentModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(SentimentModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size, 512)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Get the RoBERTa output\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "#         # Pass through the custom layers\n",
    "#         output = self.drop(cls_token_state)\n",
    "# #         output = cls_token_state\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "# #         output = self.drop(output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47436fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:30.738761Z",
     "iopub.status.busy": "2024-08-30T13:08:30.737693Z",
     "iopub.status.idle": "2024-08-30T13:08:30.743040Z",
     "shell.execute_reply": "2024-08-30T13:08:30.741940Z"
    },
    "papermill": {
     "duration": 0.042638,
     "end_time": "2024-08-30T13:08:30.745258",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.702620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AdvancedPooling(nn.Module):\n",
    "#     def __init__(self, hidden_size):\n",
    "#         super(AdvancedPooling, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#     def forward(self, hidden_states):\n",
    "#         cls_output = hidden_states[:, 0, :]  # [CLS] token output\n",
    "#         mean_output = hidden_states.mean(dim=1)  # Mean pooling over sequence\n",
    "#         max_output, _ = hidden_states.max(dim=1)  # Max pooling over sequence\n",
    "#         combined_output = torch.cat([cls_output, mean_output, max_output], dim=1)\n",
    "#         return combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "977bd388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:30.814609Z",
     "iopub.status.busy": "2024-08-30T13:08:30.814166Z",
     "iopub.status.idle": "2024-08-30T13:08:30.820086Z",
     "shell.execute_reply": "2024-08-30T13:08:30.818874Z"
    },
    "papermill": {
     "duration": 0.04322,
     "end_time": "2024-08-30T13:08:30.822390",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.779170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SentimentModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(SentimentModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size * 3, 512)\n",
    "#         self.attention_pooling = AdvancedPooling(hidden_size=self.roberta.config.hidden_size)\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         cls_output = output.last_hidden_state[:, 0, :]  # Extract [CLS] token representation\n",
    "#         hidden_states = output.last_hidden_state  # Sequence hidden states\n",
    "#         pooled_output = self.attention_pooling(hidden_states)  # Attention pooling  # Combine CLS and attention pooling\n",
    "#         output = self.drop(pooled_output)\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "#         output = self.drop(output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52251b3b",
   "metadata": {
    "papermill": {
     "duration": 0.033627,
     "end_time": "2024-08-30T13:08:30.889926",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.856299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRAIN & VALIDATION\n",
    "### Custom metric is a metric for determining the best model free from any overfitting, underfitting. ```custom_metric = (avg_val_loss−val_accuracy) + α × ∣avg_train_loss−avg_val_loss∣ + β × ∣val_accuracy-train_accuracy∣``` This metric balances between low validation loss, high validation accuracy, and penalizing large discrepancies between training and validation loss. Note that, in the model selection we have used ```α = β = 0.5```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76324482",
   "metadata": {
    "papermill": {
     "duration": 0.034831,
     "end_time": "2024-08-30T13:08:30.958383",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.923552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### But, if we have probabilistic values as input and output we cannot directly calculate the accuracy, infact we need to rely on loss only. ```custom_metric = avg_val_loss + α × ∣avg_train_loss−avg_val_loss∣```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d1b933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:31.028808Z",
     "iopub.status.busy": "2024-08-30T13:08:31.028403Z",
     "iopub.status.idle": "2024-08-30T13:08:31.034976Z",
     "shell.execute_reply": "2024-08-30T13:08:31.033772Z"
    },
    "papermill": {
     "duration": 0.044566,
     "end_time": "2024-08-30T13:08:31.037426",
     "exception": false,
     "start_time": "2024-08-30T13:08:30.992860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom metric calculation function\n",
    "def calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy, alpha=0.5, beta=0.5):\n",
    "    loss_diff = abs(avg_train_loss - avg_val_loss)\n",
    "    accuracy_diff = abs(train_accuracy - val_accuracy)\n",
    "    custom_metric = avg_val_loss - val_accuracy + alpha * loss_diff + beta * accuracy_diff\n",
    "    return custom_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca04395",
   "metadata": {
    "papermill": {
     "duration": 0.036067,
     "end_time": "2024-08-30T13:08:31.108709",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.072642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b175776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:31.182991Z",
     "iopub.status.busy": "2024-08-30T13:08:31.181574Z",
     "iopub.status.idle": "2024-08-30T13:08:31.192101Z",
     "shell.execute_reply": "2024-08-30T13:08:31.190776Z"
    },
    "papermill": {
     "duration": 0.050524,
     "end_time": "2024-08-30T13:08:31.194741",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.144217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        EarlyStopping to stop training when a metric has stopped improving.\n",
    "\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss improved to {val_loss:.4f}')\n",
    "#             torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss did not improve. Patience: {self.patience}, Counter: {self.counter}')\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d629ef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:31.267904Z",
     "iopub.status.busy": "2024-08-30T13:08:31.267445Z",
     "iopub.status.idle": "2024-08-30T13:08:31.294832Z",
     "shell.execute_reply": "2024-08-30T13:08:31.293687Z"
    },
    "papermill": {
     "duration": 0.066748,
     "end_time": "2024-08-30T13:08:31.297094",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.230346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training function with variable parameters\n",
    "def train_model(config, train_dataset, val_dataset, device):\n",
    "#     model = SentimentModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=3,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    \n",
    "    model = SentimentModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     class_weights_tmp = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights_tmp)\n",
    "#     criterion = nn.BCELoss()\n",
    "    scaler = GradScaler()  # Initialize GradScaler\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):  # Ensure epochs are passed from config\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):  # Mixed precision\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = torch.zeros_like(probabilities)\n",
    "            max_indices = torch.argmax(probabilities, dim=1)\n",
    "            predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "            predictions = predictions.float()\n",
    "                \n",
    "#                 loss = criterion(predictions, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "#             outputs = torch.sigmoid(outputs)  \n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "#             predicted_labels = (outputs > 0.5).float()\n",
    "#             correct_train_preds += (predicted_labels == labels).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "            correct_train_preds += (predictions == labels).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = torch.zeros_like(probabilities)\n",
    "                max_indices = torch.argmax(probabilities, dim=1)\n",
    "                predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "                predictions = predictions.float()\n",
    "                \n",
    "#                     loss = criterion(predictions, labels)\n",
    "                    \n",
    "#                 outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "    \n",
    "#                 predicted_labels = (outputs > 0.5).float()\n",
    "#                 correct_val_preds += (predicted_labels == labels).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "                \n",
    "#                 correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "                correct_val_preds += (predictions == labels).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "#         custom_metric = avg_val_loss - val_accuracy\n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "\n",
    "        # Report metrics using ray.train.report\n",
    "        report({\n",
    "            \"loss\": avg_val_loss,\n",
    "            \"accuracy\": val_accuracy,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"custom_metric\": custom_metric,\n",
    "            \"early_stopping_epoch\": epoch + 1,\n",
    "        })\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "#         trial_dir = os.path.join(os.environ[\"TUNE_TRIAL_DIR\"], \"checkpoint.pt\")\n",
    "#         torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "#         checkpoint_path = f\"/kaggle/working/checkpoint_epoch_{epoch}.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_fn(config):\n",
    "    # Load your data here\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "    train_dataset = SentimentDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = SentimentDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(config, train_dataset, val_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984200a5",
   "metadata": {
    "papermill": {
     "duration": 0.039673,
     "end_time": "2024-08-30T13:08:31.372251",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.332578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8851f247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:31.460057Z",
     "iopub.status.busy": "2024-08-30T13:08:31.459606Z",
     "iopub.status.idle": "2024-08-30T13:08:31.466910Z",
     "shell.execute_reply": "2024-08-30T13:08:31.465778Z"
    },
    "papermill": {
     "duration": 0.052074,
     "end_time": "2024-08-30T13:08:31.469101",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.417027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'dropout_rate': tune.choice([0.2, 0.25, 0.27, 0.3, 0.32, 0.35, 0.4]),\n",
    "    'batch_size': tune.choice([32, 64]),\n",
    "    'weight_decay': tune.choice([1e-6, 2e-6, 1e-5, 2e-5, 1e-4, 2e-4, 5e-5, 5e-6, 1e-2, 1e-3]),\n",
    "    'lr': tune.choice([1e-6, 1e-5, 2e-5, 1e-4, 2e-4, 2e-6, 3e-6, 5e-6, 3e-5, 5e-5, 2e-7, 1e-7, 1e-3, 5e-7]),\n",
    "    'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6f2b0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:31.540632Z",
     "iopub.status.busy": "2024-08-30T13:08:31.540200Z",
     "iopub.status.idle": "2024-08-30T13:08:31.544846Z",
     "shell.execute_reply": "2024-08-30T13:08:31.543797Z"
    },
    "papermill": {
     "duration": 0.042786,
     "end_time": "2024-08-30T13:08:31.547105",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.504319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'dropout_rate': tune.uniform(0.1, 0.5),\n",
    "#     'batch_size': tune.choice([16, 32, 64]),\n",
    "#     'weight_decay': tune.loguniform(1e-6, 1e-1),\n",
    "#     'lr': tune.loguniform(1e-6, 1e-1),\n",
    "#     'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed9046",
   "metadata": {
    "papermill": {
     "duration": 0.045163,
     "end_time": "2024-08-30T13:08:31.627381",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.582218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1e23e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:31.708105Z",
     "iopub.status.busy": "2024-08-30T13:08:31.707668Z",
     "iopub.status.idle": "2024-08-30T13:08:31.712801Z",
     "shell.execute_reply": "2024-08-30T13:08:31.711653Z"
    },
    "papermill": {
     "duration": 0.043965,
     "end_time": "2024-08-30T13:08:31.715037",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.671072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna_search = OptunaSearch(\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94825cb5",
   "metadata": {
    "papermill": {
     "duration": 0.034684,
     "end_time": "2024-08-30T13:08:31.785339",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.750655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SCHEDULER ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "572f6aee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:31.856475Z",
     "iopub.status.busy": "2024-08-30T13:08:31.856081Z",
     "iopub.status.idle": "2024-08-30T13:08:31.861349Z",
     "shell.execute_reply": "2024-08-30T13:08:31.860186Z"
    },
    "papermill": {
     "duration": 0.043328,
     "end_time": "2024-08-30T13:08:31.863727",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.820399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric='accuracy',\n",
    "    mode='max',\n",
    "    max_t=22,\n",
    "    grace_period=3,\n",
    "    reduction_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b1dbc",
   "metadata": {
    "papermill": {
     "duration": 0.034598,
     "end_time": "2024-08-30T13:08:31.934023",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.899425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f831474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:32.007591Z",
     "iopub.status.busy": "2024-08-30T13:08:32.006677Z",
     "iopub.status.idle": "2024-08-30T13:08:32.012009Z",
     "shell.execute_reply": "2024-08-30T13:08:32.010909Z"
    },
    "papermill": {
     "duration": 0.044988,
     "end_time": "2024-08-30T13:08:32.014415",
     "exception": false,
     "start_time": "2024-08-30T13:08:31.969427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To ignore warinings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7da0e791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T13:08:32.086273Z",
     "iopub.status.busy": "2024-08-30T13:08:32.085812Z",
     "iopub.status.idle": "2024-08-30T16:53:52.318994Z",
     "shell.execute_reply": "2024-08-30T16:53:52.317544Z"
    },
    "papermill": {
     "duration": 13520.27171,
     "end_time": "2024-08-30T16:53:52.321834",
     "exception": false,
     "start_time": "2024-08-30T13:08:32.050124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-30 16:53:52</td></tr>\n",
       "<tr><td>Running for: </td><td>03:45:00.78        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.2/31.4 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=53<br>Bracket: Iter 12.000: 0.8393094289508632 | Iter 6.000: 0.8326693227091634 | Iter 3.000: 0.8167330677290837<br>Logical resource usage: 2.0/4 CPUs, 1.0/2 GPUs (0.0/1.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  early_stopping_epoch</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_5830ba83</td><td>TERMINATED</td><td>172.19.2.2:342 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.49663 </td><td style=\"text-align: right;\">  0.811421</td><td style=\"text-align: right;\">     -0.101507 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.191003</td><td style=\"text-align: right;\">        0.932361</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_4bb3223a</td><td>TERMINATED</td><td>172.19.2.2:377 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.449642</td><td style=\"text-align: right;\">  0.798141</td><td style=\"text-align: right;\">     -0.281336 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.359451</td><td style=\"text-align: right;\">        0.842275</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_4ca8d1be</td><td>TERMINATED</td><td>172.19.2.2:480 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.70093 </td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.135788 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.701496</td><td style=\"text-align: right;\">        0.563786</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_8d5227cc</td><td>TERMINATED</td><td>172.19.2.2:560 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.685988</td><td style=\"text-align: right;\">  0.541833</td><td style=\"text-align: right;\">      0.149171 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.68948 </td><td style=\"text-align: right;\">        0.548373</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_cfd45057</td><td>TERMINATED</td><td>172.19.2.2:638 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.636397</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.074531 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.63753 </td><td style=\"text-align: right;\">        0.5578  </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_39e02947</td><td>TERMINATED</td><td>172.19.2.2:718 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.671507</td><td style=\"text-align: right;\">  0.559097</td><td style=\"text-align: right;\">      0.119437 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.680223</td><td style=\"text-align: right;\">        0.55376 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ecb4dcf6</td><td>TERMINATED</td><td>172.19.2.2:797 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.38991 </td><td style=\"text-align: right;\">  0.833997</td><td style=\"text-align: right;\">     -0.380191 </td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">    0.313042</td><td style=\"text-align: right;\">        0.884923</td><td style=\"text-align: right;\">                    11</td></tr>\n",
       "<tr><td>train_fn_0e814203</td><td>TERMINATED</td><td>172.19.2.2:875 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.466401</td><td style=\"text-align: right;\">  0.792829</td><td style=\"text-align: right;\">     -0.276636 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.529983</td><td style=\"text-align: right;\">        0.756828</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_c35d608c</td><td>TERMINATED</td><td>172.19.2.2:975 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.631684</td><td style=\"text-align: right;\">  0.571049</td><td style=\"text-align: right;\">      0.0696119</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.641177</td><td style=\"text-align: right;\">        0.562589</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_3013dde5</td><td>TERMINATED</td><td>172.19.2.2:1064</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.395769</td><td style=\"text-align: right;\">  0.827357</td><td style=\"text-align: right;\">     -0.411044 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">    0.378279</td><td style=\"text-align: right;\">        0.850954</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_e2fb0879</td><td>TERMINATED</td><td>172.19.2.2:1129</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.544405</td><td style=\"text-align: right;\">  0.839309</td><td style=\"text-align: right;\">     -0.0291655</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.131267</td><td style=\"text-align: right;\">        0.957651</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_19130272</td><td>TERMINATED</td><td>172.19.2.2:1236</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.396032</td><td style=\"text-align: right;\">  0.844622</td><td style=\"text-align: right;\">     -0.373104 </td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">    0.290749</td><td style=\"text-align: right;\">        0.890311</td><td style=\"text-align: right;\">                    13</td></tr>\n",
       "<tr><td>train_fn_7d9ba061</td><td>TERMINATED</td><td>172.19.2.2:1325</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.476627</td><td style=\"text-align: right;\">  0.828685</td><td style=\"text-align: right;\">     -0.14567  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.17426 </td><td style=\"text-align: right;\">        0.939095</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_a5aa127a</td><td>TERMINATED</td><td>172.19.2.2:1424</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.470605</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.167474 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.189234</td><td style=\"text-align: right;\">        0.93251 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_c0f84ee7</td><td>TERMINATED</td><td>172.19.2.2:1522</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.379854</td><td style=\"text-align: right;\">  0.839309</td><td style=\"text-align: right;\">     -0.452381 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.393676</td><td style=\"text-align: right;\">        0.838982</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_855bc4f7</td><td>TERMINATED</td><td>172.19.2.2:1593</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.515588</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.102526 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.207922</td><td style=\"text-align: right;\">        0.926225</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_121fffcd</td><td>TERMINATED</td><td>172.19.2.2:1694</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.473835</td><td style=\"text-align: right;\">  0.816733</td><td style=\"text-align: right;\">     -0.156733 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.209203</td><td style=\"text-align: right;\">        0.924429</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_e3f1159e</td><td>TERMINATED</td><td>172.19.2.2:1768</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.637289</td><td style=\"text-align: right;\">  0.559097</td><td style=\"text-align: right;\">      0.0803354</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638333</td><td style=\"text-align: right;\">        0.555855</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_1f7519a3</td><td>TERMINATED</td><td>172.19.2.2:1858</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.648253</td><td style=\"text-align: right;\">  0.590969</td><td style=\"text-align: right;\">      0.084878 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.671021</td><td style=\"text-align: right;\">        0.558548</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c9ff502e</td><td>TERMINATED</td><td>172.19.2.2:1940</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.451192</td><td style=\"text-align: right;\">  0.822045</td><td style=\"text-align: right;\">     -0.208457 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.22624 </td><td style=\"text-align: right;\">        0.921886</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_08497c91</td><td>TERMINATED</td><td>172.19.2.2:2016</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.417639</td><td style=\"text-align: right;\">  0.837981</td><td style=\"text-align: right;\">     -0.294426 </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.242675</td><td style=\"text-align: right;\">        0.914852</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_4d5cee37</td><td>TERMINATED</td><td>172.19.2.2:2116</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.461889</td><td style=\"text-align: right;\">  0.833997</td><td style=\"text-align: right;\">     -0.168489 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.164388</td><td style=\"text-align: right;\">        0.943734</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_9dcb9a55</td><td>TERMINATED</td><td>172.19.2.2:2204</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.418838</td><td style=\"text-align: right;\">  0.824701</td><td style=\"text-align: right;\">     -0.296302 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.273704</td><td style=\"text-align: right;\">        0.898691</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_d4f8ed92</td><td>TERMINATED</td><td>172.19.2.2:2291</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.444172</td><td style=\"text-align: right;\">  0.831341</td><td style=\"text-align: right;\">     -0.217784 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.20268 </td><td style=\"text-align: right;\">        0.92862 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_589999ea</td><td>TERMINATED</td><td>172.19.2.2:2386</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.521365</td><td style=\"text-align: right;\">  0.754316</td><td style=\"text-align: right;\">     -0.149957 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.601725</td><td style=\"text-align: right;\">        0.668687</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a131e1f8</td><td>TERMINATED</td><td>172.19.2.2:2464</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.520122</td><td style=\"text-align: right;\">  0.752988</td><td style=\"text-align: right;\">     -0.17934  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.584923</td><td style=\"text-align: right;\">        0.710737</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e7dedcae</td><td>TERMINATED</td><td>172.19.2.2:2544</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.490172</td><td style=\"text-align: right;\">  0.772908</td><td style=\"text-align: right;\">     -0.224174 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.557246</td><td style=\"text-align: right;\">        0.722858</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ff32af3f</td><td>TERMINATED</td><td>172.19.2.2:2621</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.562038</td><td style=\"text-align: right;\">  0.735724</td><td style=\"text-align: right;\">     -0.111316 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.611511</td><td style=\"text-align: right;\">        0.660456</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f49da2f4</td><td>TERMINATED</td><td>172.19.2.2:2702</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.620254</td><td style=\"text-align: right;\">  0.670651</td><td style=\"text-align: right;\">     -0.0146046</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.631812</td><td style=\"text-align: right;\">        0.610625</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_72a82448</td><td>TERMINATED</td><td>172.19.2.2:2778</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.617221</td><td style=\"text-align: right;\">  0.721116</td><td style=\"text-align: right;\">     -0.031319 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.631978</td><td style=\"text-align: right;\">        0.590722</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ec19e763</td><td>TERMINATED</td><td>172.19.2.2:2860</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.447539</td><td style=\"text-align: right;\">  0.836653</td><td style=\"text-align: right;\">     -0.22537  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.207077</td><td style=\"text-align: right;\">        0.923681</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_b770411c</td><td>TERMINATED</td><td>172.19.2.2:2937</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.443965</td><td style=\"text-align: right;\">  0.835325</td><td style=\"text-align: right;\">     -0.223533 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.200707</td><td style=\"text-align: right;\">        0.927722</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_f2070cb5</td><td>TERMINATED</td><td>172.19.2.2:3028</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.402001</td><td style=\"text-align: right;\">  0.848606</td><td style=\"text-align: right;\">     -0.312892 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.211447</td><td style=\"text-align: right;\">        0.925477</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_6b7c1fee</td><td>TERMINATED</td><td>172.19.2.2:3104</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.46018 </td><td style=\"text-align: right;\">  0.822045</td><td style=\"text-align: right;\">     -0.181718 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">    0.207956</td><td style=\"text-align: right;\">        0.930116</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_b780d9d9</td><td>TERMINATED</td><td>172.19.2.2:3196</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.393777</td><td style=\"text-align: right;\">  0.848606</td><td style=\"text-align: right;\">     -0.367839 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.272278</td><td style=\"text-align: right;\">        0.901085</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_23ee825e</td><td>TERMINATED</td><td>172.19.2.2:3303</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.447552</td><td style=\"text-align: right;\">  0.820717</td><td style=\"text-align: right;\">     -0.20028  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.204745</td><td style=\"text-align: right;\">        0.923681</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_9d8dcd5c</td><td>TERMINATED</td><td>172.19.2.2:3377</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.409663</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.330256 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.296524</td><td style=\"text-align: right;\">        0.877142</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_7ee5a3eb</td><td>TERMINATED</td><td>172.19.2.2:3470</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.637946</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0721129</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.640273</td><td style=\"text-align: right;\">        0.566929</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_6726ef17</td><td>TERMINATED</td><td>172.19.2.2:3544</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.686248</td><td style=\"text-align: right;\">  0.540505</td><td style=\"text-align: right;\">      0.150766 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.686016</td><td style=\"text-align: right;\">        0.550318</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_96de45ed</td><td>TERMINATED</td><td>172.19.2.2:3629</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.486902</td><td style=\"text-align: right;\">  0.828685</td><td style=\"text-align: right;\">     -0.127788 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.169471</td><td style=\"text-align: right;\">        0.939244</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_657a5c2b</td><td>TERMINATED</td><td>172.19.2.2:3703</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.636485</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0745013</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637532</td><td style=\"text-align: right;\">        0.55795 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_12e5f0fe</td><td>TERMINATED</td><td>172.19.2.2:3793</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.637905</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0750191</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637464</td><td style=\"text-align: right;\">        0.559147</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_2b0d8d45</td><td>TERMINATED</td><td>172.19.2.2:3869</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.516339</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.0958823</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.185495</td><td style=\"text-align: right;\">        0.934755</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_399ba094</td><td>TERMINATED</td><td>172.19.2.2:3953</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.696654</td><td style=\"text-align: right;\">  0.549801</td><td style=\"text-align: right;\">      0.149362 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.697412</td><td style=\"text-align: right;\">        0.554059</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0623ad38</td><td>TERMINATED</td><td>172.19.2.2:4040</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.635184</td><td style=\"text-align: right;\">  0.590969</td><td style=\"text-align: right;\">      0.0643425</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.650501</td><td style=\"text-align: right;\">        0.566031</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_17c637c2</td><td>TERMINATED</td><td>172.19.2.2:4111</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.642084</td><td style=\"text-align: right;\">  0.540505</td><td style=\"text-align: right;\">      0.110373 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.651055</td><td style=\"text-align: right;\">        0.549121</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_01a9b4f9</td><td>TERMINATED</td><td>172.19.2.2:4197</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.634506</td><td style=\"text-align: right;\">  0.583001</td><td style=\"text-align: right;\">      0.074525 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.652353</td><td style=\"text-align: right;\">        0.554807</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c8e3abeb</td><td>TERMINATED</td><td>172.19.2.2:4269</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.485872</td><td style=\"text-align: right;\">  0.822045</td><td style=\"text-align: right;\">     -0.123438 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.175057</td><td style=\"text-align: right;\">        0.9367  </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_e35e8eca</td><td>TERMINATED</td><td>172.19.2.2:4356</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.477127</td><td style=\"text-align: right;\">  0.831341</td><td style=\"text-align: right;\">     -0.178083 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.214513</td><td style=\"text-align: right;\">        0.920988</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_3896e862</td><td>TERMINATED</td><td>172.19.2.2:4437</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.412335</td><td style=\"text-align: right;\">  0.839309</td><td style=\"text-align: right;\">     -0.281221 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.206995</td><td style=\"text-align: right;\">        0.925477</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_dadf29a5</td><td>TERMINATED</td><td>172.19.2.2:4523</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.635736</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0764991</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.639134</td><td style=\"text-align: right;\">        0.554807</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c8428bbd</td><td>TERMINATED</td><td>172.19.2.2:4604</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.634933</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.073622 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638224</td><td style=\"text-align: right;\">        0.558848</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_887a98ed</td><td>TERMINATED</td><td>172.19.2.2:4679</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.636241</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0758265</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638033</td><td style=\"text-align: right;\">        0.555556</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_33d9cb80</td><td>TERMINATED</td><td>172.19.2.2:4761</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.437363</td><td style=\"text-align: right;\">  0.837981</td><td style=\"text-align: right;\">     -0.232094 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.192746</td><td style=\"text-align: right;\">        0.930415</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_06a4851e</td><td>TERMINATED</td><td>172.19.2.2:4837</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.456862</td><td style=\"text-align: right;\">  0.835325</td><td style=\"text-align: right;\">     -0.203042 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.199464</td><td style=\"text-align: right;\">        0.928769</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_1fc6108f</td><td>TERMINATED</td><td>172.19.2.2:4928</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.539225</td><td style=\"text-align: right;\">  0.827357</td><td style=\"text-align: right;\">     -0.0525303</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.176765</td><td style=\"text-align: right;\">        0.936102</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_7b9fa64c</td><td>TERMINATED</td><td>172.19.2.2:5005</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.461989</td><td style=\"text-align: right;\">  0.786189</td><td style=\"text-align: right;\">     -0.293984 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.507574</td><td style=\"text-align: right;\">        0.771343</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c6761c8a</td><td>TERMINATED</td><td>172.19.2.2:5091</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.461844</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.194304 </td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">    0.220183</td><td style=\"text-align: right;\">        0.92413 </td><td style=\"text-align: right;\">                     9</td></tr>\n",
       "<tr><td>train_fn_2598c7e9</td><td>TERMINATED</td><td>172.19.2.2:5165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.411971</td><td style=\"text-align: right;\">  0.836653</td><td style=\"text-align: right;\">     -0.315921 </td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">    0.263818</td><td style=\"text-align: right;\">        0.906023</td><td style=\"text-align: right;\">                    11</td></tr>\n",
       "<tr><td>train_fn_b734753f</td><td>TERMINATED</td><td>172.19.2.2:5284</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.635129</td><td style=\"text-align: right;\">  0.579017</td><td style=\"text-align: right;\">      0.0657465</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.643357</td><td style=\"text-align: right;\">        0.567976</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_17cb948d</td><td>TERMINATED</td><td>172.19.2.2:5369</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.645524</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0841926</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.654011</td><td style=\"text-align: right;\">        0.564085</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c6baa580</td><td>TERMINATED</td><td>172.19.2.2:5442</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.641056</td><td style=\"text-align: right;\">  0.549801</td><td style=\"text-align: right;\">      0.101447 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.653739</td><td style=\"text-align: right;\">        0.557501</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ec455209</td><td>TERMINATED</td><td>172.19.2.2:5528</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.431852</td><td style=\"text-align: right;\">  0.822045</td><td style=\"text-align: right;\">     -0.239921 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.230848</td><td style=\"text-align: right;\">        0.921586</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_ed63d9a0</td><td>TERMINATED</td><td>172.19.2.2:5601</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.391108</td><td style=\"text-align: right;\">  0.843293</td><td style=\"text-align: right;\">     -0.36502  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.270679</td><td style=\"text-align: right;\">        0.897194</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_a1b45225</td><td>TERMINATED</td><td>172.19.2.2:5704</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.406013</td><td style=\"text-align: right;\">  0.839309</td><td style=\"text-align: right;\">     -0.335601 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.274793</td><td style=\"text-align: right;\">        0.903479</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_6d908d9f</td><td>TERMINATED</td><td>172.19.2.2:5784</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.39153 </td><td style=\"text-align: right;\">  0.841965</td><td style=\"text-align: right;\">     -0.371714 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.287371</td><td style=\"text-align: right;\">        0.895249</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_4ce11838</td><td>TERMINATED</td><td>172.19.2.2:5885</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.439255</td><td style=\"text-align: right;\">  0.831341</td><td style=\"text-align: right;\">     -0.252891 </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.244526</td><td style=\"text-align: right;\">        0.915002</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_c9ebeda9</td><td>TERMINATED</td><td>172.19.2.2:5965</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.473929</td><td style=\"text-align: right;\">  0.788845</td><td style=\"text-align: right;\">     -0.249975 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.553836</td><td style=\"text-align: right;\">        0.73887 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f136ac44</td><td>TERMINATED</td><td>172.19.2.2:6054</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.425241</td><td style=\"text-align: right;\">  0.836653</td><td style=\"text-align: right;\">     -0.287821 </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.252218</td><td style=\"text-align: right;\">        0.910812</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_a8329e41</td><td>TERMINATED</td><td>172.19.2.2:6142</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.390692</td><td style=\"text-align: right;\">  0.843293</td><td style=\"text-align: right;\">     -0.363274 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.270428</td><td style=\"text-align: right;\">        0.901684</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_c8127031</td><td>TERMINATED</td><td>172.19.2.2:6241</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.396213</td><td style=\"text-align: right;\">  0.832669</td><td style=\"text-align: right;\">     -0.376636 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.320746</td><td style=\"text-align: right;\">        0.876842</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_60eb737d</td><td>TERMINATED</td><td>172.19.2.2:6323</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.685708</td><td style=\"text-align: right;\">  0.563081</td><td style=\"text-align: right;\">      0.128692 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.692793</td><td style=\"text-align: right;\">        0.568126</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_216f7672</td><td>TERMINATED</td><td>172.19.2.2:6411</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.399619</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.366005 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.318867</td><td style=\"text-align: right;\">        0.87804 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_46280169</td><td>TERMINATED</td><td>172.19.2.2:6486</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.418932</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.317229 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.299586</td><td style=\"text-align: right;\">        0.88642 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_17fda474</td><td>TERMINATED</td><td>172.19.2.2:6587</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.449364</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.199368 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.198408</td><td style=\"text-align: right;\">        0.929667</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_f39e94dd</td><td>TERMINATED</td><td>172.19.2.2:6662</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.507946</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.0763075</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.156053</td><td style=\"text-align: right;\">        0.949719</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_12df181d</td><td>TERMINATED</td><td>172.19.2.2:6757</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.501871</td><td style=\"text-align: right;\">  0.816733</td><td style=\"text-align: right;\">     -0.0861577</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.167274</td><td style=\"text-align: right;\">        0.939544</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_7ea54596</td><td>TERMINATED</td><td>172.19.2.2:6839</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.4525  </td><td style=\"text-align: right;\">  0.802125</td><td style=\"text-align: right;\">     -0.29625  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.509912</td><td style=\"text-align: right;\">        0.752787</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_33987d94</td><td>TERMINATED</td><td>172.19.2.2:6927</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.430821</td><td style=\"text-align: right;\">  0.807437</td><td style=\"text-align: right;\">     -0.32355  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.495621</td><td style=\"text-align: right;\">        0.766105</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_7362c8dc</td><td>TERMINATED</td><td>172.19.2.2:6994</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.703353</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.142508 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.713263</td><td style=\"text-align: right;\">        0.564534</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_132bcca2</td><td>TERMINATED</td><td>172.19.2.2:7089</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.686994</td><td style=\"text-align: right;\">  0.559097</td><td style=\"text-align: right;\">      0.133375 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.689771</td><td style=\"text-align: right;\">        0.550917</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_87b68313</td><td>TERMINATED</td><td>172.19.2.2:7159</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.704985</td><td style=\"text-align: right;\">  0.559097</td><td style=\"text-align: right;\">      0.15198  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.711383</td><td style=\"text-align: right;\">        0.553311</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_36deab26</td><td>TERMINATED</td><td>172.19.2.2:7248</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.491854</td><td style=\"text-align: right;\">  0.787517</td><td style=\"text-align: right;\">     -0.206792 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.581741</td><td style=\"text-align: right;\">        0.699663</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_90f0fcf6</td><td>TERMINATED</td><td>172.19.2.2:7319</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.602405</td><td style=\"text-align: right;\">  0.75166 </td><td style=\"text-align: right;\">     -0.0714121</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.625286</td><td style=\"text-align: right;\">        0.618855</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a319ce15</td><td>TERMINATED</td><td>172.19.2.2:7406</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.620932</td><td style=\"text-align: right;\">  0.681275</td><td style=\"text-align: right;\">     -0.0117877</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.63138 </td><td style=\"text-align: right;\">        0.594613</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f9897e93</td><td>TERMINATED</td><td>172.19.2.2:7472</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.412967</td><td style=\"text-align: right;\">  0.837981</td><td style=\"text-align: right;\">     -0.322672 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">    0.272433</td><td style=\"text-align: right;\">        0.902132</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_e3d5f548</td><td>TERMINATED</td><td>172.19.2.2:7565</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.428247</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.284235 </td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">    0.279088</td><td style=\"text-align: right;\">        0.895997</td><td style=\"text-align: right;\">                     9</td></tr>\n",
       "<tr><td>train_fn_6cbcd62b</td><td>TERMINATED</td><td>172.19.2.2:7670</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.496309</td><td style=\"text-align: right;\">  0.828685</td><td style=\"text-align: right;\">     -0.0942084</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.144151</td><td style=\"text-align: right;\">        0.952862</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_413edb78</td><td>TERMINATED</td><td>172.19.2.2:7751</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.460705</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.190319 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.198338</td><td style=\"text-align: right;\">        0.925627</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_d8daadf8</td><td>TERMINATED</td><td>172.19.2.2:7842</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.42796 </td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.195301 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.153632</td><td style=\"text-align: right;\">        0.94927 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_bf8b9605</td><td>TERMINATED</td><td>172.19.2.2:7919</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.470964</td><td style=\"text-align: right;\">  0.832669</td><td style=\"text-align: right;\">     -0.161032 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.175446</td><td style=\"text-align: right;\">        0.938496</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_6dafa1e2</td><td>TERMINATED</td><td>172.19.2.2:8014</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.478801</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.152086 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.195747</td><td style=\"text-align: right;\">        0.933259</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_46269c57</td><td>TERMINATED</td><td>172.19.2.2:8091</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.423667</td><td style=\"text-align: right;\">  0.847278</td><td style=\"text-align: right;\">     -0.262188 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.186353</td><td style=\"text-align: right;\">        0.93281 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_568fe81f</td><td>TERMINATED</td><td>172.19.2.2:8180</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.399134</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.344238 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.297052</td><td style=\"text-align: right;\">        0.889263</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_feeff367</td><td>TERMINATED</td><td>172.19.2.2:8264</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.396517</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.340469 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.277495</td><td style=\"text-align: right;\">        0.897045</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_652c3878</td><td>TERMINATED</td><td>172.19.2.2:8357</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.526841</td><td style=\"text-align: right;\">  0.812749</td><td style=\"text-align: right;\">     -0.0342478</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.159743</td><td style=\"text-align: right;\">        0.948971</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_9bb11edb</td><td>TERMINATED</td><td>172.19.2.2:8445</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.481423</td><td style=\"text-align: right;\">  0.837981</td><td style=\"text-align: right;\">     -0.132749 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.148684</td><td style=\"text-align: right;\">        0.952862</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_978b0440</td><td>TERMINATED</td><td>172.19.2.2:8529</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.636819</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0758897</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638329</td><td style=\"text-align: right;\">        0.556304</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_2bab1bbb</td><td>TERMINATED</td><td>172.19.2.2:8615</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.439474</td><td style=\"text-align: right;\">  0.810093</td><td style=\"text-align: right;\">     -0.307202 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.351108</td><td style=\"text-align: right;\">        0.84856 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_b8003976</td><td>TERMINATED</td><td>172.19.2.2:8688</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.63547 </td><td style=\"text-align: right;\">  0.572377</td><td style=\"text-align: right;\">      0.0669506</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637138</td><td style=\"text-align: right;\">        0.56633 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 13:08:36,553\tINFO worker.py:1753 -- Started a local Ray instance.\n",
      "2024-08-30 13:08:37,956\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-08-30 13:08:37,962\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "[I 2024-08-30 13:08:38,029] A new study created in memory with name: optuna\n",
      "\u001b[36m(train_fn pid=342)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=342)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=377)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=377)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  early_stopping_epoch</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_01a9b4f9</td><td style=\"text-align: right;\">  0.583001</td><td style=\"text-align: right;\">      0.074525 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.634506</td><td style=\"text-align: right;\">        0.554807</td><td style=\"text-align: right;\">    0.652353</td></tr>\n",
       "<tr><td>train_fn_0623ad38</td><td style=\"text-align: right;\">  0.590969</td><td style=\"text-align: right;\">      0.0643425</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.635184</td><td style=\"text-align: right;\">        0.566031</td><td style=\"text-align: right;\">    0.650501</td></tr>\n",
       "<tr><td>train_fn_06a4851e</td><td style=\"text-align: right;\">  0.835325</td><td style=\"text-align: right;\">     -0.203042 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.456862</td><td style=\"text-align: right;\">        0.928769</td><td style=\"text-align: right;\">    0.199464</td></tr>\n",
       "<tr><td>train_fn_08497c91</td><td style=\"text-align: right;\">  0.837981</td><td style=\"text-align: right;\">     -0.294426 </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.417639</td><td style=\"text-align: right;\">        0.914852</td><td style=\"text-align: right;\">    0.242675</td></tr>\n",
       "<tr><td>train_fn_0e814203</td><td style=\"text-align: right;\">  0.792829</td><td style=\"text-align: right;\">     -0.276636 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.466401</td><td style=\"text-align: right;\">        0.756828</td><td style=\"text-align: right;\">    0.529983</td></tr>\n",
       "<tr><td>train_fn_121fffcd</td><td style=\"text-align: right;\">  0.816733</td><td style=\"text-align: right;\">     -0.156733 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.473835</td><td style=\"text-align: right;\">        0.924429</td><td style=\"text-align: right;\">    0.209203</td></tr>\n",
       "<tr><td>train_fn_12df181d</td><td style=\"text-align: right;\">  0.816733</td><td style=\"text-align: right;\">     -0.0861577</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.501871</td><td style=\"text-align: right;\">        0.939544</td><td style=\"text-align: right;\">    0.167274</td></tr>\n",
       "<tr><td>train_fn_12e5f0fe</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0750191</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637905</td><td style=\"text-align: right;\">        0.559147</td><td style=\"text-align: right;\">    0.637464</td></tr>\n",
       "<tr><td>train_fn_132bcca2</td><td style=\"text-align: right;\">  0.559097</td><td style=\"text-align: right;\">      0.133375 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.686994</td><td style=\"text-align: right;\">        0.550917</td><td style=\"text-align: right;\">    0.689771</td></tr>\n",
       "<tr><td>train_fn_17c637c2</td><td style=\"text-align: right;\">  0.540505</td><td style=\"text-align: right;\">      0.110373 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.642084</td><td style=\"text-align: right;\">        0.549121</td><td style=\"text-align: right;\">    0.651055</td></tr>\n",
       "<tr><td>train_fn_17cb948d</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0841926</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.645524</td><td style=\"text-align: right;\">        0.564085</td><td style=\"text-align: right;\">    0.654011</td></tr>\n",
       "<tr><td>train_fn_17fda474</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.199368 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.449364</td><td style=\"text-align: right;\">        0.929667</td><td style=\"text-align: right;\">    0.198408</td></tr>\n",
       "<tr><td>train_fn_19130272</td><td style=\"text-align: right;\">  0.844622</td><td style=\"text-align: right;\">     -0.373104 </td><td style=\"text-align: right;\">                    13</td><td style=\"text-align: right;\">0.396032</td><td style=\"text-align: right;\">        0.890311</td><td style=\"text-align: right;\">    0.290749</td></tr>\n",
       "<tr><td>train_fn_1f7519a3</td><td style=\"text-align: right;\">  0.590969</td><td style=\"text-align: right;\">      0.084878 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.648253</td><td style=\"text-align: right;\">        0.558548</td><td style=\"text-align: right;\">    0.671021</td></tr>\n",
       "<tr><td>train_fn_1fc6108f</td><td style=\"text-align: right;\">  0.827357</td><td style=\"text-align: right;\">     -0.0525303</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.539225</td><td style=\"text-align: right;\">        0.936102</td><td style=\"text-align: right;\">    0.176765</td></tr>\n",
       "<tr><td>train_fn_216f7672</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.366005 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.399619</td><td style=\"text-align: right;\">        0.87804 </td><td style=\"text-align: right;\">    0.318867</td></tr>\n",
       "<tr><td>train_fn_23ee825e</td><td style=\"text-align: right;\">  0.820717</td><td style=\"text-align: right;\">     -0.20028  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.447552</td><td style=\"text-align: right;\">        0.923681</td><td style=\"text-align: right;\">    0.204745</td></tr>\n",
       "<tr><td>train_fn_2598c7e9</td><td style=\"text-align: right;\">  0.836653</td><td style=\"text-align: right;\">     -0.315921 </td><td style=\"text-align: right;\">                    11</td><td style=\"text-align: right;\">0.411971</td><td style=\"text-align: right;\">        0.906023</td><td style=\"text-align: right;\">    0.263818</td></tr>\n",
       "<tr><td>train_fn_2b0d8d45</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.0958823</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.516339</td><td style=\"text-align: right;\">        0.934755</td><td style=\"text-align: right;\">    0.185495</td></tr>\n",
       "<tr><td>train_fn_2bab1bbb</td><td style=\"text-align: right;\">  0.810093</td><td style=\"text-align: right;\">     -0.307202 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.439474</td><td style=\"text-align: right;\">        0.84856 </td><td style=\"text-align: right;\">    0.351108</td></tr>\n",
       "<tr><td>train_fn_3013dde5</td><td style=\"text-align: right;\">  0.827357</td><td style=\"text-align: right;\">     -0.411044 </td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.395769</td><td style=\"text-align: right;\">        0.850954</td><td style=\"text-align: right;\">    0.378279</td></tr>\n",
       "<tr><td>train_fn_33987d94</td><td style=\"text-align: right;\">  0.807437</td><td style=\"text-align: right;\">     -0.32355  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.430821</td><td style=\"text-align: right;\">        0.766105</td><td style=\"text-align: right;\">    0.495621</td></tr>\n",
       "<tr><td>train_fn_33d9cb80</td><td style=\"text-align: right;\">  0.837981</td><td style=\"text-align: right;\">     -0.232094 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.437363</td><td style=\"text-align: right;\">        0.930415</td><td style=\"text-align: right;\">    0.192746</td></tr>\n",
       "<tr><td>train_fn_36deab26</td><td style=\"text-align: right;\">  0.787517</td><td style=\"text-align: right;\">     -0.206792 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.491854</td><td style=\"text-align: right;\">        0.699663</td><td style=\"text-align: right;\">    0.581741</td></tr>\n",
       "<tr><td>train_fn_3896e862</td><td style=\"text-align: right;\">  0.839309</td><td style=\"text-align: right;\">     -0.281221 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.412335</td><td style=\"text-align: right;\">        0.925477</td><td style=\"text-align: right;\">    0.206995</td></tr>\n",
       "<tr><td>train_fn_399ba094</td><td style=\"text-align: right;\">  0.549801</td><td style=\"text-align: right;\">      0.149362 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.696654</td><td style=\"text-align: right;\">        0.554059</td><td style=\"text-align: right;\">    0.697412</td></tr>\n",
       "<tr><td>train_fn_39e02947</td><td style=\"text-align: right;\">  0.559097</td><td style=\"text-align: right;\">      0.119437 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.671507</td><td style=\"text-align: right;\">        0.55376 </td><td style=\"text-align: right;\">    0.680223</td></tr>\n",
       "<tr><td>train_fn_413edb78</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.190319 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.460705</td><td style=\"text-align: right;\">        0.925627</td><td style=\"text-align: right;\">    0.198338</td></tr>\n",
       "<tr><td>train_fn_46269c57</td><td style=\"text-align: right;\">  0.847278</td><td style=\"text-align: right;\">     -0.262188 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.423667</td><td style=\"text-align: right;\">        0.93281 </td><td style=\"text-align: right;\">    0.186353</td></tr>\n",
       "<tr><td>train_fn_46280169</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.317229 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.418932</td><td style=\"text-align: right;\">        0.88642 </td><td style=\"text-align: right;\">    0.299586</td></tr>\n",
       "<tr><td>train_fn_4bb3223a</td><td style=\"text-align: right;\">  0.798141</td><td style=\"text-align: right;\">     -0.281336 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.449642</td><td style=\"text-align: right;\">        0.842275</td><td style=\"text-align: right;\">    0.359451</td></tr>\n",
       "<tr><td>train_fn_4ca8d1be</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.135788 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.70093 </td><td style=\"text-align: right;\">        0.563786</td><td style=\"text-align: right;\">    0.701496</td></tr>\n",
       "<tr><td>train_fn_4ce11838</td><td style=\"text-align: right;\">  0.831341</td><td style=\"text-align: right;\">     -0.252891 </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.439255</td><td style=\"text-align: right;\">        0.915002</td><td style=\"text-align: right;\">    0.244526</td></tr>\n",
       "<tr><td>train_fn_4d5cee37</td><td style=\"text-align: right;\">  0.833997</td><td style=\"text-align: right;\">     -0.168489 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.461889</td><td style=\"text-align: right;\">        0.943734</td><td style=\"text-align: right;\">    0.164388</td></tr>\n",
       "<tr><td>train_fn_568fe81f</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.344238 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.399134</td><td style=\"text-align: right;\">        0.889263</td><td style=\"text-align: right;\">    0.297052</td></tr>\n",
       "<tr><td>train_fn_5830ba83</td><td style=\"text-align: right;\">  0.811421</td><td style=\"text-align: right;\">     -0.101507 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.49663 </td><td style=\"text-align: right;\">        0.932361</td><td style=\"text-align: right;\">    0.191003</td></tr>\n",
       "<tr><td>train_fn_589999ea</td><td style=\"text-align: right;\">  0.754316</td><td style=\"text-align: right;\">     -0.149957 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.521365</td><td style=\"text-align: right;\">        0.668687</td><td style=\"text-align: right;\">    0.601725</td></tr>\n",
       "<tr><td>train_fn_60eb737d</td><td style=\"text-align: right;\">  0.563081</td><td style=\"text-align: right;\">      0.128692 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.685708</td><td style=\"text-align: right;\">        0.568126</td><td style=\"text-align: right;\">    0.692793</td></tr>\n",
       "<tr><td>train_fn_652c3878</td><td style=\"text-align: right;\">  0.812749</td><td style=\"text-align: right;\">     -0.0342478</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.526841</td><td style=\"text-align: right;\">        0.948971</td><td style=\"text-align: right;\">    0.159743</td></tr>\n",
       "<tr><td>train_fn_657a5c2b</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0745013</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636485</td><td style=\"text-align: right;\">        0.55795 </td><td style=\"text-align: right;\">    0.637532</td></tr>\n",
       "<tr><td>train_fn_6726ef17</td><td style=\"text-align: right;\">  0.540505</td><td style=\"text-align: right;\">      0.150766 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.686248</td><td style=\"text-align: right;\">        0.550318</td><td style=\"text-align: right;\">    0.686016</td></tr>\n",
       "<tr><td>train_fn_6b7c1fee</td><td style=\"text-align: right;\">  0.822045</td><td style=\"text-align: right;\">     -0.181718 </td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.46018 </td><td style=\"text-align: right;\">        0.930116</td><td style=\"text-align: right;\">    0.207956</td></tr>\n",
       "<tr><td>train_fn_6cbcd62b</td><td style=\"text-align: right;\">  0.828685</td><td style=\"text-align: right;\">     -0.0942084</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.496309</td><td style=\"text-align: right;\">        0.952862</td><td style=\"text-align: right;\">    0.144151</td></tr>\n",
       "<tr><td>train_fn_6d908d9f</td><td style=\"text-align: right;\">  0.841965</td><td style=\"text-align: right;\">     -0.371714 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.39153 </td><td style=\"text-align: right;\">        0.895249</td><td style=\"text-align: right;\">    0.287371</td></tr>\n",
       "<tr><td>train_fn_6dafa1e2</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.152086 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.478801</td><td style=\"text-align: right;\">        0.933259</td><td style=\"text-align: right;\">    0.195747</td></tr>\n",
       "<tr><td>train_fn_72a82448</td><td style=\"text-align: right;\">  0.721116</td><td style=\"text-align: right;\">     -0.031319 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.617221</td><td style=\"text-align: right;\">        0.590722</td><td style=\"text-align: right;\">    0.631978</td></tr>\n",
       "<tr><td>train_fn_7362c8dc</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.142508 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.703353</td><td style=\"text-align: right;\">        0.564534</td><td style=\"text-align: right;\">    0.713263</td></tr>\n",
       "<tr><td>train_fn_7b9fa64c</td><td style=\"text-align: right;\">  0.786189</td><td style=\"text-align: right;\">     -0.293984 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.461989</td><td style=\"text-align: right;\">        0.771343</td><td style=\"text-align: right;\">    0.507574</td></tr>\n",
       "<tr><td>train_fn_7d9ba061</td><td style=\"text-align: right;\">  0.828685</td><td style=\"text-align: right;\">     -0.14567  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.476627</td><td style=\"text-align: right;\">        0.939095</td><td style=\"text-align: right;\">    0.17426 </td></tr>\n",
       "<tr><td>train_fn_7ea54596</td><td style=\"text-align: right;\">  0.802125</td><td style=\"text-align: right;\">     -0.29625  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.4525  </td><td style=\"text-align: right;\">        0.752787</td><td style=\"text-align: right;\">    0.509912</td></tr>\n",
       "<tr><td>train_fn_7ee5a3eb</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0721129</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637946</td><td style=\"text-align: right;\">        0.566929</td><td style=\"text-align: right;\">    0.640273</td></tr>\n",
       "<tr><td>train_fn_855bc4f7</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.102526 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.515588</td><td style=\"text-align: right;\">        0.926225</td><td style=\"text-align: right;\">    0.207922</td></tr>\n",
       "<tr><td>train_fn_87b68313</td><td style=\"text-align: right;\">  0.559097</td><td style=\"text-align: right;\">      0.15198  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.704985</td><td style=\"text-align: right;\">        0.553311</td><td style=\"text-align: right;\">    0.711383</td></tr>\n",
       "<tr><td>train_fn_887a98ed</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0758265</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636241</td><td style=\"text-align: right;\">        0.555556</td><td style=\"text-align: right;\">    0.638033</td></tr>\n",
       "<tr><td>train_fn_8d5227cc</td><td style=\"text-align: right;\">  0.541833</td><td style=\"text-align: right;\">      0.149171 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.685988</td><td style=\"text-align: right;\">        0.548373</td><td style=\"text-align: right;\">    0.68948 </td></tr>\n",
       "<tr><td>train_fn_90f0fcf6</td><td style=\"text-align: right;\">  0.75166 </td><td style=\"text-align: right;\">     -0.0714121</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.602405</td><td style=\"text-align: right;\">        0.618855</td><td style=\"text-align: right;\">    0.625286</td></tr>\n",
       "<tr><td>train_fn_96de45ed</td><td style=\"text-align: right;\">  0.828685</td><td style=\"text-align: right;\">     -0.127788 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.486902</td><td style=\"text-align: right;\">        0.939244</td><td style=\"text-align: right;\">    0.169471</td></tr>\n",
       "<tr><td>train_fn_978b0440</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0758897</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636819</td><td style=\"text-align: right;\">        0.556304</td><td style=\"text-align: right;\">    0.638329</td></tr>\n",
       "<tr><td>train_fn_9bb11edb</td><td style=\"text-align: right;\">  0.837981</td><td style=\"text-align: right;\">     -0.132749 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.481423</td><td style=\"text-align: right;\">        0.952862</td><td style=\"text-align: right;\">    0.148684</td></tr>\n",
       "<tr><td>train_fn_9d8dcd5c</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.330256 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.409663</td><td style=\"text-align: right;\">        0.877142</td><td style=\"text-align: right;\">    0.296524</td></tr>\n",
       "<tr><td>train_fn_9dcb9a55</td><td style=\"text-align: right;\">  0.824701</td><td style=\"text-align: right;\">     -0.296302 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.418838</td><td style=\"text-align: right;\">        0.898691</td><td style=\"text-align: right;\">    0.273704</td></tr>\n",
       "<tr><td>train_fn_a131e1f8</td><td style=\"text-align: right;\">  0.752988</td><td style=\"text-align: right;\">     -0.17934  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.520122</td><td style=\"text-align: right;\">        0.710737</td><td style=\"text-align: right;\">    0.584923</td></tr>\n",
       "<tr><td>train_fn_a1b45225</td><td style=\"text-align: right;\">  0.839309</td><td style=\"text-align: right;\">     -0.335601 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.406013</td><td style=\"text-align: right;\">        0.903479</td><td style=\"text-align: right;\">    0.274793</td></tr>\n",
       "<tr><td>train_fn_a319ce15</td><td style=\"text-align: right;\">  0.681275</td><td style=\"text-align: right;\">     -0.0117877</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.620932</td><td style=\"text-align: right;\">        0.594613</td><td style=\"text-align: right;\">    0.63138 </td></tr>\n",
       "<tr><td>train_fn_a5aa127a</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.167474 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.470605</td><td style=\"text-align: right;\">        0.93251 </td><td style=\"text-align: right;\">    0.189234</td></tr>\n",
       "<tr><td>train_fn_a8329e41</td><td style=\"text-align: right;\">  0.843293</td><td style=\"text-align: right;\">     -0.363274 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.390692</td><td style=\"text-align: right;\">        0.901684</td><td style=\"text-align: right;\">    0.270428</td></tr>\n",
       "<tr><td>train_fn_b734753f</td><td style=\"text-align: right;\">  0.579017</td><td style=\"text-align: right;\">      0.0657465</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.635129</td><td style=\"text-align: right;\">        0.567976</td><td style=\"text-align: right;\">    0.643357</td></tr>\n",
       "<tr><td>train_fn_b770411c</td><td style=\"text-align: right;\">  0.835325</td><td style=\"text-align: right;\">     -0.223533 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.443965</td><td style=\"text-align: right;\">        0.927722</td><td style=\"text-align: right;\">    0.200707</td></tr>\n",
       "<tr><td>train_fn_b780d9d9</td><td style=\"text-align: right;\">  0.848606</td><td style=\"text-align: right;\">     -0.367839 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.393777</td><td style=\"text-align: right;\">        0.901085</td><td style=\"text-align: right;\">    0.272278</td></tr>\n",
       "<tr><td>train_fn_b8003976</td><td style=\"text-align: right;\">  0.572377</td><td style=\"text-align: right;\">      0.0669506</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.63547 </td><td style=\"text-align: right;\">        0.56633 </td><td style=\"text-align: right;\">    0.637138</td></tr>\n",
       "<tr><td>train_fn_bf8b9605</td><td style=\"text-align: right;\">  0.832669</td><td style=\"text-align: right;\">     -0.161032 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.470964</td><td style=\"text-align: right;\">        0.938496</td><td style=\"text-align: right;\">    0.175446</td></tr>\n",
       "<tr><td>train_fn_c0f84ee7</td><td style=\"text-align: right;\">  0.839309</td><td style=\"text-align: right;\">     -0.452381 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.379854</td><td style=\"text-align: right;\">        0.838982</td><td style=\"text-align: right;\">    0.393676</td></tr>\n",
       "<tr><td>train_fn_c35d608c</td><td style=\"text-align: right;\">  0.571049</td><td style=\"text-align: right;\">      0.0696119</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.631684</td><td style=\"text-align: right;\">        0.562589</td><td style=\"text-align: right;\">    0.641177</td></tr>\n",
       "<tr><td>train_fn_c6761c8a</td><td style=\"text-align: right;\">  0.826029</td><td style=\"text-align: right;\">     -0.194304 </td><td style=\"text-align: right;\">                     9</td><td style=\"text-align: right;\">0.461844</td><td style=\"text-align: right;\">        0.92413 </td><td style=\"text-align: right;\">    0.220183</td></tr>\n",
       "<tr><td>train_fn_c6baa580</td><td style=\"text-align: right;\">  0.549801</td><td style=\"text-align: right;\">      0.101447 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.641056</td><td style=\"text-align: right;\">        0.557501</td><td style=\"text-align: right;\">    0.653739</td></tr>\n",
       "<tr><td>train_fn_c8127031</td><td style=\"text-align: right;\">  0.832669</td><td style=\"text-align: right;\">     -0.376636 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.396213</td><td style=\"text-align: right;\">        0.876842</td><td style=\"text-align: right;\">    0.320746</td></tr>\n",
       "<tr><td>train_fn_c8428bbd</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.073622 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.634933</td><td style=\"text-align: right;\">        0.558848</td><td style=\"text-align: right;\">    0.638224</td></tr>\n",
       "<tr><td>train_fn_c8e3abeb</td><td style=\"text-align: right;\">  0.822045</td><td style=\"text-align: right;\">     -0.123438 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.485872</td><td style=\"text-align: right;\">        0.9367  </td><td style=\"text-align: right;\">    0.175057</td></tr>\n",
       "<tr><td>train_fn_c9ebeda9</td><td style=\"text-align: right;\">  0.788845</td><td style=\"text-align: right;\">     -0.249975 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.473929</td><td style=\"text-align: right;\">        0.73887 </td><td style=\"text-align: right;\">    0.553836</td></tr>\n",
       "<tr><td>train_fn_c9ff502e</td><td style=\"text-align: right;\">  0.822045</td><td style=\"text-align: right;\">     -0.208457 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.451192</td><td style=\"text-align: right;\">        0.921886</td><td style=\"text-align: right;\">    0.22624 </td></tr>\n",
       "<tr><td>train_fn_cfd45057</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.074531 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636397</td><td style=\"text-align: right;\">        0.5578  </td><td style=\"text-align: right;\">    0.63753 </td></tr>\n",
       "<tr><td>train_fn_d4f8ed92</td><td style=\"text-align: right;\">  0.831341</td><td style=\"text-align: right;\">     -0.217784 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.444172</td><td style=\"text-align: right;\">        0.92862 </td><td style=\"text-align: right;\">    0.20268 </td></tr>\n",
       "<tr><td>train_fn_d8daadf8</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.195301 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.42796 </td><td style=\"text-align: right;\">        0.94927 </td><td style=\"text-align: right;\">    0.153632</td></tr>\n",
       "<tr><td>train_fn_dadf29a5</td><td style=\"text-align: right;\">  0.567065</td><td style=\"text-align: right;\">      0.0764991</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.635736</td><td style=\"text-align: right;\">        0.554807</td><td style=\"text-align: right;\">    0.639134</td></tr>\n",
       "<tr><td>train_fn_e2fb0879</td><td style=\"text-align: right;\">  0.839309</td><td style=\"text-align: right;\">     -0.0291655</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.544405</td><td style=\"text-align: right;\">        0.957651</td><td style=\"text-align: right;\">    0.131267</td></tr>\n",
       "<tr><td>train_fn_e35e8eca</td><td style=\"text-align: right;\">  0.831341</td><td style=\"text-align: right;\">     -0.178083 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.477127</td><td style=\"text-align: right;\">        0.920988</td><td style=\"text-align: right;\">    0.214513</td></tr>\n",
       "<tr><td>train_fn_e3d5f548</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.284235 </td><td style=\"text-align: right;\">                     9</td><td style=\"text-align: right;\">0.428247</td><td style=\"text-align: right;\">        0.895997</td><td style=\"text-align: right;\">    0.279088</td></tr>\n",
       "<tr><td>train_fn_e3f1159e</td><td style=\"text-align: right;\">  0.559097</td><td style=\"text-align: right;\">      0.0803354</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637289</td><td style=\"text-align: right;\">        0.555855</td><td style=\"text-align: right;\">    0.638333</td></tr>\n",
       "<tr><td>train_fn_e7dedcae</td><td style=\"text-align: right;\">  0.772908</td><td style=\"text-align: right;\">     -0.224174 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.490172</td><td style=\"text-align: right;\">        0.722858</td><td style=\"text-align: right;\">    0.557246</td></tr>\n",
       "<tr><td>train_fn_ec19e763</td><td style=\"text-align: right;\">  0.836653</td><td style=\"text-align: right;\">     -0.22537  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.447539</td><td style=\"text-align: right;\">        0.923681</td><td style=\"text-align: right;\">    0.207077</td></tr>\n",
       "<tr><td>train_fn_ec455209</td><td style=\"text-align: right;\">  0.822045</td><td style=\"text-align: right;\">     -0.239921 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.431852</td><td style=\"text-align: right;\">        0.921586</td><td style=\"text-align: right;\">    0.230848</td></tr>\n",
       "<tr><td>train_fn_ecb4dcf6</td><td style=\"text-align: right;\">  0.833997</td><td style=\"text-align: right;\">     -0.380191 </td><td style=\"text-align: right;\">                    11</td><td style=\"text-align: right;\">0.38991 </td><td style=\"text-align: right;\">        0.884923</td><td style=\"text-align: right;\">    0.313042</td></tr>\n",
       "<tr><td>train_fn_ed63d9a0</td><td style=\"text-align: right;\">  0.843293</td><td style=\"text-align: right;\">     -0.36502  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.391108</td><td style=\"text-align: right;\">        0.897194</td><td style=\"text-align: right;\">    0.270679</td></tr>\n",
       "<tr><td>train_fn_f136ac44</td><td style=\"text-align: right;\">  0.836653</td><td style=\"text-align: right;\">     -0.287821 </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.425241</td><td style=\"text-align: right;\">        0.910812</td><td style=\"text-align: right;\">    0.252218</td></tr>\n",
       "<tr><td>train_fn_f2070cb5</td><td style=\"text-align: right;\">  0.848606</td><td style=\"text-align: right;\">     -0.312892 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.402001</td><td style=\"text-align: right;\">        0.925477</td><td style=\"text-align: right;\">    0.211447</td></tr>\n",
       "<tr><td>train_fn_f39e94dd</td><td style=\"text-align: right;\">  0.823373</td><td style=\"text-align: right;\">     -0.0763075</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.507946</td><td style=\"text-align: right;\">        0.949719</td><td style=\"text-align: right;\">    0.156053</td></tr>\n",
       "<tr><td>train_fn_f49da2f4</td><td style=\"text-align: right;\">  0.670651</td><td style=\"text-align: right;\">     -0.0146046</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.620254</td><td style=\"text-align: right;\">        0.610625</td><td style=\"text-align: right;\">    0.631812</td></tr>\n",
       "<tr><td>train_fn_f9897e93</td><td style=\"text-align: right;\">  0.837981</td><td style=\"text-align: right;\">     -0.322672 </td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.412967</td><td style=\"text-align: right;\">        0.902132</td><td style=\"text-align: right;\">    0.272433</td></tr>\n",
       "<tr><td>train_fn_feeff367</td><td style=\"text-align: right;\">  0.830013</td><td style=\"text-align: right;\">     -0.340469 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.396517</td><td style=\"text-align: right;\">        0.897045</td><td style=\"text-align: right;\">    0.277495</td></tr>\n",
       "<tr><td>train_fn_ff32af3f</td><td style=\"text-align: right;\">  0.735724</td><td style=\"text-align: right;\">     -0.111316 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.562038</td><td style=\"text-align: right;\">        0.660456</td><td style=\"text-align: right;\">    0.611511</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_fn pid=480)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=480)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=560)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=560)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=638)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=638)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=718)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=718)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=797)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=797)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=875)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=875)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=975)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=975)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1064)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1064)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1129)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1129)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1236)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1236)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1325)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1325)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1424)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1424)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1522)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1522)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1593)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1593)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1694)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1694)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1768)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1768)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1858)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1858)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1940)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1940)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2016)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2016)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2116)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2116)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2204)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2204)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2291)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2291)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2386)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2386)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2464)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2464)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2544)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2544)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2621)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2621)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2702)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2702)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2778)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2778)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2860)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2860)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2937)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2937)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3028)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3028)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3104)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3104)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3196)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3196)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3303)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3303)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3377)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3377)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3470)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3470)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3544)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3544)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3629)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3629)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3703)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3703)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3793)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3793)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3869)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3869)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3953)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3953)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4040)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4040)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4111)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4111)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4197)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4197)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4269)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4269)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4356)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4356)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4437)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4437)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4523)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4523)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4604)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4604)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4679)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4679)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4761)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4761)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4837)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4837)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4928)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4928)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5005)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5005)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5091)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5091)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5165)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5165)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5284)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5284)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5369)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5369)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5442)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5442)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5528)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5528)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5601)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5601)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5704)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5704)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5784)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5784)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5885)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5885)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5965)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5965)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6054)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6054)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6142)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6142)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6241)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6241)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6323)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6323)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6411)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6411)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6486)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6486)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6587)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6587)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6662)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6662)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6757)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6757)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6839)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6839)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6927)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6927)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6994)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6994)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7089)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7089)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7159)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7159)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7248)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7248)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7319)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7319)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7406)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7406)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7472)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7472)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7565)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7565)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7670)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7670)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7751)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7751)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7842)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7842)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7919)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7919)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8014)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8014)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8091)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8091)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8180)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8180)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8264)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8264)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8357)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8357)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8445)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8445)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8529)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8529)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8615)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8615)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8688)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8688)\u001b[0m   warnings.warn(\n",
      "2024-08-30 16:53:52,030\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_fn_2024-08-30_13-08-38' in 0.0541s.\n",
      "2024-08-30 16:53:52,091\tINFO tune.py:1041 -- Total run time: 13514.13 seconds (13500.72 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /kaggle/working/tensorboard_logs\n",
    "\n",
    "\n",
    "# ray.init(ignore_reinit_error=True)\n",
    "# reporter = CLIReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "#     print_intermediate_tables=False\n",
    "# )\n",
    "\n",
    "reporter = JupyterNotebookReporter(\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "    print_intermediate_tables=False\n",
    ")\n",
    "\n",
    "# tuner = tune.run(\n",
    "#     train_fn,\n",
    "#     config=search_space,\n",
    "#     num_samples=25,\n",
    "#     progress_reporter=reporter,\n",
    "#     resources_per_trial={\"cpu\": 4, \"gpu\": 2},  # Adjust resources as needed\n",
    "#     scheduler=ASHAScheduler(\n",
    "#         metric=\"accuracy\",\n",
    "#         mode=\"max\",\n",
    "#         max_t=15,\n",
    "#         grace_period=1,\n",
    "#         reduction_factor=2\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# reporter = TensorBoardReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"training_iteration\", \"train_loss\", \"train_accuracy\"]\n",
    "# )\n",
    "\n",
    "\n",
    "result = tune.run(\n",
    "    train_fn,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "    config=search_space,\n",
    "    num_samples=100,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    search_alg=optuna_search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649cb98e",
   "metadata": {
    "papermill": {
     "duration": 0.046073,
     "end_time": "2024-08-30T16:53:52.416823",
     "exception": false,
     "start_time": "2024-08-30T16:53:52.370750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c30cb49c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:53:52.514198Z",
     "iopub.status.busy": "2024-08-30T16:53:52.512947Z",
     "iopub.status.idle": "2024-08-30T16:53:52.522944Z",
     "shell.execute_reply": "2024-08-30T16:53:52.521725Z"
    },
    "papermill": {
     "duration": 0.062211,
     "end_time": "2024-08-30T16:53:52.525368",
     "exception": false,
     "start_time": "2024-08-30T16:53:52.463157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'dropout_rate': 0.4, 'batch_size': 64, 'weight_decay': 2e-05, 'lr': 3e-05, 'epochs': 5}\n",
      "Best trial final validation loss: 0.4020007289946079\n",
      "Best trial final validation accuracy: 0.848605577689243\n",
      "Best trial final training loss: 0.2114465691149235\n",
      "Best trial final training accuracy: 0.9254769921436589\n",
      "Best trial final custom_metric: -0.312892061527585\n",
      "Best trial final Early Stopping Epoch: 5\n"
     ]
    }
   ],
   "source": [
    "# best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "# best_checkpoint_dir = best_trial.checkpoint.value\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
    "print(f\"Best trial final training loss: {best_trial.last_result['train_loss']}\")\n",
    "print(f\"Best trial final training accuracy: {best_trial.last_result['train_accuracy']}\")\n",
    "print(f\"Best trial final custom_metric: {best_trial.last_result['custom_metric']}\")\n",
    "print(f\"Best trial final Early Stopping Epoch: {best_trial.last_result['early_stopping_epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d6eb9",
   "metadata": {
    "papermill": {
     "duration": 0.048836,
     "end_time": "2024-08-30T16:53:52.622201",
     "exception": false,
     "start_time": "2024-08-30T16:53:52.573365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Train the Model with the Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41092771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:53:52.719584Z",
     "iopub.status.busy": "2024-08-30T16:53:52.719183Z",
     "iopub.status.idle": "2024-08-30T16:53:52.748551Z",
     "shell.execute_reply": "2024-08-30T16:53:52.747626Z"
    },
    "papermill": {
     "duration": 0.079869,
     "end_time": "2024-08-30T16:53:52.750862",
     "exception": false,
     "start_time": "2024-08-30T16:53:52.670993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_best_model(config, device, train_dataset = train_ds_pd, val_dataset = validation_ds_pd):\n",
    "    print(f\"\"\"\n",
    "    Tuning Model with:\n",
    "    {config}\n",
    "    \"\"\")\n",
    "#     model = SentimentModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=3,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    model = SentimentModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     class_weights_tmp = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights_tmp)\n",
    "#     criterion = nn.BCELoss()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    ## DATASET ENCODING\n",
    "    \n",
    "    train_dataset = SentimentDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = SentimentDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = None\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    \n",
    "    ### Running for config epochs +patience+1 for introducing noise. \n",
    "    \n",
    "    for epoch in range((config[\"epochs\"]+patience+1)):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = torch.zeros_like(probabilities)\n",
    "            max_indices = torch.argmax(probabilities, dim=1)\n",
    "            predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "            predictions = predictions.float()\n",
    "                \n",
    "#                 loss = criterion(predictions, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "#             outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "#             predicted_labels = (outputs > 0.5).float()\n",
    "#             correct_train_preds += (predicted_labels == labels).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "            correct_train_preds += (predictions == labels).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = torch.zeros_like(probabilities)\n",
    "                max_indices = torch.argmax(probabilities, dim=1)\n",
    "                predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "                predictions = predictions.float()\n",
    "\n",
    "#                     loss = criterion(predictions, labels)\n",
    "                \n",
    "#                 outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "    \n",
    "#                 predicted_labels = (outputs > 0.5).float()\n",
    "#                 correct_val_preds += (predicted_labels == labels).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "                correct_val_preds += (predictions == labels).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "        checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "#         # Save the best model based on validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "#             best_model_path = checkpoint_path\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_since_improvement = 0\n",
    "            best_model_path = checkpoint_path\n",
    "            # Save the model checkpoint with the best validation loss\n",
    "#             checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#             torch.save(model.state_dict(), checkpoint_path)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'config': config  # Save configuration\n",
    "            }, checkpoint_path)\n",
    "    \n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            print(f\"Best Model Epoch Saved: {epoch - patience +1}\")\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "#         if epochs_since_improvement >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "#             print(f\"Best Model Epoch Saved: {epoch - patience}\")\n",
    "#             break\n",
    "            \n",
    "#         custom_metric = calculate_custom_metric(avg_val_loss, avg_train_loss)        \n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "        print(f\"\"\"\n",
    "        Validation Loss: {avg_val_loss},\n",
    "        Training Loss: {avg_train_loss},\n",
    "        Argmax Binary Validation Accuracy: {val_accuracy},\n",
    "        Argmax Binary Training Accuracy: {train_accuracy},\n",
    "        Custom Metric: {custom_metric},\n",
    "        Epochs: {epoch+1}\n",
    "        \"\"\")\n",
    "    \n",
    "    print(f\"Best Validation Loss: {best_val_loss}, Best Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0e571",
   "metadata": {
    "papermill": {
     "duration": 0.046527,
     "end_time": "2024-08-30T16:53:52.845034",
     "exception": false,
     "start_time": "2024-08-30T16:53:52.798507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BEST MODEL AFTER FINAL TRAINING & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbe4123e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:53:52.938471Z",
     "iopub.status.busy": "2024-08-30T16:53:52.938012Z",
     "iopub.status.idle": "2024-08-30T16:59:30.923985Z",
     "shell.execute_reply": "2024-08-30T16:59:30.922762Z"
    },
    "papermill": {
     "duration": 338.085547,
     "end_time": "2024-08-30T16:59:30.976840",
     "exception": false,
     "start_time": "2024-08-30T16:53:52.891293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Tuning Model with:\n",
      "    {'dropout_rate': 0.4, 'batch_size': 64, 'weight_decay': 2e-05, 'lr': 3e-05, 'epochs': 5}\n",
      "    \n",
      "\n",
      "        Validation Loss: 0.4173536077141762,\n",
      "        Training Loss: 0.5758340746164322,\n",
      "        Argmax Binary Validation Accuracy: 0.8127490039840638,\n",
      "        Argmax Binary Training Accuracy: 0.669734380845492,\n",
      "        Custom Metric: -0.2446478512494737,\n",
      "        Epochs: 1\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.3647834435105324,\n",
      "        Training Loss: 0.42356979548931123,\n",
      "        Argmax Binary Validation Accuracy: 0.8339973439575034,\n",
      "        Argmax Binary Training Accuracy: 0.8093527871305649,\n",
      "        Custom Metric: -0.42749844604411236,\n",
      "        Epochs: 2\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.368868213146925,\n",
      "        Training Loss: 0.3417958391564233,\n",
      "        Argmax Binary Validation Accuracy: 0.8406374501992032,\n",
      "        Argmax Binary Training Accuracy: 0.8581369248035915,\n",
      "        Custom Metric: -0.4494833127548333,\n",
      "        Epochs: 3\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.3941846303641796,\n",
      "        Training Loss: 0.26866269750254496,\n",
      "        Argmax Binary Validation Accuracy: 0.8366533864541833,\n",
      "        Argmax Binary Training Accuracy: 0.8936026936026936,\n",
      "        Custom Metric: -0.35123313608493123,\n",
      "        Epochs: 4\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.44728120788931847,\n",
      "        Training Loss: 0.20802390170948845,\n",
      "        Argmax Binary Validation Accuracy: 0.8326693227091634,\n",
      "        Argmax Binary Training Accuracy: 0.9251777029554807,\n",
      "        Custom Metric: -0.21950527160677125,\n",
      "        Epochs: 5\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.4725586548447609,\n",
      "        Training Loss: 0.13588123470544816,\n",
      "        Argmax Binary Validation Accuracy: 0.8353253652058433,\n",
      "        Argmax Binary Training Accuracy: 0.9603441825664047,\n",
      "        Custom Metric: -0.13191859161114536,\n",
      "        Epochs: 6\n",
      "        \n",
      "Early stopping at epoch 7\n",
      "Best Model Epoch Saved: 2\n",
      "Best Validation Loss: 0.3647834435105324, Best Validation accuracy: 0.8313413014608234\n"
     ]
    }
   ],
   "source": [
    "best_config = best_trial.config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model with the best configuration\n",
    "best_model, best_model_path = train_best_model(best_config, device, train_ds_pd, validation_ds_pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206dfa3",
   "metadata": {
    "papermill": {
     "duration": 0.048241,
     "end_time": "2024-08-30T16:59:31.073545",
     "exception": false,
     "start_time": "2024-08-30T16:59:31.025304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfe16c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:31.173206Z",
     "iopub.status.busy": "2024-08-30T16:59:31.172734Z",
     "iopub.status.idle": "2024-08-30T16:59:32.505099Z",
     "shell.execute_reply": "2024-08-30T16:59:32.503912Z"
    },
    "papermill": {
     "duration": 1.385433,
     "end_time": "2024-08-30T16:59:32.507525",
     "exception": false,
     "start_time": "2024-08-30T16:59:31.122092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: /kaggle/working/final_best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "# final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path) \n",
    "\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path)\n",
    "torch.save({'model_state_dict': best_model.state_dict(),'config': best_config}, final_model_path)\n",
    "\n",
    "print(f\"Best model saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f03a82",
   "metadata": {
    "papermill": {
     "duration": 0.04788,
     "end_time": "2024-08-30T16:59:32.605243",
     "exception": false,
     "start_time": "2024-08-30T16:59:32.557363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "219fc889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:32.704352Z",
     "iopub.status.busy": "2024-08-30T16:59:32.703914Z",
     "iopub.status.idle": "2024-08-30T16:59:34.389469Z",
     "shell.execute_reply": "2024-08-30T16:59:34.388145Z"
    },
    "papermill": {
     "duration": 1.737746,
     "end_time": "2024-08-30T16:59:34.391825",
     "exception": false,
     "start_time": "2024-08-30T16:59:32.654079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /kaggle/working/final_best_model.pt for inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# final_model_path = \"/kaggle/input/tachygraphy-lv2-emotion-moodtags-v1/transformers/default/1/final_best_model.pt\"\n",
    "\n",
    "\n",
    "checkpoint = torch.load(final_model_path)\n",
    "config = checkpoint['config']\n",
    "\n",
    "# loaded_model = SentimentModel(\n",
    "#     roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#     n_classes=3,\n",
    "#     dropout_rate=config[\"dropout_rate\"]\n",
    "# )\n",
    "loaded_model = SentimentModel(\n",
    "    roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "    n_classes=3,\n",
    "    dropout_rate=config[\"dropout_rate\"]\n",
    ")\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(f\"Loaded model from {final_model_path} for inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35866e9",
   "metadata": {
    "papermill": {
     "duration": 0.047544,
     "end_time": "2024-08-30T16:59:34.488263",
     "exception": false,
     "start_time": "2024-08-30T16:59:34.440719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PREDICT ON RANDOM INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6133b47",
   "metadata": {
    "papermill": {
     "duration": 0.047571,
     "end_time": "2024-08-30T16:59:34.585436",
     "exception": false,
     "start_time": "2024-08-30T16:59:34.537865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d3fda63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:34.686067Z",
     "iopub.status.busy": "2024-08-30T16:59:34.685148Z",
     "iopub.status.idle": "2024-08-30T16:59:34.694267Z",
     "shell.execute_reply": "2024-08-30T16:59:34.692920Z"
    },
    "papermill": {
     "duration": 0.06171,
     "end_time": "2024-08-30T16:59:34.696637",
     "exception": false,
     "start_time": "2024-08-30T16:59:34.634927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, device, max_len=128):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "#     # Convert logits to probabilities using sigmoid\n",
    "#     probabilities = torch.sigmoid(logits)\n",
    "    \n",
    "#     # Convert probabilities to binary predictions\n",
    "#     predictions = torch.zeros_like(probabilities)\n",
    "#     max_indices = torch.argmax(probabilities, dim=1)\n",
    "#     predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "    \n",
    "#     # Move predictions to CPU and convert to numpy for easy manipulation\n",
    "#     predictions_array = predictions.cpu().numpy().squeeze()\n",
    "\n",
    "#     return predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec390d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:34.792976Z",
     "iopub.status.busy": "2024-08-30T16:59:34.792471Z",
     "iopub.status.idle": "2024-08-30T16:59:34.803181Z",
     "shell.execute_reply": "2024-08-30T16:59:34.802173Z"
    },
    "papermill": {
     "duration": 0.060961,
     "end_time": "2024-08-30T16:59:34.805410",
     "exception": false,
     "start_time": "2024-08-30T16:59:34.744449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = loaded_model\n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a722d384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:34.900407Z",
     "iopub.status.busy": "2024-08-30T16:59:34.900018Z",
     "iopub.status.idle": "2024-08-30T16:59:35.547797Z",
     "shell.execute_reply": "2024-08-30T16:59:35.546809Z"
    },
    "papermill": {
     "duration": 0.698312,
     "end_time": "2024-08-30T16:59:35.550394",
     "exception": false,
     "start_time": "2024-08-30T16:59:34.852082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96032fed",
   "metadata": {
    "papermill": {
     "duration": 0.045616,
     "end_time": "2024-08-30T16:59:35.643069",
     "exception": false,
     "start_time": "2024-08-30T16:59:35.597453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Samples & Random Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9fc44ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:35.740604Z",
     "iopub.status.busy": "2024-08-30T16:59:35.739844Z",
     "iopub.status.idle": "2024-08-30T16:59:37.597374Z",
     "shell.execute_reply": "2024-08-30T16:59:37.596167Z"
    },
    "papermill": {
     "duration": 1.910231,
     "end_time": "2024-08-30T16:59:37.599741",
     "exception": false,
     "start_time": "2024-08-30T16:59:35.689510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'hey! hru, wanna ply valo toni8?': [[0.00867144 0.52959716 0.45334682]]\n",
      "NEAGTIVE: 0.0, NEUTRAL: 1.0, POSITIVE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"de41b6d1-b093-419c-a499-a1aa87d89fd5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"de41b6d1-b093-419c-a499-a1aa87d89fd5\")) {                    Plotly.newPlot(                        \"de41b6d1-b093-419c-a499-a1aa87d89fd5\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.008671442,0.52959716,0.45334682,0.008671442],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('de41b6d1-b093-419c-a499-a1aa87d89fd5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"hey! hru, wanna ply valo toni8?\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35575bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:37.698602Z",
     "iopub.status.busy": "2024-08-30T16:59:37.697682Z",
     "iopub.status.idle": "2024-08-30T16:59:38.068045Z",
     "shell.execute_reply": "2024-08-30T16:59:38.066912Z"
    },
    "papermill": {
     "duration": 0.422627,
     "end_time": "2024-08-30T16:59:38.070430",
     "exception": false,
     "start_time": "2024-08-30T16:59:37.647803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'what a badass char is arthur, he is the best game char ever made, i luv rdr2': [[0.00596881 0.01314257 0.9876622 ]]\n",
      "NEAGTIVE: 0.0, NEUTRAL: 0.0, POSITIVE: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"0e6d7867-c917-4d07-a6aa-48669bc12554\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0e6d7867-c917-4d07-a6aa-48669bc12554\")) {                    Plotly.newPlot(                        \"0e6d7867-c917-4d07-a6aa-48669bc12554\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.00596881,0.013142574,0.9876622,0.00596881],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0e6d7867-c917-4d07-a6aa-48669bc12554');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"what a badass char is arthur, he is the best game char ever made, i luv rdr2\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7eac8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T16:59:38.175448Z",
     "iopub.status.busy": "2024-08-30T16:59:38.175035Z",
     "iopub.status.idle": "2024-08-30T16:59:38.540894Z",
     "shell.execute_reply": "2024-08-30T16:59:38.539913Z"
    },
    "papermill": {
     "duration": 0.421209,
     "end_time": "2024-08-30T16:59:38.543162",
     "exception": false,
     "start_time": "2024-08-30T16:59:38.121953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'I don't no fr y hes sooo sad.': [[0.98414916 0.0126807  0.00935807]]\n",
      "NEAGTIVE: 1.0, NEUTRAL: 0.0, POSITIVE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"11dead4e-732a-4b1b-b0a4-966e72bf83ac\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"11dead4e-732a-4b1b-b0a4-966e72bf83ac\")) {                    Plotly.newPlot(                        \"11dead4e-732a-4b1b-b0a4-966e72bf83ac\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.98414916,0.012680701,0.009358069,0.98414916],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('11dead4e-732a-4b1b-b0a4-966e72bf83ac');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"I don't no fr y hes sooo sad.\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5557640,
     "sourceId": 9273793,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13909.649543,
   "end_time": "2024-08-30T16:59:43.917972",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-30T13:07:54.268429",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "005aa0d7db18418889e0293a6002bc7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "091b9dd52ec24b708f7870664c4a25a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c629648ebef9484fa890dbcf5654c647",
       "placeholder": "​",
       "style": "IPY_MODEL_cbd9bceb89734f05a84dfb3fe029ff56",
       "value": " 52.0/52.0 [00:00&lt;00:00, 3.53kB/s]"
      }
     },
     "0d29e11767f641aca5e1fd5523516494": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19232b2c5a0a4f46a507d21c74914225": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e0f082edf944e76a0c8e9b8e30811f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_767df08e8c2d4e09aea63c3f1638bcdb",
       "placeholder": "​",
       "style": "IPY_MODEL_9443628945c34941913978678db6b6d0",
       "value": " 579/579 [00:00&lt;00:00, 40.5kB/s]"
      }
     },
     "230cc0c791374628bc506848351eff8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "252cbfdaddf240b4a4da61294d058bbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2f862550d1c74097aaf420b644ebb7cf",
        "IPY_MODEL_407b82e3f9394d739392bfe79116d4fe",
        "IPY_MODEL_091b9dd52ec24b708f7870664c4a25a8"
       ],
       "layout": "IPY_MODEL_19232b2c5a0a4f46a507d21c74914225"
      }
     },
     "2f862550d1c74097aaf420b644ebb7cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ddf7a2dabca9407a849f9a48175a591d",
       "placeholder": "​",
       "style": "IPY_MODEL_59b8203aafab49ec90bc87434702e17e",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "309bd563ea6d4031a38365ca8e667d72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a67b27692d214e31ad466914f1a1a6e2",
       "placeholder": "​",
       "style": "IPY_MODEL_230cc0c791374628bc506848351eff8e",
       "value": "spm.model: 100%"
      }
     },
     "3927dc4644e342d3854ca3f9923a8318": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "407b82e3f9394d739392bfe79116d4fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8912ce537e8433d97b2a80a5210daa5",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c3c75fc94b204dc3b6a6e759929dceb8",
       "value": 52.0
      }
     },
     "54a2eae7c4084d0181f47a2ad04bf3b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "55228b91fd654c3d878aa8da51fe39df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dab0f92d4b4c434d8a3862eb5ae9a7e9",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_005aa0d7db18418889e0293a6002bc7d",
       "value": 579.0
      }
     },
     "59b8203aafab49ec90bc87434702e17e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5f8d1f844bff4365856c091c8a65f5e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62d98a5f13404969883e2b2eab37c435": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7634e7b65bb340358b08a8c8676bd7e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3927dc4644e342d3854ca3f9923a8318",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fe17eaeaea1c4c7ea70fc5f88aae701a",
       "value": 2464616.0
      }
     },
     "767df08e8c2d4e09aea63c3f1638bcdb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ceaa24782024c3089b58d46a27273bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_309bd563ea6d4031a38365ca8e667d72",
        "IPY_MODEL_7634e7b65bb340358b08a8c8676bd7e9",
        "IPY_MODEL_ef274ef664f64f39922e5121aafe212a"
       ],
       "layout": "IPY_MODEL_62d98a5f13404969883e2b2eab37c435"
      }
     },
     "9443628945c34941913978678db6b6d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "98f9499a36e04ca6b35523130ec059cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a67b27692d214e31ad466914f1a1a6e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbe7d89b0917402185475caa18a051d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f51e964dbc0e4f2cbc79a212a79a9d65",
       "placeholder": "​",
       "style": "IPY_MODEL_98f9499a36e04ca6b35523130ec059cf",
       "value": "config.json: 100%"
      }
     },
     "c3c75fc94b204dc3b6a6e759929dceb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c629648ebef9484fa890dbcf5654c647": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbd9bceb89734f05a84dfb3fe029ff56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dab0f92d4b4c434d8a3862eb5ae9a7e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddf7a2dabca9407a849f9a48175a591d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8912ce537e8433d97b2a80a5210daa5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef274ef664f64f39922e5121aafe212a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0d29e11767f641aca5e1fd5523516494",
       "placeholder": "​",
       "style": "IPY_MODEL_54a2eae7c4084d0181f47a2ad04bf3b3",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 24.9MB/s]"
      }
     },
     "f08f56b26629466393a5f3160f482ff1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bbe7d89b0917402185475caa18a051d3",
        "IPY_MODEL_55228b91fd654c3d878aa8da51fe39df",
        "IPY_MODEL_1e0f082edf944e76a0c8e9b8e30811f5"
       ],
       "layout": "IPY_MODEL_5f8d1f844bff4365856c091c8a65f5e8"
      }
     },
     "f51e964dbc0e4f2cbc79a212a79a9d65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe17eaeaea1c4c7ea70fc5f88aae701a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
